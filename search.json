[{"title":"ListNet Model","url":"%2Fblog%2FListNet-model.html","content":"\nLTR方法可以分为 point-wise、pair-wise、list-wise 三类, ListNet 算法就是 list-wise 方法的一种. \n\n# ListWise 方法\n\n上标表示训练集中 query 的序号, 下标表示一个特定query对应的doc 的序号:\n- $Q = \\{q^{(1)}, q^{(2)}, \\dots, q^{(m)}\\}$ : 训练集中query的集合, $m$ 表示训练集中 query的数量;\n- $d^{(i)} = (d_1^{(i)}, d_2^{(i)}, \\dots, d_{n^{(i)}}^{(i)})$ : query $q^{(i)}$ 对应的doc列表, $n^{(i)}$ 表示第 $i$个query 对应的doc 列表的大小;\n- $y^{(i)} = (y_1^{(i)}, y_2^{(i)}, \\dots, y_{n^{(i)}}^{(i)})$ : $d^{(i)}$ 列表中每一个doc 的rank分.  这个分可以是由人工标注得到, 也可以通过用户行为日志得到(e.g. 基于点击模型挖掘. 基于用户行为的标注对于高频query效果较好, 但对长尾query效果欠佳), . 根据实际需求, 这个rank分可以分为若干级别, 一般为5级$\\{0, 1, 2, 3, 4\\}$, 数值越大说明对应的 doc 和 query 相关性约高. \n- $x_j^{(i)} = \\Psi(q^{(i)}, d_j^{(i)})$: 由 $q^{(i)}$ 和 $d_j^{(i)}$ 组成的 query-doc pair 的特征.\n- $x^{(i)} = (x_1^{(i)}, x_2^{(i)}, \\dots, x_{n^{(i)}}^{(i)})$: query $q^{(i)}$ 对应的query-doc pair 列表 特征集合. note: 上标表示query序号, 下标表示doc序号.\n- $\\mathcal {T} = \\{x^{(i)}, y^{(i)}\\}_{i=1}^m$ : 训练集合. \n\n假设有一个算分函数 $f(x; w)$, 其中 $w$ 为模型参数, $x$ 为输入特征向量, 这个函数可以是简单的线性回归函数，也可以是复杂的神经网络模型. 输入一个 query-doc pair 的特征向量, 输出一个得分 .  对于一个query $q^{(i)}$ 的得分列表可以表示为 $z^{(i)} = \\{f(x_1^{(i)}), f(x_2^{(i)}), \\dots, f(x_{n^{(i)}}^{(i)})\\}$.  我们希望按照 $z^{(i)}$ 对所有doc 进行排序 和 按照 $y^{(i)}$ 对doc进行排序 越相似越好.\n\n这个相似程度我们使用 损失函数来衡量 : \n$$\n\\sum_{i-1}^m L(y^{(i)}, z^{(i)})\n$$\n我们的目标就是通过最小化损失函数训练一个算分函数 $f(x; w)$ 用来预测. \n\nListNet 中 的算分函数 $f(x; w)$ 选用的是一个神经网络模型, 下面介绍 ListNet 是怎么构建这个损失函数的. \n\n# ListNet 损失函数\n\nListNet使用 cross-entropy 作为损失函数, cross-entropy 可以定义为 $H(p,q) = \\sum p \\log q$, 所以我们只需要确定这个公式中 p和q的表示方式.\n\n根据样本数据的实际标注的 $y$ 值 , $d^{(i)} = (d_1^{(i)}, d_2^{(i)}, \\dots, d_{n^{(i)}}^{(i)}) $ 中的 $d_j^{(i)}; j \\in \\{1, 2, \\dots n^{(i)} \\}$ 排列在第一个的概率表示为:\n$$\nP_{y^{(i)}}(j)\n$$\n\n\n根据算分公式计算得到的 $z$ 值, 集合 $d^{(i)} = (d_1^{(i)}, d_2^{(i)}, \\dots, d_{n^{(i)}}^{(i)}) $ 中的 $d_j^{(i)}; j \\in \\{1, 2, \\dots n^{(i)} \\}$ 排列在第一个的概率表示为:\n$$\nP_{z^{(i)}}(j)\n$$\n\n\n这两个概率就是交叉熵公式中的 $p$和$q$. 那么我们下面推到这个概率是怎么来的.\n\n\n\n## Permutation Probability\n\n> Suppose that $\\pi$ is a permutation on the $n$ objects, and $\\phi(\\cdot)$ is an increasing and strictly positive function. Then, the probability of permutation $ \\pi $ given the list of scores $s$ is defined as\n> $$\n> P_s(\\pi) = \\prod_{j=1}^n \\frac{\\phi(s_{\\pi(j)})}{\\sum_{k=j}^n \\phi(s_{\\pi(k)})}\n> $$\n> where $s_{\\pi(j)}$ is the score of object at position $j$ of permutation $\\pi$.\n\n即, 和某一query对于 $n$ 个doc对象, 可以得到 $A_n^n$ 个排列 (permutation). 再使用算分公式计算得到 $n$ 个doc的得分列表 $s$ 后,  我们可以使用上面的公式计算任意一个排列 $\\pi$ 的概率. 其中: $\\pi(j)$ 表示排列 $\\pi$ 中的第 $j$ 个元素, $s_{\\pi(j)})$ 表示第 $j$ 个元素的得分.\n\n上式具有如下性质\n\n- 所有$A_n^n$个排列(permutation)的概率之和为1;\n- 概率最大排列是按照得分逆序排列所有doc的;\n- 交换排列中两个对象的位置，得分高的对象前移会使得排列概率增大;\n- 如果 $\\phi(x) = \\alpha x$ 是一个线性函数，可以保证 $P_s(\\pi)$ 缩放不变性;\n- 如果 $\\phi(x) = \\exp(x)$ 是一个指数函数，可以保证 $P_s(\\pi)$ 平移不变性.\n\n此处不一一证明, 需要深究的话请查看原始论文.\n\n一个query对应的有 $n$ 个 doc 的列表,  $y^{(i)} = (y_1^{(i)}, y_2^{(i)}, \\dots, y_{n}^{(i)})$ 为其一个 score list. $z^{(i)} = \\{f(x_1^{(i)}), f(x_2^{(i)}), \\dots, f(x_{n}^{(i)})\\}$ 为其另一个 score list. 对于这两个 score list 可以分别按照上面的公式计算得到 $A_n^n = n!$ 个 permutation probability. 这样就可以通过 listwise loss function (e.g. cross entropy) 计算得到一个两个score list的相似程度, 能够是两个score list最相似的算分公式 $f(x; w)$ 就是我们要求的算分公式.\n\n但是复杂度太高, 对于 $n$ 个doc, 就需要计算 $n!$ 个permutation probability, 在实际操作中是很难实现的. ListNet 使用 Top One Probability 来解决这个问题\n\n## Top One Probability\n\ntop one probability 表示在给定 score list 后, 列表中的第 $j$ 个对象排在第一个的概率.\n\n> The top one probability of object $j$ is defined as\n> $$\n> P_s(j) = \\sum_{\\pi(i)=j,\\pi \\in \\Omega_n}P_s(\\pi).\n> $$\n> where $P_s(\\pi)$ is permutation probability of $\\pi$ given $s$.\n\n其中 $\\Omega_n$ 为 $n$ 个对象的所有排列(permutation)的集合, 其中包含 $n!$ 个排列.\n\n按照上面的公式, 仍然需要 $n!$ 个 permutation probability. 实际上我们可以对上面的公式进行推到得到一个更高效的计算方法. 即:\n$$\nP_s(j) = \\frac{\\phi(s_j)}{\\sum_{k=1}^n \\phi(s_k)}.\n$$\n其中 $s_j$ 是 score list 中第 $j$ 个对象的score.\n\n此处即可得到以交叉熵损失函数, 如下:\n$$\n\\begin{align}\n& P_{y^{(i)}}(j) = \\frac{\\phi(y_j^{(i)})}{\\sum_{k=1}^n \\phi(y_k^{(i)})}\\\\\n& P_{z^{(i)}}(j) = \\frac{\\phi(z_j^{(i)})}{\\sum_{k=1}^n \\phi(z_k^{(i)})}\\\\\n& L(y^{(i)}, z^{(i)}) = - \\sum_{j=1}^{n^{(i)}} P_{y^{(i)}}(j) \\log P_{z^{(i)}}(j) = - \\sum_{j=1}^{n^{(i)}} \\frac{\\phi(y_j^{(i)})}{\\sum_{k=1}^n \\phi(y_k^{(i)})} \\log \\frac{\\phi(z_j^{(i)})}{\\sum_{k=1}^n \\phi(z_k^{(i)})} \\\\\n& \\mathcal{L} = \\sum_{i-1}^m L(y^{(i)}, z^{(i)}).\n\\end{align}\n$$\n\n# 模型优化\n\n为了简化表述, 此处我们假定 $\\phi(x) = \\exp(x)$ , 此时:\n$$\n\\begin{align}\nL(y^{(i)}, z_{f_w}^{(i)}) &= - \\sum_{j=1}^{n^{(i)}} P_{y^{(i)}}(j) \\log P_{z^{(i)}}(j) \\\\\n&= - \\sum_{j=1}^{n^{(i)}} \\frac{\\exp(y_j^{(i)})}{\\sum_{k=1}^n \\exp(y_k^{(i)})} \\log \\frac{\\exp[f_w(x_j^{(i)})]}{\\sum_{k=1}^n \\exp[f_w(x_k^{(i)})]}\n\\end{align}\n$$\n\n\n使用随机梯度下降法, $L(y^{(i)}, z^{(i)})$ 对 $w$ 求偏导, 得到 $\\Delta w$:\n$$\n\\begin{align}\n\\Delta w &= \\frac{\\partial L(y^{(i)}, z_{f_w}^{(i)})}{\\partial w} \\\\\n&=- \\sum_{j=1}^{n^{(i)}} \\frac{\\exp(y_j^{(i)})}{\\sum_{k=1}^n \\exp(y_k^{(i)})} \\frac{\\partial f_w(x_j^{(i)})}{\\partial w} + \\frac{1}{\\sum_{j=1}^{n^{(i)}} \\exp[f_w(x_j^{(i)})]} \\cdot \\sum_{j=1}^{n^{(i)}} \\exp[f_w(x_j^{(i)})] \\frac {\\partial f_w(x_j^{(i)})}{\\partial w}\n\\end{align}\n$$\n\n使用随机梯度下降法优化求解ListNet模型的算法如下所示\n\n![](ListNet-model/listnet-alg.png)\n\n其时间复杂度 $O(m \\cdot n_{max})$.\n\n# 参考资料\n\nCao Z , Qin T , Liu T Y , et al. Learning to Rank: From Pairwise Approach to Listwise Approach[C]// International Conference on Machine Learning. ACM, 2007.\n\n[ListNet原理](https://x-algo.cn/index.php/2016/08/18/listnet-principle/)","tags":["IR"],"categories":["Model"]},{"title":"牛顿法","url":"%2Fblog%2FNewton-Methods.html","content":"\n# 原理\n\n牛顿法收敛速度快，每一步需要求解目标函数的海赛矩阵的逆矩阵，计算比较复杂，可通过拟牛顿法简化计算过程。\n\n因为牛顿法是通过泰勒展开推导出来的。\n\n先看泰勒展开：\n$$\nf(x)=f(x^{(k)})+\\frac {f′(x^{(k)})}{1!}(x−x^{(k)})+\\frac {f′′(x^{(k)})}{2!}(x−x^{(k)})^2+\\frac {f′′′(x^{(k)})}{3!}(x−x^{(k)})^3+ \\dots\n$$\n\n\n\n我们取右式的前3项：\n$$\nf(x)=f(x^{(k)})+\\frac {f′(x^{(k)})}{1!}(x−x^{(k)})+\\frac {f′′(x^{(k)})}{2!}(x−x^{(k)})^2\n$$\n\n如果 $x$ 是向量，则：\n\n$$\nf(x)=f(x^{(k)})+ g_k^T(x−x^{(k)})+\\frac 12 (x−x^{(k)})^T H(x^{(k)})(x−x^{(k)})\n$$\n此处: $g_k = g(x^{(k)}) = \\nabla f(x^{(k)})$ 为$f(x)$在 $x^{(k)}$ 处的梯度。$H(x^{(k)})$是$f(x)$的海塞矩阵(Hesse matrix) \n$$\nH(x) = [\\frac {\\partial^2f}{\\partial x_i \\partial x_j}]_{n \\times n}\n$$\n在点 $x^{(k)}$的值。\n\n函数$f(x)$有极值的必要条件是在极值点处一阶导数为0，即梯度向量为0。特别是当$H(x^{(k)})$为正定矩阵时，函数$f(x)$的极值为极小值。牛顿法利用极小点的必要条件 \n\n$$\n\\nabla f(x)=0\n$$\n\n每次迭代从点 $x^{(k)}$ 开始，求目标函数的极小点，作为第 $k+1$ 次迭代值$x^{(k+1)}$。具体地，假设$x^{(k+1)}$满足： \n\n$$\n\\nabla f(x^{(k+1)})=0\n$$\n\n三阶的泰勒展开式关于 $x$ 求导，得\n\n\n$$\n\\nabla f(x) = g_k + H(x^{(k)})(x−x^{(k)})\n$$\n\n当 $x = x^{(k+1)}$ 时：\n$$\n\\nabla f(x^{(k+1)}) = g_k + H(x^{(k)})(x^{(k+1)}−x^{(k)}) = 0\n$$\n\n此时：\n\n$$\nx^{(k+1)} \\gets x^{(k)} - \\frac {g_k}{H_k}\n$$\n\n## 牛顿法总结\n\n牛顿法：是通过求解目标函数的一阶导数为0时的参数，进而求出目标函数最小值时的参数。有点为：\n\n- 收敛速度很快。\n- 海森矩阵的逆在迭代过程中不断减小，可以起到逐步减小步长的效果。\n\n缺点：\n\n- 海森矩阵的逆计算复杂，代价比较大；\n- 只适用于Hessian矩阵是正定的情况：在深度学习中，目标函数的表面通常非凸的，此时Hessian矩阵不是正定的。如果Hessian矩阵的特征值并不都是正的，牛顿法实际上回导致更新朝错误方向移动。\n\nnote： Hessian矩阵不是是正定时 可以通过正则化Hessian矩阵来避免。常用的正则化策略包括在Hessian矩阵对角线上增加常数 $\\alpha$，即$H=H+\\alpha I$.\n\n## 梯度下降法和牛顿法的区别\n\n- 梯度下降法是一阶优化算法，牛顿法是二阶优化算法\n- 牛顿法的收敛速度相比梯度下降法常常较快\n- 牛顿法每次需要更新一个二维矩阵，计算代价很大，实际使用中常使用拟牛顿法\n- 牛顿法对初始值有一定要求，在非凸优化问题中（如神经网络训练），牛顿法很容易陷入鞍点（牛顿法步长会越来越小），而梯度下降法则很容易逃离鞍点（因此在神经网络训练中一般使用梯度下降法）\n- 梯度下降法在靠近最优点时会震荡，因此步长调整在梯度下降法中是必要的，具体有adagrad, adadelta, rmsprop, adam等一系列自适应学习率的方法\n\n\n\n\n\n# 参考资料\n\n[梯度下降法和(拟)牛顿法区别及介绍](https://blog.csdn.net/pupilxmk/article/details/80735599)","tags":["Optimization"],"categories":["Mathematics"]},{"title":"From RankNet to LambdaRank to LambdaMart An Overview阅读笔记","url":"%2Fblog%2FRankNet-LambdaRank-LambdaMart.html","content":"\n# LTR问题\n\n搜索引擎根据用户输入的Query检索得到最相关的topk个网页；推荐引擎根据用户的兴趣偏好推荐用户最感兴趣的topk个文章。涉及到topk的问题，都会涉及到排序的问题。LTR(Learning To Rank)是在处理排序问题时采用机器学习方法来训练模型的方法。可以将LTR方法分为  point-wise、pair-wise、list-wise 三类. 之前介绍的[Prank](https://weirping.github.io/blog/PRank.html) 算法属于point-wise. \n\n本文介绍的三个模型都属于 pair-wise.\n\n# RankNet\n\n|  符号   |       含义       |\n| :-----: | :--------------- |\n| $f(x:w)$ | RankNet 底层模型 |\n|$s_i$|$s=f(x)$|\n| $ U_i $ |     index i url     |\n| $U_i \\rhd U_j$ | 样本中 $ U_i $ 排在 $ U_j $ 前面 |\n|$P_{ij} = P(U_i \\rhd U_j)$|模型计算出的 $ U_i $ 排在 $ U_j $ 前面的概率|\n|$\\bar P_{ij}$|样本中 $ U_i $ 排在 $ U_j $ 前面的概率|\n| $C= C_{ij} = C(s_i, s_j) = C(s_i - s_j) $ | 损失函数 |\n| $I$ | $\\{i,j\\} \\in  I$ ，样本中所有 url pair对 |\n| $\\eta$ | 梯度下降中的步长 |\n\n\n\nRankNet像是一个框架，它将我们常用的那些模型赋予了LTR功能。比如回归模型不能学习到样本中rank信号，将其使用RankNet包装以后就可以学习到Rank信号。\n\n> For RankNet, the underlying model can be any model for which the output of the model is a differentiable function of the model parameters\n\n此处 underlying model 表示为 $f(x:w)$. 实际应用中这个模型可以是简单的回归模型，也可以是复杂的神经网络模型。(原论文中  $f(x:w)$是神经网络模型)\n\n对于一个$U_i$,  $f(x:w)$的算分结果为 :\n$$\ns_i = f(x:w) \\tag1\n$$\n\n下面介绍RankNet是怎么将一个普通的模型赋予LTR功能的。\n\n---\n\n\n令 $U_i \\rhd U_j$ 表似事件 $U_i$ 排序比 $U_j$ 更加靠前，则通过模型计算得到该事件的概率为：\n\n$$\nP_{ij} \\equiv P(U_i \\rhd U_j) \\equiv \\frac{1}{1+e^{-\\sigma(s_i - s_j)}} \\tag 2\n$$\n\n在训练样本的同一个query对应的所有url中，令：\n\n$$\nS_{ij} =\n\\left \\{\n\\begin {align}\n1; U_i \\rhd U_j \\\\\n0; U_i \\equiv U_j \\\\\n-1; U_i \\lhd U_j\n\\end {align}\n\\right . \\tag 3\n$$\n\n则样本中 $U_i \\rhd U_j$ 的概率可以表示为：\n\n$$\n\\bar P_{ij} = \\frac12(1 + S_{ij}) =\n\\left \\{\n\\begin {align}\n1; U_i \\rhd U_j \\\\\n\\frac12; U_i \\equiv U_j \\\\\n0; U_i \\lhd U_j\n\\end {align}\n\\right . \\tag 4\n$$\n\nRankNet的损失函数可以使用交叉熵得到：\n$$\nC(s_i - s_j)= - \\bar P_{ij} \\log P_{ij} - (1 - \\bar P_{ij}) \\log (1 - P_{ij}) \\tag 5\n$$\n\n此时：\n\n$$\n\\frac{\\partial C(s_i - s_j)}{\\partial s_{i}} = \\sigma (\\frac12 (1-S_{ij}) - \\frac{1}{1+e^{\\sigma(s_i - s_j)}}) = - \\frac{\\partial C(s_i - s_j)}{\\partial s_{j}} \\tag 6\n$$\n\n使用stochastic gradient descent更新 $w_k$ 的迭代公式\n\n$$\nw_k \\rightarrow w_k - \\eta \\frac{\\partial C_{ij}}{\\partial{w_k}} = w_k - \\eta (\\frac{\\partial C_{ij}}{\\partial s_i} \\frac{\\partial s_i}{\\partial{w_k}} + \\frac{\\partial C_{ij}}{\\partial s_j} \\frac{\\partial s_j}{\\partial{w_k}}) \\tag 7\n$$\n\n\n\n$$\n\\delta C = \\sum_k \\frac{\\partial C}{\\partial{w_k}} \\delta w_k =\\sum_k \\frac{\\partial C}{\\partial{w_k}} (-\\eta \\frac{\\partial C}{\\partial{w_k}}) = -\\eta \\sum_k (\\frac{\\partial C}{\\partial{w_k}})^2 \\lt 0  \\tag 8\n$$\n\n\n\n## Speeding Up Ranknet Training\n\n使用上述方法更新权重 $w$ 是相当慢的, 其时间复杂度为$O(n^2)$ (n为一个query下doc的数量). 下面介绍一种方式使时间复杂度降到 $O(n)$ .\n\n对 (7) 中的梯度 $\\frac{\\partial C_{ij}}{\\partial{w_k}}$ 进行分解:\n\n$$\n\\begin {align}\n\\frac{\\partial C(s_i - s_j)}{\\partial{w_k}} &= \\frac{\\partial C(s_i - s_j)}{\\partial s_i} \\frac{\\partial s_i}{\\partial{w_k}} + \\frac{\\partial C(s_i - s_j)}{\\partial s_j} \\frac{\\partial s_j}{\\partial{w_k}} \\\\\n&= \\sigma (\\frac12 (1-S_{ij}) - \\frac{1}{1+e^{\\sigma(s_i - s_j)}})(\\frac{\\partial s_i}{\\partial{w_k}} - \\frac{\\partial s_j}{\\partial{w_k}}) \\\\\n&= \\lambda_{ij}(\\frac{\\partial s_i}{\\partial{w_k}} - \\frac{\\partial s_j}{\\partial{w_k}})\n\\end {align} \\tag 9\n$$\n\n此处令\n$$\n\\lambda_{ij} = \\frac{\\partial C(s_i - s_j)}{\\partial s_{i}}  = - \\frac{\\partial C(s_i - s_j)}{\\partial s_{j}} = \\sigma (\\frac12 (1-S_{ij}) - \\frac{1}{1+e^{\\sigma(s_i - s_j)}}) \\tag {10}\n$$\n可以将(9)看做三部分:\n\n1. $\\frac{\\partial C}{\\partial{w_k}}$ : 损失函数在模型$f(x)$参数 $w_k$ 方向上梯度的分量。\n2. $(\\frac{\\partial s_i}{\\partial{w_k}} - \\frac{\\partial s_j}{\\partial{w_k}})$: 只与模型 $f(x)$ 有关。即打分模型部分\n3. $\\lambda_{ij}$:  只与 排序功能有关。 所以 $\\lambda_{ij}$ 是与排序有关的部分。可以理解为：模型经过 $U_i, U_j$ 这一url对训练后 模型参数 $w_k$ 的更新大小的度量，使样本$U_i, U_j$ 的预测排序更加贴近样本排序。\n\n定义 $I$ 为同一query下，所有的url对的index的集合， 并且任何一个url对只能在 $I$ 中出现过一次。即，$U_i \\rhd U_j$ 且$\\{i,j\\} \\in I$。例如：有三个url，其相关性满足 $U_1 \\rhd U_2 \\rhd U_3$，那么集合$I$中就包含{(1,2), (1,3), (2,3)}共三个pair。\n\n在集合 $I$ 中的所有url对都满足 $U_i \\rhd U_j$ ，$S_{ij} = 1, \\bar P_{ij}=1$。 损失函数变为：\n$$\nC(s_i - s_j)= - \\log P_{ij} = -\\log \\frac{1}{1+e^{-\\sigma(s_i - s_j)}}\n$$\n$\\lambda_{ij}$ 变为：\n$$\n\\begin {align}\n\\lambda_{ij} = \\frac{\\partial C(s_i - s_j)}{\\partial s_{i}} &= \\sigma (- \\frac{1}{1+e^{\\sigma(s_i - s_j)}})\\\\\n&= - \\frac{\\sigma}{1+e^{\\sigma(s_i - s_j)}}\n\\end {align}  \\tag {11}\n$$\n\n\n可以对 $\\lambda$ 进一步变化。考察一个query下的 $U_i$， 分为两部分: 所有排在$U_i$后面的 url 的集合 $I_{i-}$;  所有排在$U_i$前面的 url 的集合 $I_{-i}$; 可以定义与 $U_i$ 有关的 $\\lambda_i$ :\n$$\n\\lambda_i = \\sum_{m\\in I_{i-}} \\lambda_{im} - \\sum_{n \\in I_{-i}}\\lambda_{ni}  \\tag {12}\n$$\n\n> To compute $\\lambda_i$ (for url $U_i$), we find all $m$ for which $\\{i, m\\} \\in I$ and all $n$ for which $\\{n, i\\} \\in I$ . For the former, we increment $\\lambda_i$ by $\\lambda_{i m}$  , and for the latter, we decrement $\\lambda_i$ by $\\lambda_{ni}$ . For example, if there were just one pair with  $U1 \\rhd  U2$ , then $I = \\{\\{1, 2\\}\\}$ , and $\\lambda_1 = \\lambda_{12} = −\\lambda_2$ .\n\n上面介绍了准备知识, 线面进入正题.\n\n我们采用 mini-batch的方式更新 $w_k$ .其中每一个 batch 的训练数据为一个query下所有url对，即 $\\{i,j\\} \\in I$ 。\n$$\n\\begin {align}\nw_k &\\rightarrow w_k - \\eta \\sum_{\\{i,j\\} \\in I} \\frac{\\partial C}{\\partial{w_k}} \\\\\n&= w_k - \\eta \\sum_{\\{i,j\\} \\in I} (\\frac{\\partial C}{\\partial s_i} \\frac{\\partial s_i}{\\partial{w_k}} + \\frac{\\partial C}{\\partial s_j} \\frac{\\partial s_j}{\\partial{w_k}}) \\\\\n&= w_k - \\eta \\sum_{\\{i,j\\} \\in I} \\lambda_{ij}(\\frac{\\partial s_i}{\\partial{w_k}} - \\frac{\\partial s_j}{\\partial{w_k}}) \\\\\n&\\equiv w_k - \\eta \\sum_i \\lambda_i \\frac{\\partial s_i}{\\partial{w_k}}\n\\end {align} \\tag {13}\n$$\n其中 $\\lambda_i$ 可以由公式 (1), (11) 和 (12) 计算得到.\n\n下面举例说明 $\\sum_{\\{i,j\\} \\in I} \\lambda_{ij}(\\frac{\\partial s_i}{\\partial{w_k}} - \\frac{\\partial s_j}{\\partial{w_k}}) \\equiv \\sum_i \\lambda_i \\frac{\\partial s_i}{\\partial{w_k}}$ 。\n\n例如有三个url，其相关性满足 $U_1 \\rhd U_2 \\rhd U_3$，那么集合$I$中就包含{(1,2), (1,3), (2,3)}共三个pair。此时：\n$$\n\\begin {align}\n\\sum_{\\{i,j\\} \\in I} \\lambda_{ij}(\\frac{\\partial s_i}{\\partial{w_k}} - \\frac{\\partial s_j}{\\partial{w_k}}) &= \\lambda_{12}(\\frac{\\partial s_1}{\\partial{w_k}} - \\frac{\\partial s_2}{\\partial{w_k}}) + \\lambda_{13}(\\frac{\\partial s_1}{\\partial{w_k}} - \\frac{\\partial s_3}{\\partial{w_k}}) + \\lambda_{23}(\\frac{\\partial s_2}{\\partial{w_k}} - \\frac{\\partial s_3}{\\partial{w_k}}) \\\\\n&=(\\lambda_{12}+\\lambda_{13})\\frac{\\partial s_1}{\\partial{w_k}}+(\\lambda_{23} -\\lambda_{12})\\frac{\\partial s_2}{\\partial{w_k}}+(-\\lambda_{13} -\\lambda_{23})\\frac{\\partial s_3}{\\partial{w_k}} \\\\\n&=\\lambda_{1}\\frac{\\partial s_1}{\\partial{w_k}} + \\lambda_{2}\\frac{\\partial s_2}{\\partial{w_k}} + \\lambda_{3}\\frac{\\partial s_3}{\\partial{w_k}} \\\\\n&= \\sum_i \\lambda_i \\frac{\\partial s_i}{\\partial{w_k}}\n\\end {align}\n$$\n(13)式 中 $\\delta w_k = \\eta \\sum_i \\lambda_i \\frac{\\partial s_i}{\\partial{w_k}}$ 可以 分为两部分理解：\n\n- $\\lambda_i $ : 与排序有关的部分。$\\lambda_i$ 决定着第 $i$ 个doc在迭代中的移动方向和幅度，样本中的排在 $U_i$ 前面的doc越少，排在 $U_i$ 后面的doc越多，那么文档 $U_i$ 向前移动的幅度就越大。结合式(12)的定义可以发现 **每条文档移动的方向和趋势取决于其他所有与之 label 不同的文档。**\n\n  > The arrows ($\\lambda$’s) mentioned above are exactly those gradients. The $\\lambda$’s for a given URL $U_1$ get contributions from all other URLs for the same query that have different labels. The $\\lambda$ ’s can also be interpreted as forces : if $U_2$ is more relevant than $U_1$, then $U_1$ will get a push downwards of size $|\\lambda |$ ; if $U_2$ is less relevant than $U_1$, then $U_1$ will get a push upwards of size $| \\lambda |$.\n- $\\frac{\\partial s_i}{\\partial{w_k}}$ : 与模型 $f(x:w)$有关的部分。\n\n(13)式 这样的$w_k$的迭代方式相当于是mini-batch learning。可以加速RankNet的学习过程。通过Stochastic gradient descent计算的时候，是对每一个pair对都会进行一次权重的更新。现在的mini-batch learning的方式，是对同一个query下的所有doc进行一次权重的更新。时间消耗从$O(n^2)$降到了$O(n)$。(n为一个query下doc的数量)。原始的RankNet算法使用神经网络进行模型训练，每次权重的更新迭代都需要先进行前向预测，再进行误差的后向传播，将每个url pair 更新一次$w_k$改为每query 更新一次，将减少前项和后向传播计算的次数，进而减少模型训练时间。\n\n \n\n# LambdaRank\n\n上面我们介绍了以**错误 URL 对最少**为优化目标的RankNet算法，然而许多时候仅以错误pair数来评价排序的好坏是不够的。在搜索场景下，我们更关心的是[搜索结果的质量指标](https://weirping.github.io/blog/Metrics-in-IR.html)，如 NDCG, ERR 等。即，在搜索场景下我们更关心top K 个结果的相关性能不能满足用户需求，越相关的结果排的越靠前越好。\n\n而RankNet是以错误的URL对的数量为优化目标的，所以RankNet的优化目标和IR评价指标之间还是存在gap的。\n\n![](RankNet-LambdaRank-LambdaMart/RankNet-LambdaRank.png)\n\n如上图所示，每条横线条表示一个doc，蓝色表示相关doc，灰色表示不相关doc，RankNet以pairwise error的方式计算cost，左图的cost为13。通过迭代$w$后, 把第一个 doc 下调3个位置，第二个相关doc上移 5个位置，此时 cost 为11。在实际情况下，左边的效果比右边的更好，因为左边的第一个就是相关文档。即，以NDCG或者ERR等评价指标时，在优化过程中下调前面相关doc的位置反而使NDCG/ERR向更差的方向变化。\n\n如上图左边所示，在下一次迭代时，黑色的箭头表示RankNet对两个相关结果的调序方向和强度。但是按照NDCG等IR评价指标，我们更关注靠前位置的相关文档的排序位置的提升，即 红色箭头所示的方向和强度。\n\nLambdaRank正是基于这个思想演化而来，其中Lambda指的就是红色箭头，代表下一次迭代优化的方向和强度，也就是梯度。\n\n需要指出的是：LambdaRank是一个经验算法，它不是通过定义显示的损失函数然后求梯度的方式推导而来，而是分析排序问题需要的梯度的**物理意义**，直接定义梯度，即Lambda梯度。但是这并不意味着此时的梯度不是损失函数的的梯度，  实际上是存在一个 implict 损失函数。\n\nLambdaRank在RankNet的加速算法形式变化而来。即把 (11)式 右边乘以 $|\\Delta NDCG|$ \n$$\n\\begin {align}\n\\lambda_{ij} = \\frac{\\partial C(s_i - s_j)}{\\partial s_{i}} = - \\frac{\\sigma}{1+e^{\\sigma(s_i - s_j)}} |\\Delta Z_{ij}|\n\\end {align} \\tag{14}\n$$\n其中 $|\\Delta Z_{ij}|$  表示把$U_i$ 和 $U_j$ 的位置交换后引起的评价指标的变化， 如 $|\\Delta NDCG|$ 和 $|\\Delta ERR|$ 等\n\n损失函数的梯度代表了文档下一次迭代优化的方向和强度. 由于引入了IR评价指标，Lambda梯度更关注位置靠前的相关doc, 避免了下调靠前的相关doc。LambdaRank相比RankNet的优势在于 使用mini-batch 加快模型训练，同时考虑了评价指标，直接对问题求解，效果更明显。\n\n# LambdaMart\n\nMart即GBDT，参考 [GBDT](https://weirping.github.io/blog/GBDT.html), 和 [xgboost](https://weirping.github.io/blog/xgboost.html) 两篇文章。\n\n- LambdaRank重新定义了梯度，赋予了梯度新的物理意义, 因此，所有可以使用梯度下降法求解的模型都可以使用这个梯度.\n\n- MART 模型结果由许多棵树组成，每棵树拟合的目标是损失函数的梯度。\n\n将梯度Lambda和MART结合就是大名鼎鼎的LambdaMART。**在LambdaMART中每棵树拟合的目标换成了Lambda.**  \n\n算法如下:\n\n![](RankNet-LambdaRank-LambdaMart/LambdaMART.png)\n\n可以看出LambdaMART的框架其实就是MART，主要的创新在于中间计算的梯度使用的是Lambda，是pairwise的。\n\n下面简单介绍LambdaMART每一步的工作：\n\n​         1)  每棵树的训练会先遍历所有的训练数据（label不同的文档pair），计算每个pair互换位置导致的指标变化$\\Delta Z_{ij}$以及Lambda，即 $\\lambda_{ij} = \\frac{\\partial C(s_i - s_j)}{\\partial s_{i}} = - \\frac{\\sigma}{1+e^{\\sigma(s_i - s_j)}} |\\Delta Z_{ij}|$ ，然后计算每个文档的Lambda：$\\lambda_i = \\sum_{m \\in I_{i-}} \\lambda_{im} - \\sum_{n \\in I_{-i}}\\lambda_{in}$ ，再计算每个 $\\lambda_i$ 的导数$w_i$，用于后面的Newton step求解叶子节点的数值。(此处Mart使用的是牛顿法求解的, 可以参考 [xgboost](https://weirping.github.io/blog/xgboost.html) )\n\n​         2)  创建回归树拟合第一步生成的 $\\lambda_i$，划分树节点的标准是Mean Square Error，生成一颗叶子节点数为L的回归树。\n\n​         3)  对第二步生成的回归树，计算每个叶子节点的数值，采用Newton step求解，即对落入该叶子节点的文档集，用公式 $\\gamma_{lm} = \\frac{\\sum_{x_i \\in R_{lm}} \\lambda_i}{\\sum_{x_i \\in R_{lm}} w_i}$  计算该叶子节点的输出值。\n\n​         4)  更新模型，将当前学习到的回归树加入到已有的模型中，学习率取$v$\n\n​         LambdaMART具有很多优势：\n\n​         1)  适用于排序场景：不是传统的通过分类或者回归的方法求解排序问题，而是直接求解\n\n​         2)  损失函数可导：通过损失函数的转换，将类似于NDCG这种无法求导的IR评价指标转换成可以求导的函数，并且赋予了梯度的实际物理意义，数学解释非常漂亮\n\n​         3)  增量学习：由于每次训练可以在已有的模型上继续训练，因此适合于增量学习\n\n​         4)  组合特征：因为采用树模型，因此可以学到不同特征组合情况\n\n​         5)  特征选择：因为是基于MART模型，因此也具有MART的优势，可以学到每个特征的重要性，可以做特征选择\n\n​         6)  适用于正负样本比例失衡的数据：因为模型的训练对象具有不同label的文档pair，而不是预测每个文档的label，因此对正负样本比例失衡不敏感\n\n# 参考资料\n\nBurges, C. J. C. (2010). From RankNet to LambdaRank to LambdaMART: An Overview. Msr-Tr-2010-82, 41(4), 574–581.\n\nBurges C , et al. Learning to rank using gradient descent[C] International Conference on Machine Learning. ACM, 2005:89-96.\n\nLi H . Learning to Rank for Information Retrieval and Natural Language Processing[M]. Morgan & Claypool Publishers, 2011.\n\nQ. Wu, C.J.C. Burges, K. Svore and J. Gao. Adapting Boosting for Information Retrieval Measures. Journal of Information Retrieval, 2007.\n\n[Learning to Rank算法介绍：RankNet，LambdaRank，LambdaMart](https://www.cnblogs.com/bentuwuying/p/6690836.html)\n\n","tags":["IR"],"categories":["Model"]},{"title":"tensorflow datasets","url":"%2Fblog%2Ftensorflow-datasets.html","content":"\n\n\n为了方便大家学习， tensorflow自身提供了多种数据集，并且将这些数据集进行了封装，方便我们直接使用。它使用 `tensorflow-datasets` 这个module封装了我们常用的各种公共数据集，在进行模型的学习过程中可以直接用该模块加载我们需要的数据集进行训练，挺方便的。本文介绍该模块的简单使用。\n\n# 安装\n\n```shell\npip install tensorflow-datasets\n```\n\n\n\n# 使用\n\n```python\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n```\n\n# 查看可用数据集\n\n`tensorflow-datasets` 提供了我们常用的数据集，可以通过下面的命令查看有哪些可用的数据集.\n\n```python\ntfds.list_builders()\n# 目前我这里可以的数据集如下\n# ['bair_robot_pushing_small', 'cats_vs_dogs', 'celeb_a', 'celeb_a_hq', 'cifar10', 'cifar100', 'coco2014', 'diabetic_retinopathy_detection', 'dummy_dataset_shared_generator', 'dummy_mnist', 'fashion_mnist', 'image_label_folder', 'imagenet2012', 'imdb_reviews', 'lm1b', 'lsun', 'mnist', 'moving_mnist', 'nsynth', 'omniglot', 'open_images_v4', 'quickdraw_bitmap', 'squad', 'starcraft_video', 'svhn_cropped', 'tf_flowers', 'wmt_translate_ende', 'wmt_translate_enfr']\n```\n\n# 了解数据集\n\n确定了可用数据集以后我们可以选择一个来使用， 首先需要了解一下这个数据集的基本信息。下面以 mnist为例。\n\n```python\nmnist_builder = tfds.builder(\"mnist\")\nmnist_builder.download_and_prepare()  # 下载数据集\ninfo = mnist_builder.info\nprint(info)\n\n# tfds.core.DatasetInfo(\n#     name='mnist',\n#     version=1.0.0,\n#     description='The MNIST database of handwritten digits.',\n#     urls=['http://yann.lecun.com/exdb/mnist/'],\n#     features=FeaturesDict({\n#         'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n#         'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10)\n#     },  \n#     total_num_examples=70000,\n#     splits={\n#         'test': <tfds.core.SplitInfo num_examples=10000>,\n#         'train': <tfds.core.SplitInfo num_examples=60000>\n#     },  \n#     supervised_keys=('image', 'label'),\n#     citation='\"\"\"\n#         @article{lecun2010mnist,\n#           title={MNIST handwritten digit database},\n#           author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n#           journal={ATT Labs [Online]. Available: http://yann. lecun. com/exdb/mnist},\n#           volume={2},\n#           year={2010}\n#         } \n#\n#     \"\"\"',\n# )\n```\n\n通过该信息我们可以知道 数据集共有 70000条数据，分为训练集60000和测试集10000； 没条数据包含 'image', 'label' 两部分。 label 包含10个类别 等重要信息。\n\n同时在代码里我们可以直接调用这些信息\n\n```python\nprint(info.features)\nprint(info.features[\"label\"].num_classes)\nprint(info.features[\"label\"].names)\n\n# FeaturesDict({'image': Image(shape=(28, 28, 1), dtype=tf.uint8), 'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10)})\n# 10\n# ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n\n```\n\n# 使用数据集\n\n使用mnist_builder 的as_dataset 函数即可获取我们的数据，其定义如下：\n\n```python\ndef as_dataset(self,\n               split=None,\n               batch_size=1,\n               shuffle_files=None,\n               as_supervised=False):\n    \"\"\"Constructs a `tf.data.Dataset`.\n\n      Callers must pass arguments as keyword arguments.\n\n      Args:\n        split: `tfds.core.SplitBase`, which subset(s) of the data to read. If None\n          (default), returns all splits in a dict\n          `<key: tfds.Split, value: tf.data.Dataset>`.\n        batch_size: `int`, batch size. Note that variable-length features will\n          be 0-padded if `batch_size > 1`. Users that want more custom behavior\n          should use `batch_size=1` and use the `tf.data` API to construct a\n          custom pipeline. If `batch_size == -1`, will return feature\n          dictionaries of the whole dataset with `tf.Tensor`s instead of a\n          `tf.data.Dataset`.\n        shuffle_files: `bool`, whether to shuffle the input files.\n          Defaults to `True` if `split == tfds.Split.TRAIN` and `False` otherwise.\n        as_supervised: `bool`, if `True`, the returned `tf.data.Dataset`\n          will have a 2-tuple structure `(input, label)` according to\n          `builder.info.supervised_keys`. If `False`, the default,\n          the returned `tf.data.Dataset` will have a dictionary with all the\n          features.\n\n      Returns:\n        `tf.data.Dataset`, or if `split=None`, `dict<key: tfds.Split, value:\n        tfds.data.Dataset>`.\n\n        If `batch_size` is -1, will return feature dictionaries containing\n        the entire dataset in `tf.Tensor`s instead of a `tf.data.Dataset`.\n      \"\"\"\n\n```\n\n举例： \n\n```python\n# get dataset\nmnist_train = mnist_builder.as_dataset(split=tfds.Split.TRAIN)\nmnist_test = mnist_builder.as_dataset(split=tfds.Split.TEST)\nprint(mnist_train)\nprint(mnist_test)\n\n# <DatasetV1Adapter shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>\n# <DatasetV1Adapter shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>\n```\n\n获得 tf.data.Dataset 对象 (mnist_train 和 mnist_test 都是的) 以后我们就可以使用 [`tf.data` API](https://www.tensorflow.org/guide/datasets) 提供的api来操作数据集用于模型驯良了\n\ntensorflow-datasets 对于数据的使用提供了更高级的封装 `load` 函数， 如下所示\n\n```python\nmnist_train = tfds.load(name=\"mnist\", split=tfds.Split.TRAIN)\nassert isinstance(mnist_train, tf.data.Dataset)\nprint(mnist_train)\n\n# 下载数据\n#  <DatasetV1Adapter shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>\n```\n\n\n\n# 参考\n\n[https://www.tensorflow.org/datasets/overview](https://www.tensorflow.org/datasets/overview)\n\napi 接口 [https://www.tensorflow.org/datasets/api_docs/python/](https://www.tensorflow.org/datasets/api_docs/python/)","tags":["Tensorflow"],"categories":["Toolkit"]},{"title":"相关性打分公式","url":"%2Fblog%2Fnote-of-relevence-socres.html","content":"\n\n\n# BM25\n\nBM25算法是一种常见用来做相关度打分的公式，思路比较简单，主要就是计算一个query里面所有term和文档的相关度，然后在把分数做累加操作,而每个词的相关度分数主要还是受到tf/idf的影响。公式如下：\n$$\nscore(Q, d) = \\sum_{t \\in Q} W_t R(t, d)\n$$\n其中：$R(t,d)$是每个词和文档的相关度值；$t$代表query中的term；$d$代表相关的文档；$W_t$是词$t$的权重。 \n\n$W_t$可由外部设置，默认是$idf$值，idf公式的基本思想是：词的重要程度和其出现在总文档集合里的频率成反比。其公式如下: \n$$\nIDF(t) = \\log \\frac{N-n(t) + 0.5}{n(t) + 0.5}\n$$\n其中：$N$是文档总数；$n(t)$是包含该词的文档数；0.5是调教系数，避免$n(t)$为0的情况。取个log是为了让idf的值受N和$n(t)$的影响更加平滑。\n\n从这个公式可以看出当$N$越大，$n(ti)$越小时$idf$值越大，\n\n下面是$R(t,d)$的公式，\n$$\n\\begin {align}\n& R(t, d) = \\frac{tf(t)(k_1 + 1)}{tf(t) + K(d)}   \\frac{qf(t)(k_2 + 1)}{qf(t) + k_2} \\\\\n\\\\\n& K(d) = k_1(1-b + b \\frac{dl}{avgdl})\n\\end {align}\n$$\n其中: $k_1$，$k_2$，$b$都是调节因子，一般$k1=2$，$k2=1$，$b=0.75$； $tf(t)$是词$t$在文档中的次数，$qf(t)$代表词在查询句里的次数；$dl$是文档长度，$avgdl$是文档平均长度；\n\n可以看出如果其他因素一样$dl$越大，相关度越低；至于除以一个$avgdl$，我想是拿本篇文档长度和整体文档长度水平做比较 ，以免单独取$dl$值时过大。\n\n乘积的左边因数代表词在文档中的次数关系，乘积的右边因数代表词在查询语句中的次数关系。绝大多数情况下，查询词在查询语句里面出现一次，所以$qf(t)$可以看成是1，又因为$k_2$为1，所以右边因数其实就等于1，所以公式可化简为下面这样:\n$$\nR(q_i, d) = \\frac{tf(t)(k_1 + 1)}{tf(t) + K}\n$$\n公式化简后可得:\n$$\nscore(Q, d) = \\sum_{t \\in Q} IDF(t) \\frac{tf(t)(k_1 + 1)}{tf(t) + k_1(1-b + b \\frac{dl}{avgdl})}   \\\\\n$$\n影响BM25公式的因数有\n\n1 $idf$：  $idf$越高分数越高\n\n2 $tf$：  $tf$越高分数越高\n\n3 $dl/avgdl$ ： 如果该文档长度在文档水平中越高则分数越低。\n\n4 $k_1, k_2, b$为分数的调节因子\n\n\n\n# BM25F(2004)\n\n一般情况下，一篇文章是分为多个部分的，如 title，content，description，anchor 等，在BM25F算分公式中，这些部分被称为域(field)。有两篇文章，一篇文章的title部分与query 的BM25相关性得分为 a， 另一篇文章的content部分与query 的BM25相关性得分也为 a。假设不考虑这两篇文章其他部分与query的相关性情况，根据经验，一般第一篇文章应该应该比第一篇文章更相关。BM25F 引入了文章d的每个域的信息，它将每个term在文章d中的每个域中的相关性进行了处理。公式如下：\n$$\n\\begin {align}\n& score(Q, d) = \\sum_{t \\in Q} IDF(t) \\frac{w(t,d)}{k_1 + w(t,d)}   \\\\\n\\\\\n& w(t,d) = \\sum_{f \\in d} \\frac{tf(t,f,d) \\times boost_f}{1-b_f + b_f \\frac{len(f, d)}{avglen(f)}}\n\\end {align}\n$$\n\n#  \n\n# OkaTP(2003)\n\nBM25 被也称为 **Okapi BM25**,  OkaTP是BM25与 term proximity 融合的相关性计算公式。\n\nquery中第 $i$ 个term的权重定义为：\n\n$$\nqw_i = \\frac{qtf_i}{k_3+qtf_i} \\cdot \\log \\frac{N-DF_i}{DF_i}\n$$\n\n- $N$ is the sum of documents within all collections,\n- $DF_i$  is the number of documents containing the term $t_i$ within all collections.\n- $qtf_i $query term frequency.\n\n可以发现 $qw_i$ 的定义在形式上比较像BM25中 query部分与IDF 的乘积。 区别是常量参数的设置。在论文中设置 $k_3 = 1000$.\n\nterm proximity 定义如下\n\n$$\n\\mathrm {tpi(t_i, t_j)} = \\frac {1.0}{dist[t_i, t_j] ^2}\n$$\n$d(t_i, t_j)$ is the distance expressed in number of words between search term $t_i$ and $t_j$.\n\n下式体现了BM25与 term proximity 的融合， 该算法将BM25中的tf 替换成了 $\\sum_{occ(t_i, t_j)}tpi(t_i, t_j)$\n$$\nw_d(t_i, t_j) = (k_1 +1) \\frac{\\sum_{occ(t_i, t_j)}tpi(t_i, t_j)}{K+ \\sum_{occ(t_i, t_j)}tpi(t_i, t_j)}\n$$\n\n$K$ 的定义和BM25相同。\n\nOkaTP 最终定义为\n$$\nOkaTP(q,d) = BM25(q,d) + \\sum_{(t_i, t_j) \\in S}\\min\\{qw_i, qw_j\\} \\cdot w_d(t_i, t_j)\n$$\n其中 S是 query中所有term 两两组合的集合。\n\n\n\n# BM25TP(2006)\n\n该算法与 OkaTP 非常相似。\n\n其中TP即 term proximity，在该算法中引入了proximity 信息来优化相关性计算效果。\n\n假设一个query q中包含n个term $\\{t_1, \\dots, t_n \\}$， $d$ 表示一篇文章，任意两个不同term $t_j, t_k$  在文章 $d$ 中所处位置的距离表示为 $dist(t_j, t_k)$。这两个term的\n$$\n\\begin {align}\n& BM25TP(q, d) = BM25(q，d) + \\sum_i^n \\min\\{1, W_{t_i}\\} \\cdot \\frac{acc_d (t_i) \\cdot (k_1 + 1)}{acc_d (t_i) + K} \\\\\n\\\\\n& acc_d (t_i) = \\sum_{i \\neq j} W_{t_i} \\cdot \\mathrm{tpi}_d(t_i, t_j) \\\\\n\\\\\n& \\mathrm {tpi}_d = \\sum_{ o(t_i) \\in \\mathrm {occurrences\\ of\\ t_i\\ in\\ document\\ d}} \\frac {1}{dist[o(t_i), t_j] ^2}\n\\end {align}\n$$\nnote: query中的第 $i$ 个term可能在 document 可能出现多次， 每一次出现用 $o(t_i)$ 表示。\n\n原始论文见 Term proximity scoring for ad-hoc retrieval on very large text collections\n可以结合文章 Selective Term Proximity Scoring Via BP-ANN 理解上面第2，3两个公式。\n\n# newTP(2008)\n\n文章认为OkaTP存在两个方面的问题 1. OkaTP 算分公式的后面部分(可以看做对于prase的算分)和前面的BM25部分是有重叠的，即一个term会同时出现在前后两个部分； 2.Linear combination of scores of  unigrams  and  those of loose phrases may break the non-linear property of term frequency。\n\n基于这两点提出了 newTP算法。 newTP中引入了 span的概念。 span 是根据query term在一个docment中的命中位置，将整个命中列表分割为多个片段，每个片段称为一个 expanded span。 span 的确定规则如下。\n\n> (1)  The distance between the current and the next is bigger  than a threshold MAX_DIS, then the chain is separated between these two hits;\n> (2)  The current and the next hit are identical, then the chain is separated between these two hits;\n> (3)  The next hit is identical to a hit with former continuous sub-chain, then the distance between the current and the next  and  the  distance  between  the  identical  hit  and  its next  is  compared,  the  chain  is  separated  at  the  bigger gap. \n> (4)  Otherwise, go on scanning the next hit.\n\n其中 MAX_DIS 是认为设定的。\n\n根据span的中 query term的密度和数量来确定一个term对于相关性的贡献。从而取代OkaTP 中的 tpi 和 tf部分。\n\n一个$span_i$ 中的term t的 对于相关性的贡献表示为:\n$$\nf(t, espan_i) = [\\frac {n_i}{width(espan_i)}]^x \\cdot (n_i)^y\n$$\n其中:\n\n> - t is a query term,\n> - espan_i is an expanded span that contains t,\n> - n_i is the number of query terms that occur in espan_i\n> - Width(espan_i) is the width of espan_i\n> - x is an exponent that is used  to  restrain  that  the  value  decayed too rapidly with the density of an expanded span increasing,\n> - y is  an  exponent  that  is  used  to  prompting  the  case  that  more unique query terms appear in one expanded span.\n\n\n\n一个term t 在整个document 中对相关性的贡献为:\n$$\nrc_t = \\sum_i f(t, espan_i)\n$$\n可以看出 rc 中包含了 proximity的信息 和 tf的信息。\n\n直接用 rc 替换 BM25 中的 tf， 得到新的相关性计算公式:\n$$\nnewTP = \\sum_{t \\in Q} w_t \\cdot \\frac{rc_t(k_1 + 1)}{rc_t + K}\n$$\n\n# BM25TOP(2012)\n\n其中TOP即 term order proximity.  该算法是在BM25TP的基础上进行的优化。在该算法中引入了 term oder信息， 如果两个term在 query中出现的顺序 与 其在document中的顺序相反则进行惩罚， 如果顺序相同则 reward。\n\n在BM25TP算法中 使用的 $dist[o(t_i), t_j] ^2$ 来计算proximity， 但是这个公式对于term oder是不敏感的。就会认为 John is faster than Mary 和 Mary is faster than John 两个句子是相同的。\n\n为了说明 BM25TOP算法，先引入如下两个定义。\n\n$p_{t_i;Q}$: The position of $t_i$ in query Q\n$p_{t_i;d}$: The position of $t_i$ in document d\n\n\n\n在BM25TOP 中使用了一个新的公式对 $dist[o(t_i), t_j] ^2$ 进行了替换。这个公式应该符合如下三个条件。\n\n- always positive, regardless of $p_{t_x ;d} -  p_{t_y ;d} > 0$ or $p_{t_x ;d} -  p_{t_y ;d} < 0$; \n- rewards term proximity; becoming higher as $p_{t_x ;d} -  p_{t_y ;d}$ increases and vice versa; (since the score is inversely proportional to this quantity).\n- rewards correct term ordering, becoming higher in case of $p_{t_x ;d} -  p_{t_y ;d} < 0$ and vice versa; \n\n满足前两条是BM25TP算法中dist 函数也能满足的，第三条是增加考虑 term order 的一项。\n\n满足以上三个条件的公式挺多，论文中选择了如下公式。\n$$\n\\begin {align}\n& \\phi_d(t_x, t_y) = [a_d(t_x, t_y)]^2 - a_d(t_x, t_y) +1 \\\\\n\\\\\n & a_d(t_x, t_y) = \\frac{(p_{t_x ;d} -  p_{t_y ;d}) }{\\xi(t_x, t_y)} \\\\\n\\end {align}\n$$\n其中\n$$\n\\xi(t_x, t_y) = \\left\\{\n \\begin {align}\n 1,  & p_{t_x ;Q} -  p_{t_y ;Q} > 0 \\\\\n -1, & p_{t_x ;Q} -  p_{t_y ;Q} < 0 \\\\\n \\end {align}\n \\right .\n$$\n$\\phi_d(t_x, t_y)$ 的大小表示 $t_x$ 和 $t_y$ 在文档 d 中 的相对距离，符号说明了这两个term在query和document中的顺序是否相同，正号(+) 表示顺序相同，符号(-) 表示这两个term在query和document中的顺序相反。\n\n$ \\phi_d(t_x, t_y)$ 随 $a_d(t_x, t_y)$ 的函数变化图像如下:\n\n![](note-of-relevence-socres/bm25top-phi.png)\n\nnote:  proximity 是 $\\phi_d(t_x, t_y)$ 的倒数，  $\\phi_d(t_x, t_y)$ 值越大 proximity 越小。\n\n从上图可以看出，两个term距离越远， $\\phi_d(t_x, t_y)$ 越大， proximity 越小；\n\n当对于两对term的 $a_d$ 的大小相等，但符号相反时，符号为负(-) 的一对 term 的proximity会更小。\n\n下面将BM25TOP的计算公正整理如下：\n$$\n\\begin {align}\n& BM25TOP(q, d) = BM25(q，d) + \\sum_i^n \\min\\{1, W_{t_i}\\} \\cdot \\frac{acc_d^\" (t_i) \\cdot (k_1 + 1)}{acc_d^\" (t_i) + K} \\\\\n\\\\\n& acc_d^\" (t_i) = \\sum_{i \\neq j} W_{t_i} \\cdot \\mathrm{tpi}_d^\"(t_i, t_j) \\\\\n\\\\\n& \\mathrm {tpi}_d'' = \\sum_{ o(t_i) \\in \\mathrm {occurrences\\ of\\ t_i\\ in\\ document\\ d}} \\frac {1}{\\phi_d(o(t_i), t_j)}  \\\\\n\\\\\n& \\phi_d(o(t_i), t_j) = [a_d(o(t_i), t_j)]^2 - a_d(o(t_i), t_j) +1 \\\\\n\\\\\n & a_d(t_i, t_j) = \\frac{(p_{o(t_i) ;d} -  p_{t_j ;d}) }{\\xi(o(t_i), t_j)} \\\\\n\\end {align}\n$$\n其中:\n$$\n\\xi(o(t_i), t_j) = \\left\\{\n \\begin {align}\n 1,  & p_{o(t_i) ;d} -  p_{t_j ;d} > 0 \\\\\n -1, & p_{o(t_i) ;d} -  p_{t_j ;d} < 0 \\\\\n \\end {align}\n \\right .\n$$\n\n# 其他\n\n文章： An exploration of proximity measures in information retrieval \n\n对 Span-based approaches 和 Distance aggregation approaches 两大类方法中的 5 个度量 proximity 的方法进行了测试， 确定 min cover 的度量方法是其中最好的一种 proximity 度量方法。并将 min cover proximity 整合到了 BM25中\n\n文章 Learning in a Pairwise Term-Term Proximity Framework for Information Retrieval 罗列了 11个proximity 的度量方法，并将它们整合到了 一个统一的相关性计算公式中。\n\n# 未完待续\n\n\n\n# 参考资料\n\n1. [BM25相关度打分公式](https://www.cnblogs.com/hdflzh/p/4034602.html)\n2. BM25F： Robertson, S.E., Zaragoza, H., & Taylor, M.J. (2004). Simple BM25 extension to multiple weighted fields. *CIKM*.\n3. OkaTP：Y. Rasolofo and J. Savoy. Term Proximity Scoring for Keyword-Based Retrieval Systems. In Proceedings of the 25th European Conference on IR Research (ECIR 2003)  pages 207--218, April 2003\n4. BM25TP： S. B uttcher, C. L. A. Clarke, and B. Lushman. Term proximity scoring for ad-hoc retrieval on very large text collections. In Proc. SIGIR, pages 621- 622, 2006.\n5. newTP：Song R , Taylor M J , Wen J R , et al. Viewing Term Proximity from a Different Perspective[C]// European Conference on Information Retrieval. Springer, Berlin, Heidelberg, 2008.\n6. BM25TOP：L. Akritidis, D. Katsaros, and P. Bozanis. Improved retrieval effectiveness by effcient combination of term proximity and zone scoring: A simulation-based evaluation. Simul. Model. Pract. Th., 22:74{91, 2012.\n7. 5 proximity mmeasures：T. Tao and C. Zhai. An exploration of proximity measures in information retrieval. In Proc. SIGIR,pages 295-302, 2007\n8. 11 proximity mmeasures：Cummins R , O'Riordan C . Learning in a Pairwise Term-Term Proximity Framework for Information Retrieval[C]// International Acm Sigir Conference on Research & Development in Information Retrieval. ACM, 2009.\n\n\n\n","tags":["Application"],"categories":["Application"]},{"title":"EM 算法","url":"%2Fblog%2FEM-algorithm.html","content":"\n和 [最大似然估计](https://weirping.github.io/blog/Output_Units_and_Cost_Functions-Neural_networks.html) 一样， EM算法是机器学习中的一种参数估计方法，在隐式马尔科夫算法(HMM)、LDA主题模型, Gaussian mixture model 等都有应用。本文从最大似然估计作为切入点，逐步论述EM算法的使用情景和原理。\n\n# 问题引入\n\n> 我们有两枚硬币, C1 和 C2, 进行抛掷硬币实验(贝努力实验); \n> 假设 C1 取正面的概率 为 $\\theta_1$;\n> 假设 C2 取正面的概率 为 $\\theta_2$;\n> 通过抛掷实验 估计 $\\theta_1$, $\\theta_2$.\n\n硬币的方向使用变量 $x$ 表示; 正面记作 $x=1$, 反面记作 $x=0$;\n\n# 从最大似然估计说起\n\n我们使用硬币C1和C2 分别投掷$n=100$次, 并记录每一次哪一面朝上, 来据估计参数 $\\theta_1$和$\\theta_2$ .  我们可以使用最大似然估计来计算这两个参数.\n\n对于一次贝努力抛硬币实验中有两个结果，即  $x=1$ 是正面，$x=0$ 是反面，令是正面的概率为$\\theta$, 则有：\n$$\np(x=1|\\theta) = \\theta\n$$\n则$x$的概率分布可写成如下形式:\n$$\np(x|\\theta) = \\theta^x (1-\\theta)^{(1-x)}\n$$\n\n现在假定有一个 $x$ 的观测数据集 $D=\\{x_1, x_2, \\dots, x_n\\}$，那么我们能够构造出参数 $\\theta$ 的**似然函数**：\n\n$$\nL(\\theta) = \\prod_{i=1}^n p(x_i|\\theta)\n$$\n可以看到 $L(\\theta)$ 是连乘的，所以为了便于分析, 可以取对数得到 **对数似然函数**：\n$$\n\\ln L(\\theta) = \\ln \\prod_{i=1}^n p(x_i|\\theta) = \\sum_{i=1}^n \\ln p(x_i | \\theta)\n$$\n\n(对数)似然函数对 $\\theta$ 求偏导, 并令偏导数等于零即得到了参数 $\\theta$ 的估计值.\n\n通过以上方法可以分别估计  C1 取正面的概率 $\\theta_1$ 和 C2 取正面的概率 $\\theta_2$.\n\n那么我们换一个场景: 我们每一次投掷硬币都**有放回的随机的从两枚硬币中选择一个进行投掷**. 共进行 $n=100$ 次实验. 那么此时我们最终拿到的是100次硬币的朝向数据 $X=\\{x_1, x_2, \\dots, x_n\\}$ . 但是每一次是用了哪一枚硬币, 我们并不清楚. 在这种情况下怎么才能估计参数 $\\theta_1$和$\\theta_2$呢?\n\n这个时候，对于每一次投掷，就有两个东西需要估计的了，**一是这个数据是C1的还是C2的投掷得到的？二是 C1 取正面的概率 $\\theta_1$ 和 C2 取正面的概率 $\\theta_2$？** 其中 用于表示 这个数据是C1的还是C2的投掷得到的 变量就是一个未被观测到的隐含变量.  EM算法就是用来求包含隐含变量的的模型的最大似然解的算法.\n\n> The goal of the EM algorithm is to find maximum likelihood solutions for models having latent variables.\n\n# EM算法的思想\n\n假设我们想估计A（C1 or C2）和 B（$\\theta$）两个参数，在开始状态下二者都是未知的，但如果知道了A的信息就可以得到B的信息，反过来知道了B也就得到了A。可以考虑首先赋予A某种初值，以此得到B的估计值，然后从B的当前值出发，重新估计A的取值，这个过程一直持续到收敛为止。\n\n下面给出两种关于EM算法的推导: 第一种是网上常见的基于 jensen 不等式的方法, 第二种是基于KL距离的推到方法.\n\n# 基于 Jensen 不等式\n\n\n\n## EM算法推导\n\n假设我们有一个样本集$\\mathbf X=\\{ x^{( 1 )},x^{( 2 )} \\cdots x^{( n )} \\}$，包含n个独立的样本。但每个样本 $i$ 对应的类别 $z^{( i )}$ 是未知的，也即隐含变量。故我们需要估计概率模型 $$p(x,z)$$ 的参数 $\\mathbf \\theta$ ，很难用最大似然求解。\n\n对于参数估计，我们本质上还是想获得一个使似然函数最大化的那个参数 $\\mathbf \\theta$ ，现在与最大似然不同的只是似然函数式中多了一个未知的变量 $z$ 。也就是说我们的目标是找到适合的 $\\theta$ 和 $z$ 让损失函数最大化。按照最大似然求解求解思路, 可以对未知的 $\\mathbf \\theta$ 和 $z$ 分别求偏导，再令其等于0. 但实际施行起来计算是非常复杂的. \n\n先给出(对数)似然函数:\n$$\n\\begin {align}\np(\\mathbf{X}|\\mathbf{\\theta }) &= \\sum _{\\mathbf{z}} p(\\mathbf{X}, \\mathbf{Z}| \\mathbf{\\theta}) \\\\\n\\log p(\\mathbf{X}|\\mathbf{\\theta }) &= \\log \\sum _{\\mathbf{z}} p(\\mathbf{X}, \\mathbf{Z}| \\mathbf{\\theta}) \\\\\n&= \\log \\prod_i^n \\sum_{z^{( i )}} p( x^{( i )},z^{( i )};\\theta  ) \\\\\n&= \\sum_i^n \\log \\sum_{z^{( i )}} p( x^{( i )},z^{( i )};\\theta  ) \\\\\n\\end {align}\n$$\n本质上我们是需要最大化上面的公式，也就是似然函数。但是由于加入了因变量$z$, 使得似然函数中有“和的对数”，对 $\\mathbf \\theta$ 求导后形式会非常复杂，所以很难求解得到未知参数 $\\mathbf \\theta$ 和 $z$ 。\n\n对于每个实例 $x^{( i )}$ ,用 $Q ( z^{( i )} )$ 表示样本实例隐含变量 $z$ 的某种分布，且 $Q ( z^{( i )} )$ 满足条件 $\\sum_{z^{( i )}} Q ( z^{( i )} ) =1$, 如果 $Q ( z^{( i )} )$  是连续性的，则 $Q ( z^{( i )} )$  表示概率密度函数，需要将求和符号换成积分符号。\n\n对该公式做如下变形, 使得公式中只包含“对数的和”，求导就容易了。\n$$\n\\begin {align}\n\\log p(\\mathbf{X}|\\mathbf{\\theta }) & = \\sum_i \\log \\sum_{z^{( i )}} p( x^{( i )},z^{( i )};\\theta  ) \\tag{1}    \\\\\n& = \\sum_i \\log \\sum_{z^{( i )}} Q ( z^{( i )} ) \\frac {p( x^{( i )},z^{( i )};\\theta  )} {Q( z^{( i )} )}  \\tag{2}  \\\\\n& \\ge \\sum_i \\sum_{z^{( i )}} Q( z^{( i )} )\\log \\frac {p( x^{( i )},z^{( i )};\\theta  )} {Q( z^{( i )} )}   \\tag{3}\n\\end {align}\n$$\n其中: (2)到(3)的变换用到了 **Jensen不等式(Jensen's inequality)**.\n\n> ## Jensen不等式\n>\n> 从凸函数说起, 设$\\varphi$ 是定义域为实数的函数，如果对于所有的实数$x$，$\\varphi(x)$的二次导数大于等于0，那么$\\varphi(x)$是凸函数。如果$f(x)$的二次导数只大于0，不等于0，那么称 $\\varphi(x)$ 是严格凸函数。当 $x$ 是向量时，如果$\\varphi(x)$ 的 Hessian 矩阵H是半正定的，那么$\\varphi(x)$是凸函数。如果 Hessian 矩阵H是正定的那么称$\\varphi(x)$是严格凸函数。\n>\n> 如果$\\varphi$是凸函数，$X$是随机变量，那么：\n> $$\n> \\varphi(E[X]) \\le E[\\varphi (X)].\n> $$\n> 特别地，如果$\\varphi$是严格凸函数，当且仅当$X$是常量时，上式取等号。Jensen不等式应用于凹函数时，不等号方向反向。\n\n再回到(2), 因为$f(x)=\\log x$为凹函数。EM算法就是使用了凹函数的 Jensen 不等式.\n\n由于 $\\sum_{z^{( i )}} Q ( z^{( i )} ) =1$, (2)中的 $\\sum_{z^{( i )}} Q ( z^{( i )} ) \\frac {p( x^{( i )},z^{( i )};\\theta  )} {Q( z^{( i )} )}$ 可以看作是 $ \\frac {p( x^{( i )},z^{( i )};\\theta  )} {Q( z^{( i )} )}$ 的期望, 根据凹函数 Jensen 不等式, 就可以推导出(3)的不等式了.\n\n现在(3)容易地求导了，但是(2)和(3)是不等号，而我们想得到(2)的最大值。\n\n为了方便表述, 可以将不等号两边简化为如下形式:\n$$\nL(\\theta) \\ge J(\\theta, Q(z)) \\\\\n$$\n其中: $ L(\\theta) = \\sum_i \\log p( x^{( i )};\\theta ) $, $J(\\theta, Q(z)) = \\sum_i \\sum_{z^{( i )}} Q( z^{( i )} )\\log \\frac {p( x^{( i )},z^{( i )};\\theta  )} {Q( z^{( i )} )}$; $Q(z)$对应（3）中 $Q( z^{( i )} )$  的集合，如果$z$是多项式分布，$Q(z)$就表示多项式分布的参数向量。\n\nEM算法通过不断的最大化 $J(\\theta, Q(z))$，使 $L(θ)$ 的下界提高，最终达到 $L(θ)$ 的最大值. 现在有两个未知量 $\\theta$ 和 $Q(z)$, EM算法首先会固定$\\theta$，然后调整 $Q(z)$ 最大化下界$J(\\theta, Q(z))$；接着通过固定$Q(z)$，再使用MLE调整$\\theta$，依次迭代，直至收敛到局部最优解。\n\n注意: 固定 $\\theta$ 后, $L(θ)$ 是一个常数, $J(\\theta, Q(z))$ 是一个以 $Q(z)$ 为变量, 最大值为常数 $L(θ)$ 的函数. 根据 Jensen 不等式的定义 **当且仅当$X$是常量时，Jensen不等式的等号成立**  可知,  对于固定的 $\\theta$  只要保证 $\\frac {p( x^{( i )},z^{( i )};\\theta  )} {Q( z^{( i )} )}$ 为常量, $J(\\theta, Q(z))$ 即能取的最大值 $L(θ)$. 此时:\n$$\n\\frac {p( x^{( i )},z^{( i )};\\theta  )} {Q( z^{( i )} )} = c\n$$\n其中: $c$ 是常量.\n\n又因为 $\\sum_{z^{( i )}} Q ( z^{( i )} ) =1$, 可以做如下推导:\n$$\n\\sum_{z^{( i )}}p( x^{( i )},z^{( i )};\\theta  ) = \\frac {\\sum_{z^{( i )}}p( x^{( i )},z^{( i )};\\theta  )} {1} =\n\\frac {\\sum_{z^{( i )}}p( x^{( i )},z^{( i )};\\theta  )} {\\sum_{z^{( i )}} Q ( z^{( i )} )} = \\frac {p( x^{( i )},z^{( i )};\\theta  )} {Q( z^{( i )} )} = c \\\\\n$$\n\n$$\n\\begin {align}\nQ( z^{( i )} ) &= \\frac {p( x^{( i )},z^{( i )};\\theta  )}{\\sum_{z^{( i )}}p( x^{( i )},z^{( i )};\\theta  )} \\\\\n&= \\frac {p( x^{( i )},z^{( i )};\\theta  )}{p( x^{( i )};\\theta  )} \\\\\n&= p(z^{( i )} | x^{( i )};\\theta  ) \\\\\n\\end {align}\n$$\n\n可以看出 $Q( z^{( i )} )$ 是在固定参数 $\\theta$ 后，根据样本数据调整 $z^{( i )}$ 所得到的后验概率。使用上式也解决了$Q( z^{( i )} )$如何计算的问题, 不需要通过MLE 类计算了。\n\n## EM 算法过程\n\n第一步，初始化分布参数 $\\theta$；\n第二步，重复E-step 和 M-step直到收敛：\n\n- E-step：根据当前的 $\\theta$ 来计算出的隐性变量的后验概率（条件概率），其实就是隐性变量的期望值。作为隐藏变量的现有估计值：\n  $$\n  Q( z^{( i )} ) := p(z^{( i )} | x^{( i )};\\theta  )\n  $$\n\n- M-step：固定当前的 $Q( z^{( i )} )$ , 最大化似然函数从而获得新的 $\\theta$ :\n  $$\n  \\theta := \\arg\\max_{\\theta} \\sum_i \\sum_{z^{( i )}} Q( z^{( i )} )\\log \\frac {p( x^{( i )},z^{( i )};\\theta  )} {Q( z^{( i )} )}\n  $$\n\n## 收敛性证明\n\n假定 $\\theta^{(t)}$ 和$\\theta^{(t+1)}$是EM第$t$次和$t+1$次迭代后的结果。如果我们证明了$l(\\theta^{(t)})<=l(\\theta^{(t+1)})$  ，也就是说极大似然估计单调增加，那么最终我们就会得到极大似然估计的最大值。下面来证明，选定  $\\theta^{(t)}$ 之后，我们得到E-step：\n$$\nQ( z^{( i )} ) := p(z^{( i )} | x^{( i )};\\theta  )\n$$\n这一步保证了在给定 $\\theta^{(t)}$ 时，Jensen不等式中的等式成立，也就是\n$$\nl(\\theta^{(t)}) = \\sum_i \\sum_{z^{( i )}} Q( z^{( i )} )\\log \\frac {p( x^{( i )},z^{( i )};\\theta^{(t)} )} {Q( z^{( i )} )}\n$$\n然后进行M步，固定$Q^{(t)}(z^{(i)})$,并将 $\\theta^{(t)}$ 试作变量，对上面的式子求导，得到 $\\theta^{(t+1)}$,这样经过一些推导会有以下式子成立：\n$$\n\\begin {align}\nl(\\theta^{(t+1)}) &\\ge \\sum_i \\sum_{z^{( i )}} Q( z^{( i )} )\\log \\frac {p( x^{( i )},z^{( i )};\\theta^{(t+1)} )} {Q( z^{( i )} )} \\\\\n&\\ge \\sum_i \\sum_{z^{( i )}} Q( z^{( i )} )\\log \\frac {p( x^{( i )},z^{( i )};\\theta^{(t)} )} {Q( z^{( i )} )} \\\\\n&= l(\\theta^{(t)})\n\\end {align}\n$$\n\n\n\n# 基于KL距离\n\n该方法参考自 《Pattern recognition and machine learning》.\n\n对于包含观测变量 $\\mathbf{X}$ 和隐含变量 $\\mathbf Z$ 的概率模型, 其联合概率分布可以表示为 $p(\\mathbf{X}, \\mathbf{Z}| \\mathbf{\\theta})$. 整个数据集的(对数)似然函数可以表示为: \n$$\n\\begin {align}\np(\\mathbf{X}|\\mathbf{\\theta }) &= \\sum _{\\mathbf{z}} p(\\mathbf{X}, \\mathbf{Z}| \\mathbf{\\theta}) \\\\\n\\ln p(\\mathbf{X}|\\mathbf{\\theta }) &= \\sum _{\\mathbf{z}} \\ln p(\\mathbf{X}, \\mathbf{Z}| \\mathbf{\\theta}) \n\\end {align}\n$$\n\n为了方便论述, 这里假设 $\\mathbf Z$ 是一个离散型变量. 隐含变量  $\\mathbf Z$ 的概率分布函数 表示为 $q(\\mathbf{Z})$.\n\n如上文所述, 直接对包含隐含变量的 $\\ln p(\\mathbf{X}|\\mathbf{\\theta })$ 求偏导是非常困难的, 但是如果隐含变量是已知的,就可以使用最大似然估计直接求解能够是似然函数 $\\ln p(\\mathbf{X}, \\mathbf{Z}|\\mathbf{\\theta })$ 最大化的参数 $\\theta$.\n\n我们目标是最大化上面的公式. 可以将对数似然函数做如下变形:\n$$\n\\begin {align}\n\\ln p(\\mathbf{X}|\\mathbf{\\theta }) &= \\mathcal{L}(q, \\mathbf{\\theta}) + \\mathrm{KL}(q || p)  \\tag{4}  \\\\\n\\\\\n\\mathcal{L}(q,\\mathbf{\\theta }) &= \\sum _{\\mathrm{Z}}q(\\mathbf{Z}) \\ln \\left\\{ \\frac {p(\\mathbf{X}, \\mathbf{Z}| \\mathbf{\\theta})}{q(\\mathbf{Z})} \\right\\}  \\tag{5} \\\\\n\\\\\n\\mathrm{KL}(q || p) &= \\sum _{\\mathrm{Z}}q(\\mathbf{Z}) \\ln \\left\\{ \\frac {q(\\mathbf{Z})}{p (\\mathbf{Z}| \\mathbf{X}, \\mathbf{\\theta})} \\right\\}  \\tag{6} \\\\\n\\end {align}\n$$\n\n其中: \n\n- $\\mathcal{L}(q,\\mathbf{\\theta })$ 是包含 $q(\\mathbf{Z})$ 和 $p(\\mathbf{X}, \\mathbf{Z}| \\mathbf{\\theta})$ 的函数. \n- $\\mathrm{KL}(q || p)$ 是 $q(\\mathbf{Z})$ 和 $p (\\mathbf{Z}| \\mathbf{X}, \\mathbf{\\theta})$ 的 KL距离(Kullback-Leibler divergence).  $p (\\mathbf{Z}| \\mathbf{X}, \\mathbf{\\theta})$ 表示 $\\mathbf{Z}$ 的后验概率, 相应的 $q(\\mathbf{Z})$ 就表示 $\\mathbf{Z}$ 的先验概率\n\n根据 KL距离 的定义有 $KL(q || p) \\ge 0 $, 当且仅当 $q = p$ 时, 等号成立. 也就是说 对于式 (6) 当 $q(\\mathbf{Z}) =  p (\\mathbf{Z}| \\mathbf{X}, \\mathbf{\\theta})$ 时, $\\mathrm{KL}(q || p) = 0 $. \n\n同时根据式 (4) 可知 $\\ln p(\\mathbf{X}|\\mathbf{\\theta }) \\ge \\mathcal{L}(q, \\mathbf{\\theta})$, 即, $\\mathcal{L}(q, \\mathbf{\\theta})$ 是对数似然函数 $\\ln p(\\mathbf{X}|\\mathbf{\\theta })$ 的下界. 如下图所示:\n\n![](EM-algorithm/GEM1.png)\n\nEM算法分为E-step 和 M-step, 下面分别讲解.\n\n在E-step我们固定 $\\theta$ 记为  $\\theta^{\\mathrm{old}}$ , 由于似然函数是一个只关于 $\\theta$的函数, 此时似然函数是一个常数  $\\ln p(\\mathbf{X}|\\mathbf{\\theta^{\\mathrm{old}}})$ . E-step 是在给定 $\\theta^{\\mathrm{old}}$ 后最大化一个关于 $q(\\mathbf{Z})$ 的下界函数 $\\mathcal{L}(q,\\mathbf{ \\theta^{\\mathrm{old}} })$的过程, 且已知 $\\mathcal{L}(q,\\mathbf{ \\theta^{\\mathrm{old}} })$ 的最大值为常数$\\ln p(\\mathbf{X}|\\mathbf{\\theta^{\\mathrm{old}}})$. 根据上图可知, 当 $\\mathrm{KL}(q || p) = 0$ 时, $\\mathcal{L}(q,\\mathbf{ \\theta^{\\mathrm{old}} })$ 可以取到最大值 $\\ln p(\\mathbf{X}|\\mathbf{\\theta^{\\mathrm{old}}})$. 此时 :\n$$\nq(\\mathbf{Z}) =  p (\\mathbf{Z}| \\mathbf{X}, \\mathbf{\\theta^{\\mathrm{old}}}).  \\tag{7}\n$$\n\nE-step 如下图所示:\n\n![](EM-algorithm/GEM2.png)\n\n当 $q(\\mathbf{Z})$ 确定后, 将(7) 带入下界函数(5)可以做如下变形:\n$$\n\\begin {align}\n\\mathcal{L}(q,\\mathbf{\\theta }) &= \\sum _{\\mathrm{Z}} p (\\mathbf{Z}| \\mathbf{X}, \\mathbf{\\theta}^{old}) \\ln \\left\\{ \\frac {p(\\mathbf{X}, \\mathbf{Z}| \\mathbf{\\theta})}{p (\\mathbf{Z}| \\mathbf{X}, \\mathbf{\\theta}^{old}))} \\right\\}  \\tag{8}\\\\\n\\\\\n&= \\sum _{\\mathrm{Z}} p (\\mathbf{Z}| \\mathbf{X}, \\mathbf{\\theta}^{old}) \\ln p (\\mathbf{X}, \\mathbf{Z}| \\mathbf{\\theta}) - \\sum _{\\mathrm{Z}} p (\\mathbf{Z}| \\mathbf{X}, \\mathbf{\\theta}^{old}) \\ln p (\\mathbf{Z}| \\mathbf{X}, \\mathbf{\\theta}^{old}) \\tag{9}\\\\\n\\\\\n&= \\mathcal{Q}(\\mathbf{\\theta}, \\mathbf{\\theta}^{old}) + \\mathrm{const} \\tag{10}\n\\end {align}\n$$\n\n\n\n其中式(9) 右边的一项是一个常数, 用 const表示. 左边一项定义为 似然函数 $\\ln p (\\mathbf{X}, \\mathbf{Z}| \\mathbf{\\theta})$ 的期望, 即:\n$$\n\\begin {align}\n\\mathcal{Q}(\\mathbf{\\theta}, \\mathbf{\\theta}^{old}) &= \\sum _{\\mathrm{Z}} p (\\mathbf{Z}| \\mathbf{X}, \\mathbf{\\theta}^{old}) \\ln p (\\mathbf{X}, \\mathbf{Z}| \\mathbf{\\theta}) \\\\\n&= E_{\\mathbf{Z}| \\mathbf{X}, \\mathbf{\\theta}^{old}} \\ln p (\\mathbf{X}, \\mathbf{Z}| \\mathbf{\\theta})\n\\end {align}\n$$\n可能这就是为什么 这一步叫做 E-step(Expectation step) 的原因吧.\n\nM-step 是在上一步确定的 $q(\\mathbf{Z})$ 的基础上, 最大化关于 $\\theta$ 的下界函数 $\\mathcal{L}(q,\\mathbf{\\theta })$ 的过程.通过上问可知, 最大化 $\\mathcal{L}(q,\\mathbf{\\theta })$ 等价与最大化 $\\mathcal{Q}(\\mathbf{\\theta}, \\mathbf{\\theta}^{old})$. 此时可以使用最大似然估计来求解得到能够使$\\mathcal{Q}(\\mathbf{\\theta}, \\mathbf{\\theta}^{old})$ 最大化的 $\\theta$ 记为 $\\theta^{\\mathrm{new}}$. \n\n当$\\theta$ 取值为 $\\theta^{\\mathrm{new}}$时, 下界函数变大, 即 $\\mathcal{L}(q,\\mathbf{\\theta^{\\mathrm{new}} }) \\ge \\mathcal{L}(q,\\mathbf{\\theta^{\\mathrm{old}} })$ . 同时由于 $q(\\mathbf{Z}) =  p (\\mathbf{Z}| \\mathbf{X}, \\mathbf{\\theta^{\\mathrm{old}}}) \\ne p (\\mathbf{Z}| \\mathbf{X}, \\mathbf{\\theta^{\\mathrm{new}}})$, $\\mathrm{KL}(q || p) \\gt 0$ , 所以似然函数会增加更多. 如下图所示:\n\n\n![](EM-algorithm/GEM3.png)\n\n对EM算法的计算流程整理如下: \n\n> Given a joint distribution $p(\\mathbf{X}, \\mathbf{Z}| \\mathbf{\\theta})$  over observed variables $\\mathbf{X}$ and latent variables $\\mathbf{Z}$, governed by parameters $\\mathbf{\\theta}$, the goal is to maximize the likelihood function  $p(\\mathbf{X} | \\mathbf{\\theta})$  with respect to  $\\mathbf{\\theta}$.\n> 1. Choose an initial setting for the parameters $\\theta^{\\mathrm{old}} $\n> 2. E step Evaluate \n> $$\n> q(\\mathbf{Z}) =  p (\\mathbf{Z}| \\mathbf{X}, \\mathbf{\\theta^{\\mathrm{old}}})\\\n> $$\n> \n> 3. M step Evaluate $\\theta^{\\mathrm{new}}$, \n> $$\n> \\theta^{\\mathrm{new}} = {\\arg\\max}_{\\theta} \\mathcal{Q}(\\mathbf{\\theta}, \\mathbf{\\theta}^{old})\n> $$\n> where\n> $$\n> \\begin {align}\n> \\mathcal{Q}(\\mathbf{\\theta}, \\mathbf{\\theta}^{old}) &= \\sum _{\\mathrm{Z}} p (\\mathbf{Z}| \\mathbf{X}, \\mathbf{\\theta}^{old}) \\ln p (\\mathbf{X}, \\mathbf{Z}| \\mathbf{\\theta}) \\\\\n> &= E_{\\mathbf{Z}| \\mathbf{X}, \\mathbf{\\theta}^{old}} \\ln p (\\mathbf{X}, \\mathbf{Z}| \\mathbf{\\theta})\n> \\end {align}\n> $$\n> \n> 4. Check for convergence of either the log likelihood or the parameter values. If the convergence criterion is not satisfied, then let\n> $$\n> \\theta^{\\mathrm{old}} = \\theta^{\\mathrm{new}}\n> $$\n> and return to step 2.\n\n# reference\n\n[ Statistical Machine Learning (course 495)](https://ibug.doc.ic.ac.uk/media/uploads/documents/expectation_maximization-1.pdf)\n\n[JerryLead博客-（EM算法）The EM Algorithm](http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006936.html)\n\n[从最大似然到EM算法浅解](http://blog.csdn.net/zouxy09/article/details/8537620)\n\nBishop, Christopher M. Pattern recognition and machine learning. springer, 2006.\n\n[https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm](https://en.wikipedia.org/wiki/Expectation–maximization_algorithm)\n\n","tags":["Optimization"],"categories":["Mathematics"]},{"title":"卡方检验","url":"%2Fblog%2FChi-Square-Test.html","content":"\n卡方检验是一种用途广泛的假设检验方法，它属于非参数检验方法。用于比较两个及两个以上样本率( 构成比）以及两个分类变量的关联性分析。思想是比较理论频数和实际频数的吻合程度。\n\n# 卡方分布\n\n设 $X_1, X_2, \\dots ,X_n$ 是来自总体$N(0,1)$的样本,则称统计量\n$$\n\\mathcal X^2=X_1^2 + X_2^2+ \\dots +X_n^2\n$$\n服从自由度为$n$的$\\chi^2$分布,记为$\\mathcal X^2 \\sim \\chi^2(n)$ . 此处,自由度是指上式右端包含的**独立变量**的个数。\n\n卡方分布的概率密度函数为：\n\n$$\nf(x;n)=\n \\begin{cases}\n \\dfrac {x^{\\frac {n}{2}-1}e^{-\\frac {x}{2}}}{2^{\\frac {n}{2}}   \\Gamma (\\frac {n}{2})},&x>0;\\\\\n 0,&{\\text{otherwise}}.\n \\end{cases}\n$$\n\n![](Chi-Square-Test/Chi-square_pdf.png)\n\n\n\n卡方分布是由正态分布构造而成的一个新的分布，当自由度$n$很大时，$\\chi^2$分布近似为正态分布。此时：\n均值：$E(\\chi^2)=n$\n方差：$D(\\chi^2)=2n$\n\n分布的可加性： 若$\\chi^2(n_1)$  $\\chi^2(n_2)$ 互相独立，则：服从$\\chi^2(n_1) + \\chi^2(n_2)$ 自由度为$n1+n2$ 的 $\\chi^2$ 分布。\n\n# 假设检验\n\n可以复习这篇文章[假设检验](https://weirping.github.io/blog/hypothesis-testing.html)。\n\n# 卡方检验\n\n卡方检验是专用于解决计数数据统计分析的假设检验法。卡方检验的两个应用：拟合性检验和独立性检验。\n\n## 拟合性检验\n\n拟合优度检验是为检验观察到的一批数据是否与某种理论分布符合，而采用的计算方法就是卡方检验法。\n\n假设一总体$X$服从分布：\n\n$$\nH_0:P(X=a_i)=p_i; \\ \\ \\ (i=1,\\dots,k) \\\\\n$$\n\n其中: $a_i,p_i$都是已知的，且$a_1,\\dots,a_k$两两各不相同，$p_i>0$.\n\n先设想总体$X$的样本数量$n$足够大，按大数定理，若以$v_i$记$X_1,\\dots,X_n$中等于$a_i$的个数，应有$v_i/n≈p_i$。我们把$np_i$称为$a_i$这个“类”的理论值，而把$v_i$称为其经验值或者观察值。如下表：\n\n| 类别   | $a_1$  | $a_2$  | $\\dots$ | $a_i$  | $\\dots$ | $a_k$  |\n| ---- | ------ | ------ | ------- | ------ | ------- | ------ |\n| 理论值  | $np_1$ | $np_2$ | $\\dots$ | $np_i$ | $\\dots$ | $np_k$ |\n| 经验值  | $v_1$  | $v_2$  | $\\dots$ | $v_i$  | $\\dots$ | $v_k$  |\n\n表中最后两行的差异越小，则$H_0$越可能是对的. 为了反映这种差异,皮尔逊采用 z统计量：\n$$\n\\begin {align}\nZ &=∑\\frac{(理论值−经验值)^2}{理论值} \\\\\n&=∑_{i=1}^k \\frac{(np_i−v_i)^2}{(np_i)} \\sim \\chi_{k-1}^2\n\\end {align}\n$$\n\n对公式解释分三部分：\n\n1. 理论值−经验值：反映差异;\n2. (理论值−经验值)^2：排除1中存在正负抵消的情况;\n3. (理论值−经验值)^2/理论值：针对不同“类”下值域差异过大问题，将差异转换到同种尺度内。\n\n\n**如果原假设$H_0$成立，则在样本大小$n \\to \\infty$时，$Z$的分布趋向于自由度为$k-1$的$\\chi^2$分布，即$\\chi_{k−1}^2$。** \n\n\n\n![](Chi-Square-Test/Chi-square-test.png)\n\n\n\n\n\nscipy 中提供了 chisquare 进行卡方拟合优度检查，其函数签名如下：\n\n>chisquare(f_obs, f_exp=None, ddof=0, axis=0)\n>\n>f_obs : array_like\n>   各类别的观察频率\n>\n>f_exp : array_like, optional\n>   各类别的期望频率. 默认为频率相等 \n>\n>ddof : int, optional\n>   \"Delta degrees of freedom\": adjustment to the degrees of freedom\n>   for the p-value.  The p-value is computed using a chi-squared\n>   distribution with **k - 1 - ddof** degrees of freedom, where k\n>   is the number of observed frequencies.  The default value of ddof\n>   is 0.\n>\n>axis : int or None, optional\n>   The axis of the broadcast result of f_obs and f_exp along which to\n>   apply the test.  If axis is None, all values in f_obs are treated\n>   as a single data set.  Default is 0.\n\n\n\n\n```python\nfrom scipy.stats import chisquare\n\nchisquare([16, 18, 16, 14, 12, 12]) # 默认的期望频数时均匀分布的\n# Power_divergenceResult(statistic=2.0, pvalue=0.8491450360846096)\n\nchisquare([16, 18, 16, 14, 12, 12], f_exp=[16, 16, 16, 16, 16, 8])\n#Power_divergenceResult(statistic=3.5, pvalue=0.6233876277495822)\n\n# ddof \"Delta degrees of freedom\" ，计算pvalue时使用的自由度为  k - 1 - ddof\nchisquare([16, 18, 16, 14, 12, 12], f_exp=[16, 16, 16, 16, 16, 8], ddof=1)\n# Power_divergenceResult(statistic=3.5, pvalue=0.477878344488724)\n```\n\n\n\n\n\n\n## 独立性检验\n\n卡方检验还可以用于检验两个或两个以上因素（各有两项或以上的分类）之间是否相互影响的问题，这种检验称为独立性检验。例如要讨论血型与性格的关系，血型有A、B、AB、O四类，性格采用心理学上的A型性格来划分，即有A型和B型两种，每个人可能是它们之间交叉所形成的8种类型中的一种，那么倒底它们之间有不有关系，就可以用卡方独立性检验。\n\n卡方独立性检验的零假设是各因素之间相互独立。因此理论次数的计算也是基于这一假设，具体计算时，采用列联表的方式，后面将举例说明。\n\n两组大白鼠在不同致癌剂作用下的发癌率如下表，问两组发癌率有无差别（致癌剂对大白鼠的发癌数是否会有影响）？\n\n![](Chi-Square-Test/sample01.png)\n\n表中只有 52, 19, 39,  3  这四个数据是整个表中的基本资料，其余数据均由此推算出来；这四格资料表就称**四格表**（fourfold table），或称2行2列表（2×2 contingency table）。从该资料算出的两组发癌率分别为73.24%和92.86%，两者的差别可能是 **抽样误差** 所致，亦可能是 **两组发癌率确有不同** 。这里可通过卡方检验来验证其差异有无统计学意义（即，是否为抽样误差所致），检验的基本公式为：\n$$\n\\chi^2 = \\sum \\frac {(A-T)^2}{T}\n$$\n其中：\n\n- $A$ 为实际数，四格表的四个基本数据就是实际数；\n- $T$ 为理论数，是根据检验假设推断出来的；理论数的计算方式如下：\n  1. 假设这两组的发癌率相同，差别仅是由抽样误差所致\n  2. 那么理论发癌率为两组合计发癌率，即 $91 \\div 113=80.3 \\% $ \n  3. 以此为依据便可推算出四格表中相应的四格的理论数\n\n卡方独立性检验的步骤如下：\n\n1. 建立假设，确定显著性水平 $\\alpha$：\n\n   >H0: 两组的发癌率相同\n   >\n   >H1:两组的发癌率不同\n   >\n   >$\\alpha = 0.05$\n\n2. 计算理论数，计算公式为：\n   根据 H0 假设，理论发癌率为 $91 \\div 113=80.3 \\% $ .\n   则 四格表中的真实发癌数 分别为：\n   第1行1列： $71 \\times 80.3 \\%=57.18$ \n   第1行2列： $71 \\times (1-80.3 \\%)=13.82$\n   第2行1列： $42 \\times 80.3 \\%=33.82$\n   第2行2列： $42 \\times (1-80.3 \\%)=8.18$\n   即得到如下四格表，其中括号里面为理论发癌数。\n\n![](Chi-Square-Test/sample02.png)\n\n3. 计算卡方值按公式代入\n   $$\n   \\begin {align}\n   \\chi^2 &=  \\sum \\frac {(A-T)^2}{T} \\\\\n   &= \\frac {(52-57.18)^2}{57.18} + \\frac {(19-13.82)^2}{13.82} + \\frac {(39-33.82)^2}{33.82} + \\frac {(3-8.18)^2}{8.18} \\\\\n   &=0.47+1.94+0.79+3.28 \\\\\n   &=6.48\n   \\end {align}\n   $$\n\n4. 查卡方值表求$P$值\n   本例中卡方检验的自由度为 n=（行数-1）（列数-1）\n   查卡方界值表，找到 $\\chi_{0.05}^2(1) = 3.84$\n   由于 $6.48 \\gt \\chi_{0.05}^2(1) = 3.84  $ 所以 $P < 0.05$ \n   所以拒绝原假设 H0，接受备择假设 H1。差异有显著统计学意义， 即，两组的发癌率不同。（不明白的话，可以去复习假设检验的相关知识）\n\nscipy 中提供了 基于 contingency table （四格表）进行$chi^2$独立性检验的函数，\n\n```python\nimport numpy as np\nfrom scipy.stats import chi2_contingency\ncontingency_table = np.array([[442, 514], [38, 6]])   # 共建四格表\nchi2, pval, dof, expctd = chi2_contingency(contingency_table) # chi2统计量, p-value, 自由度, 期望值\n```\n\n# 卡方检验用于特征选择\n\n用卡方检验做特征选择更好的是应用于分类问题。 特征选择的假设为：如果一个特征与个类别相互独立，则认为这个特征不好，反之，如果一个特征与类别相关，则认为这个特征比较好。在这种场景下，我们的检验检验问题可以定义为：\n$$\n\\begin {align}\n& H_0: \\text{变量与类别相互独立} \\\\\n& H_1: \\text{变量与类别相关}\n\\end {align}\n$$\n可以将该方法理解为拟合性检验问题。如对于一个特征来说，其中观察值为各类别中该特征的值之和（分类数量=观察值数量=理论值数量），理论值为各类别在总样本量中所占的比例 乘以 该特征值只和。可以参考sklearn中**函数chi2**的代码chi2\n\n那么 $\\chi^2$ 统计量越大 或者 p-value 越小 则变量与类别越相关，越时一个应该被选用的特征。\n\n此处我们可以不定义显著性水平，因为我们的目标一般时从若干个变量中 k 个相关性好的特征，我们只需要按照 $\\chi^2$ 统计量或者 p-value 的大小关系选择最好的 k 个变量即可。\n\n在 sklearn 中提供了这个功能：\n\n```python\nfrom sklearn.feature_selection import chi2\nfrom sklearn.datasets import load_iris\nchi2(iris.data, iris.target)\n# (array([ 10.81782088,   3.59449902, 116.16984746,  67.24482759]),\n#  array([4.47651499e-03, 1.65754167e-01, 5.94344354e-26, 2.50017968e-15]))\n```\n\n上面的结果中 第一行 为4个特征对应的  $\\chi^2$ 统计量, 第二行为 p-value。\n\n还可以和 SelectKBest 一起使用，直接选择 k个最好的特征。 下面的例子是从64个特征中选择20个特征\n\n```\nfrom sklearn.datasets import load_digits\nfrom sklearn.feature_selection import SelectKBest, chi2\nX, y = load_digits(return_X_y=True)\nX.shape\n# (1797, 64)\nmodel = SelectKBest(chi2, k=20)\nX_new = model.fit_transform(X, y)\nX_new.shape\n# (1797, 20)\n\nmodel.scores_ # 可以得到每个特征chi2 统计量\n\nmodel.pvalues_ # 可以得到每个特征pvalue\n```\n\n# 卡方检验用于特征离散化\n\n在评分卡模型中需要对连续特征进行分箱/离散化，就可以采用卡方检验方法进行离散化。\n\n具体方法见我的代码和blog(目前不公开)。\n\n# 参考资料\n\n [卡方检验综述](http://www.cnblogs.com/liyongzhao/articles/3369117.html)\n\n[特征选择-卡方检验用于特征选择](https://blog.csdn.net/ldcadai/article/details/72854462)\n\n [卡方分布、卡方独立性检验和拟合性检验理论及其python实现](https://www.cnblogs.com/Yuanjing-Liu/p/9252844.html)\n\n[SelectKBest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)","tags":["Data Exploration"],"categories":["Mathematics"]},{"title":"最大熵模型","url":"%2Fblog%2FMaximum-Entropy-Model.html","content":"\n# 最大熵原理\n\n在学习概率模型时, 所有可能的模型中熵最大的模型是最好的模型; 若概率模型需要满足一些约束, 则最大熵原理就是在满足已知约束的条件集合中选择熵最大模型. 最大熵原理指出, 对一个随机事件的概率分布进行预测时, 预测应当满足全部已知的约束, 而对未知的情况不要做任何主观假设. 在这种情况下, 概率分布最均匀, 预测的风险最小, 因此得到的概率分布的熵是最大. 要点为两个,即:\n\n1. 对于已知约束的情况下,建模要要满足约束;\n2. 除了约束外不做任何假设.\n\n最大熵原理的实质就是, 在已知部分知识的前提下, 关于未知的分布最合理的推断就是符合已知知识最随机的推断.\n看一个简单的例子: 设$a \\in \\{x, y\\}$ 且 $b \\in \\{0, 1\\}$, 要推断概率分布 $p(a,b)$. 现在我们唯一所知道的信息是 $p(x,0) + p(y,0) = 0.6$, 即：\n\n![](Maximum-Entropy-Model/max-entropy-pre1.png)\n\n由于约束条件很少，满足条件的分布有无数多个，例如下面的分布就是满足已知条件的一个分布：\n\n![](Maximum-Entropy-Model/max-entropy-pre2.png)\n\n但按照最大熵原则，上述分布却不是一个好的分布，因为这个分布的熵不是满足条件的所有分布中熵最大的分布。按照最大熵的原则，应该选择的下面的分布：\n\n![](Maximum-Entropy-Model/max-entropy-pre3.png)\n\n因为，最大熵原则要求，合理的分布应该同时满足要求：\n\n$$\n\\begin {align}\n& \\hat p = \\arg\\max_{p \\in P} H(p) = \\arg\\max_{p \\in P} [- \\sum_{a \\in \\{x, y\\}, b \\in \\{0, 1\\}} p(a, b) \\log p(a, b)] \\\\\n& p(x,0) + p(y,0) = 0.6 \\\\\n& p(x,0) + p(y,0) + p(x,1) + p(y,1) = 1 \\\\\n\\end {align}\n$$\n\n\n# 最大熵模型\n\n将最大熵原理应用于分类问题, 得到的就是最大熵模型.\n\n为了下文论述方便, 此处先定义下文中需要使用的符号:\n\n- $\\mathcal {T} = \\{(x_1, y_1),(x_2, y_2), \\dots (x_N, y_N) \\} $ 表示训练数据集\n- $x_i \\in \\mathcal X$ 表示特征集合\n- $y_i \\in \\mathcal Y$ 表示 label 集合\n\n最大熵模型是用于处理分类问题的, 所以我们的最终目标是求 $p(y_i|x_i)$ .\n\n按照最大熵的原理, 我们需要让模型满足已知的所有约束条件, 那么问题来了:\n\n- 这些约束条件哪里来呢? \n- 怎么表示这些约束?\n\n## 特征函数\n\n最大熵模型需要的约束实际上就是从训练数据$\\mathcal T$中抽取的.\n\n首先我们我们需要从训练数据中抽取岀了若干特征. 其次使用 **特征函数** 来表示这些特征. 对于一个给定的样本 $(x,y)$ ,特征函数可以定义为任意实值函数, 通常我们都是使用二值函数来定义. 如下所示:\n\n$$\nf(x, y) = \n\\left \\{\n\\begin {align}\n1, \\ \\ & x, y满足条件\\\\\n0, \\ \\ & otherwise\n\\end {align}\n\\right .\n$$\n\n下面使用词性标注的例子来说明: \n\n假设我们需要判断\"打\"字是动词还是量词,已知的训练数据有:\n\n> (x_1,y_1)=(一打火柴,量词)\n\n> (x_2,y_2)=(三打啤酒,量词)\n\n> (x_3,y_3)=(五打塑料袋,量词)\n\n> (x_4,y_4)=(打电话,动词)\n\n> (x_5,y_5)=(打篮球,动词)\n\n通过观察, 我们发现, \"打\"前面为数字时, \"打\"是量词, \"打\"后面为名词时, \"打\"是动词,这就是从训练数据中提取的两个特征, 可分别用特征函数表示为:\n\n$$\nf(x, y) = \n\\left \\{\n\\begin {align}\n1, \\ \\ & \"打\"前面为数字 \\\\\n0, \\ \\ & otherwise\n\\end {align}\n\\right .\n$$\n\n$$\nf(x, y) = \n\\left \\{\n\\begin {align}\n1, \\ \\ & \"打\"前面为名词 \\\\\n0, \\ \\ & otherwise\n\\end {align}\n\\right .\n$$\n\n对于上面的5条训练数据,我们便有:\n\n$$\nf_1(x_1, y_1) = f_1(x_2, y_2)=f_1(x_3,y_3)=1; f1(x_4, y_4)=f1(x_5, y_5)=0 \\\\\nf_2(x_1, y_1) = f_2(x_2, y_2)=f_2(x_3,y_3)=0; f2(x_4, y_4)=f2(x_5, y_5)=1 \\\\\n$$\n\n## 经验分布与预测分布\n\n所谓经验(概率)分布是指在训练数据$\\mathcal T$进行统计得到的分布,用 $\\tilde p$ 表示. 由于真实分布是无法直接获取的(如果内得到,我们就不需要训练模型了), 通常我们都是使用经验分布来表示真实分布(要求: 训练数据集是从总体中 **独立同分布** 抽样获取的).\n\n在最大熵模型中, 需要考察两个经验分布 $\\tilde p(x,y)$ 和 $\\tilde p(x)$,其定义分别为:\n\n$$\n\\begin {align}\n& \\tilde p(x, y) &= \\frac {cout(x, y)}{N} \\\\\n& \\tilde p(x)    &= \\frac {cout(x)}{N} \\\\\n\\end {align}\n$$\n\n其中, $count(x,y)$ 和 $cont(x)$ 分别表示 $(x,y)$ 和 $x$ 在训练数据 $mathcal T$ 中出现的次数.\n\n同时存在一个模型(即我们最终训练得到的模型, 目前未知), 该模型也可以预测 $p(y|x)$. 那么利用Beyes定理 $(x, y)$ 的预测分布可以表示为:\n\n$$\np(x, y) = p(x) p(y| x)\n$$\n\n但是上式中的 $p(x)$ 是未知的. 此处使用 $\\tilde p(x)$ 来对 $p(x)$ 进行近似, 那么 $(x, y)$ 的预测分布可以近似为:\n\n$$\np(x, y) \\approx \\tilde p(x) p(y| x)\n$$\n\n利用上述定义的特征函数, 经验分布和预测分布,就可以进一步定义我们所需的约束条件了.\n\n\n## 约束条件\n\n在最大上模型中, 建立约束条件的基础是我们认为:\n\n**每一个特征对应的特征函数 $f$, 在 $\\mathcal T$ 上关于经验分布 $\\tilde p(x,y)$ 的数学期望 $E_{\\tilde p}(f)$ 与它们在模型中关于 $p(x,y)$ 的数学期 $E_p(f)$ 望相等.**\n\n$$\n\\begin {align}\nE_{\\tilde p}(f) & = \\sum_{(x,y) \\in \\mathcal T} \\tilde p(x, y)f(x, y) \\\\\nE_p(f)          & = \\sum_{(x,y) \\in \\mathcal T} p(x, y)f(x, y) \\\\\n                & = \\sum_{(x,y) \\in \\mathcal T} \\tilde p(x) p(y \\mid x)f(x, y) \\\\\n\\end {align}\n$$\n\n即:\n\n$$\n\\begin {align}\n& E_{\\tilde p}(f) =  E_p(f) \\\\\n\\\\\n& \\sum_{(x,y) \\in \\mathcal T} \\tilde p(x, y)f(x, y) = \\sum_{(x,y) \\in \\mathcal T} \\tilde p(x) p(y \\mid x)f(x, y) \\\\\n\\end {align}\n$$\n\n假设从训练数据中抽取了 $n$ 个特征, 便有 $n$ 个特征函数 $f_i, (i=1, 2, \\dots, n)$, 相应的就有 $n$ 个约束条件.\n\n$$\n E_{\\tilde p}(f_i) =  E_p(f_i), (i=1, 2, \\dots, n)\n$$\n\n\n\n## 模型表示\n\n给定训练数据 $\\mathcal T$, 我们的目标是:利用最大熵原理选择一个最好的分类模型, 即对于任意给定的输入 $x \\in \\mathcal X$,可以以概率 $p(y \\mid x)$ 输出 $y \\in \\mathcal Y$.\n\n最大熵模型本质上是一个约束最优化问题，即在给定的约束下求目标函数的最值问题。 上面已经介绍了约束条件，基于最大熵原理我们的目标函数即为熵的最大化，即：\n\n$$\n\\begin {align}\nH(p) = H(y \\mid x) & = -\\sum_{(x,y) \\in \\mathcal T} p(x, y) \\log p(y \\mid x) \\\\\n                   & = -\\sum_{(x,y) \\in \\mathcal T} p(x) p(y \\mid x) \\log p(y \\mid x) \\\\\n                   & = -\\sum_{(x,y) \\in \\mathcal T} \\tilde p(x) p(y \\mid x) \\log p(y \\mid x) \\\\\n\\end {align}\n$$\n\n由于 $p(x)$ 是未知的. 此处使用 $\\tilde p(x)$ 来对 $p(x)$ 进行近似。\n\n对综上给出形式化的最大熵模型：\n对于给定的训练数据$\\mathcal T$, 特征函数 $f_i(x,y), i=1,2,…,n$, 最大熵模型就是求解:\n\n$$\n\\begin {align}\n\\max_p & H(p) & = -\\sum_{(x,y) \\in \\mathcal T} \\tilde p(x) p(y \\mid x) \\log p(y \\mid x) \\\\\ns.t.   &      & E_{\\tilde p}(f_i) =  E_p(f_i), (i=1, 2, \\dots, n)                       \\\\\n       &      & \\sum_y p(y \\mid x) = 1                                                  \\\\\n\\end {align}\n$$\n\n其中的条件 $\\sum_y p(y \\mid x)=1$ 是为了保证 $p(y \\mid x)$ 是一个合法的概率分布.\n\n# 参考资料\n\n[最大熵模型 Maximum Entropy Model](https://www.cnblogs.com/ooon/p/5677098.html)\n\n[最大熵学习笔记](https://blog.csdn.net/itplus/article/details/26550597)\n\n\n","tags":["NLP"],"categories":["Model"]},{"title":"马尔科夫链及其平稳分布","url":"%2Fblog%2FStationary-Distribution-Markov-chain.html","content":"\n马尔科夫链假设某一时刻状态转移的概率只依赖于它的前一个状态。这样做可以大大简化模型的复杂度，因此马尔科夫链在很多序列模型中得到广泛的应用，比如循环神经网络RNN，隐式马尔科夫模型HMM等. \n\n马尔科夫链分布提供了使马尔科夫链和初始状态无关的一个办法，并刻画了马尔科夫链在长时间下的极限行为和平均行为。\n\n马尔科夫过程/马尔科夫链 是一种随机过程, 本文首先简单回顾随机过程中的平稳随机过程, 然后引出马尔科夫链及其平稳分布.\n\n变量说明:\n\n- $X$ : 随机变量;\n- $x$ : 随机变量的值;\n- $\\chi$ : 随机变量所有可能取值的集合. $ \\forall x \\in \\chi$ . 对于马尔科夫链来说 $\\chi$ 为其状态空间. \n\n# 平稳随机过程\n\n**随机过程**: 设有一个过程$\\{X_i\\}$, 若对于每一个固定的时刻 $i$ , $X_i$ 是一个随机变量, 则称 $\\{X_i\\}$ 为随机过程. \n\n随机过程是一组随时间变化的随机变量序列, 刻画一个过程需要知道所有有限的联合概率密度函数:\n$$\n\\begin {align}\n& P(X_1 = x_1, X_2=x_2, \\dots, X_n=x_n) = P(x_1, x_2, \\dots, x_n) \\\\\n& (x_1, x_2, \\dots, x_n) \\in \\chi ^n\n\\end {align}\n$$\n**平稳随机过程**: 如果随机变量序列的任何有限子集的 **联合分布* 关于时间下标的位移 *不变* , 即 对于每个 $n$ 和 位移$l$, 以及任意的 $ x_1, x_2, \\dots, x_n \\in \\chi $ 有:\n$$\n\\begin {align}\nP(X_1 = x_1, X_2=x_2, \\dots, X_n=x_n) = P(X_{1+l} = x_1, X_{2+l}=x_2, \\dots, X_{n+l}=x_n) \\\\\n\\end {align}\n$$\n则称该随机过程是平稳的(Stationary). \n\n# 马尔科夫过程\n\n离散随机过程 $\\{X_i\\}$ 满足 \n$$\nP(X_n=x_n|X_{n-1}=x_{n-1},...,X_1=x_1) = P(X_n=x_n|X_{n-1}=x_{n-1})\n$$\n则称其为马尔可夫链/马尔科夫过程. \n\n既然某一时刻状态转移的概率只依赖于它的前一个状态，那么我们只要能求出系统中任意两个状态之间的转换概率，这个马尔科夫链的模型就定了。\n\n马尔科夫链:\n\n- 是一种随机事件序列;\n- 认为未来的取值只与当前取值有关，与历史取值无关\n- 是一种离散型的随机过程。\n\n**时间不变的马尔科夫过程** : 如果条件概率 $P(x_{n+1} \\mid x_n)$ 不依赖与 $n$, 即对 $n=1,2, \\dots$ 有:\n$$\nP(X_{n+1}= b \\mid X_n = a) = P(X_2=b \\mid X_1=a)\n$$\n则成马尔科夫链是 时间不变的. \n\n时间不变的马尔科夫链中, 从一个状态变道另一个状态的的概率与下标(时间)无关. 一个时间不变的马尔科夫链完全可以由其初始状态和概率转移矩阵表示.\n\n实际上我们平时所说的马尔科夫链 一般都是 时间不变的. 如在HMM中用到的马尔科夫链.\n\n**状态空间**: 马尔科夫链中所有可能的状态值的集合, 记为 $\\chi$ . \n\n如果马尔科夫链可以从任意状态经过有限步转移到另一任意状态, 且其转移概率为正, 则成词马尔科夫链是不可约的.  即**状态空间中任意两个状态都是相互连通的**. 这里的连通可以不是直接相连，只要能够通过有限次转移到达即可。比如对于a, b, c状态，存在a->b, b->c，则我们认为a到c是可连通的。\n\n马尔科夫链中如果从一个状态转移到他自身的不同路径长度的最大公因子为1, 则称马尔科夫链是**非周期的**. 我们处理的问题基本上都是非周期性的.\n\n# 平稳分布 / 平稳马尔科夫过程\n\n马尔科夫链完全可以由其初始状态和概率转移矩阵表示. 令向量$\\pi(j)$ 表示序列中某个随机变量正好取第 $j$ 个状态的概率, $P$ 表示状态转移矩阵, $P_{ij}$表示从第$i$个状态转移到第$j$个状态的概率. note: 此处的 $i$ 和 $j$ 表示的是状态空间中状态的序号, 而不是随机过程中的时间序号.\n\n如果一个**非周期**的马尔科夫链有状态转移矩阵$P$, 并且它的任何两个状态是**连通**的，那么$\\lim_{n \\to \\infty} P_{ij}^n $与$i$无关，我们有：\n\n结论一:\n\n$$\n\\lim_{n \\to \\infty}P_{ij}^n = \\pi (j)\n$$\n\n结论二: \n\n假设状态空间中共有 $K$ 个状态($K$ 可以是有限的，也可以是无限的), 状态转移矩阵经过 $n$ 自乘以次后的方阵中各元素的值只与列号有关,  同列中的元素的值相同.\n$$\n\\lim_{n \\to \\infty}P^n = \n\\begin {Bmatrix}\n\\pi(1) & \\pi(2) & \\dots & \\pi(j) & \\dots& \\pi(K) \\\\\n\\pi(1) & \\pi(2) & \\dots& \\pi(j) & \\dots& \\pi(K) \\\\\n\\vdots & \\vdots & \\ddots & \\vdots &  & \\vdots &  \\\\\n\\pi(1) & \\pi(2) & \\dots& \\pi(j) & \\dots & \\pi(K) \\\\\n\\vdots & \\vdots &  & \\vdots & \\ddots & \\vdots &  \\\\\n\\pi(1) & \\pi(2) & \\dots& \\pi(j) & \\dots& \\pi(K) \\\\\n\\end{Bmatrix}\n$$\n\n结论三: \n\n$$\n\\pi (j) = \\sum_{i=0}^{K} \\pi(i)P_{ij}\n$$\nnote: $K$ 可以是有限的，也可以是无限的. 一般文章中使用 $\\infty$, 为了避免将此处的$i$误解为马尔科夫链中随机变量的序号, 我使用了$K$来代替. \n\n结论四: \n\n若马尔科夫链是 **非周期的** , 并且其何两个状态是**连通的** , 则该马尔科夫链具有唯一.\n即: $\\pi$是方程$\\pi P = \\pi$的唯一非负解.\n\n其中：\n$$\n\\begin {align}\n& \\pi=[\\pi(1),\\pi(2),\\dots ,\\pi(j), \\dots \\pi(K)] \\\\ \n& \\sum_{i=0}^{K} \\pi(i)=1 \\\\\n& K \\le \\infty \\\\\n\\end {align}\n$$\n\n再次强调: $n$ 表示一个马尔科夫链中第 $n$ 个随机变量的序号.  $i$ 和 $j$ 是状态序号. \n\n上面的性质中需要注意的有：\n\n1. 非周期的马尔科夫链：这个主要是指马尔科夫链的状态转化不是循环的，如果是循环的则永远不会收敛。我们遇到的马尔科夫链一般都是非周期性的。\n2. 任何两个状态是连通的：这个指的是从任意一个状态可以通过有限步到达其他的任意一个状态。\n3. 马尔科夫链的状态数可以是有限的，也可以是无限的。因此可以用于连续概率分布和离散概率分布。\n4. $\\pi$通常称为马尔科夫链的平稳分布。\n\n# 平稳马尔科夫过程的例子\n\n![](Stationary-Distribution-Markov-chain/stationary-example.png)\n\n　这个马尔科夫链是表示股市模型的，共有三种状态：牛市（Bull market）, 熊市（Bear market）和横盘（Stagnant market）。每一个状态都以一定的概率转化到下一个状态。比如，牛市以0.025的概率转化到横盘的状态。这个状态概率转化图可以以矩阵的形式表示。如果我们定义矩阵阵$P$, 某一位置$P(i,j)$的值为$P(j \\mid i)$, 即从状态 $i$ 转化到状态 $j$ 的概率，并定义牛市为状态0， 熊市为状态1, 横盘为状态2. 这样我们得到了马尔科夫链模型的状态转移矩阵为：\n$$\nP = \n\\begin {Bmatrix}\n0.9 & 0.075 & 0.025 \\\\\n0.15 & 0.8 & 0.05 \\\\\n0.25 & 0.25 & 0.5 \\\\\n\\end {Bmatrix}\n$$\n假设我们当前股市的概率分布为：$[0.3,0.4,0.3]$, 即30%概率的牛市，40%概率的熊盘与30%的横盘。然后这个状态作为序列概率分布的初始状态$v_{t0}$，将其带入这个状态转移矩阵计算$v_{t1},v_{t2},v_{t3} \\dots$ 的状态。代码如下：\n\n```python\nimport numpy as np\nmatrix = np.matrix([[0.9,0.075,0.025],\n                    [0.15,0.8,0.05],\n                    [0.25,0.25,0.5]], dtype=float)\nvector = np.matrix([[0.3,0.4,0.3]], dtype=float)\nprint \"round: %d \\t\" % (0), vector\nfor i in range(100):\n    vector = vector * matrix\n    print \"round: %d \\t\" % (i+1), vector\n```\n\n部分输出结果如下:\n\n```shell\nround: 0 \t[[0.3 0.4 0.3]]\nround: 1 \t[[0.405  0.4175 0.1775]]\nround: 2 \t[[0.4715  0.40875 0.11975]]\nround: 3 \t[[0.5156 0.3923 0.0921]]\nround: 4 \t[[0.54591  0.375535 0.078555]]\nround: 5 \t[[0.567288 0.36101  0.071702]]\n...\nround: 51 \t[[0.62499994 0.31250005 0.06250001]]\nround: 52 \t[[0.62499996 0.31250004 0.0625    ]]\nround: 53 \t[[0.62499997 0.31250003 0.0625    ]]\nround: 54 \t[[0.62499998 0.31250002 0.0625    ]]\nround: 55 \t[[0.62499998 0.31250002 0.0625    ]]\n...\nround: 60 \t[[0.625  0.3125 0.0625]]\nround: 61 \t[[0.625  0.3125 0.0625]]\nround: 62 \t[[0.625  0.3125 0.0625]]\nround: 63 \t[[0.625  0.3125 0.0625]]\nround: 64 \t[[0.625  0.3125 0.0625]]\nround: 65 \t[[0.625  0.3125 0.0625]]\n```\n\n可以发现，从第60轮开始，我们的状态概率分布就不变了，一直保持在[0.625   0.3125  0.0625]，即62.5%的牛市，31.25%的熊市与6.25%的横盘。那么这个是巧合吗？\n\n我们现在换一个初始概率分布试一试，现在我们用$[0.7,0.1,0.2]$作为初始概率分布，然后这个状态作为序列概率分布的初始状态$v_{t0}$，将其带入这个状态转移矩阵计算$v_{t1},v_{t2},v_{t3} \\dots$的状态。结果如下：\n\n```shell\nround: 0 \t[[0.7 0.1 0.2]]\nround: 1 \t[[0.695  0.1825 0.1225]]\nround: 2 \t[[0.6835  0.22875 0.08775]]\nround: 3 \t[[0.6714 0.2562 0.0724]]\nround: 4 \t[[0.66079  0.273415 0.065795]]\nround: 5 \t[[0.652172 0.28474  0.063088]]\n...\nround: 56 \t[[0.62500001 0.31249999 0.0625    ]]\nround: 57 \t[[0.625  0.3125 0.0625]]\nround: 58 \t[[0.625  0.3125 0.0625]]\nround: 59 \t[[0.625  0.3125 0.0625]]\nround: 60 \t[[0.625  0.3125 0.0625]]\n```\n\n尽管这次我们采用了不同初始概率分布，最终状态的概率分布趋于同一个稳定的概率分布$[0.625   0.3125  0.0625]$， 也就是说**马尔科夫链模型的状态收敛到的稳定概率分布与我们的初始状态概率分布无关**。如果我们得到了这个稳定概率分布对应的马尔科夫链模型的状态转移矩阵，则我们可以用任意的概率分布样本开始，带入马尔科夫链模型的状态转移矩阵，这样经过一些序列的转换，最终就可以得到符合对应稳定概率分布的样本。这个性质不光对离散状态成立，连续状态时也成立。\n\n对于一个确定的状态转移矩阵 $P$ ，它的 $n$ 次幂 $P^n$ 在当 $n$ 足够大的时候是确定的的值. \n\n```python\nmatrix0 = np.matrix([[0.9,0.075,0.025],\n                     [0.15,0.8,0.05],\n                     [0.25,0.25,0.5]], dtype=float)\nmatrix = np.matrix(matrix0)\nfor i in range(100):\n    matrix = np.matmul(matrix, matrix0)\n    print \"round: %d \\n\" % (i+1), matrix\n```\n\n部分结果如下:\n\n```shell\nround: 1 \n[[0.8275  0.13375 0.03875]\n [0.2675  0.66375 0.06875]\n [0.3875  0.34375 0.26875]]\nround: 2 \n[[0.7745  0.17875 0.04675]\n [0.3575  0.56825 0.07425]\n [0.4675  0.37125 0.16125]]\n...\nround: 61 \n[[0.625      0.3125     0.0625    ]\n [0.62499999 0.31250001 0.0625    ]\n [0.625      0.3125     0.0625    ]]\nround: 62 \n[[0.625  0.3125 0.0625]\n [0.625  0.3125 0.0625]\n [0.625  0.3125 0.0625]]\nround: 63 \n[[0.625  0.3125 0.0625]\n [0.625  0.3125 0.0625]\n [0.625  0.3125 0.0625]]\nround: 64 \n[[0.625  0.3125 0.0625]\n [0.625  0.3125 0.0625]\n [0.625  0.3125 0.0625]]\nround: 65 \n[[0.625  0.3125 0.0625]\n [0.625  0.3125 0.0625]\n [0.625  0.3125 0.0625]]\n```\n\n可以发现，在 $n \\le 2$ 以后，$P^n$ 的值稳定不再变化，而且每一行都为$[0.625   0.3125  0.0625]$，这和我们前面的稳定分布是一致的。\n\n# 参考资料\n\n[MCMC(二)马尔科夫链](https://www.cnblogs.com/pinard/p/6632399.html)\n\n[马尔科夫链及其平稳状态](https://www.cnblogs.com/coshaho/p/9740937.html)\n\n信息论基础\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n​    \n\n\n\n","tags":["Information Theory"],"categories":["Mathematics"]},{"title":"n元模型","url":"%2Fblog%2Fn-gram-model.html","content":"\n# 概述\n\n## 符号定义\n\n$L$ : 语言, 如 汉语, 英语, 或者一门专门的语言.\n\n$T$ : 从语言$L$ 中随机抽样的样本. \n\n$s$ : 语言中的一个句子. \n\n## 语言模型(language model)\n\n根据语言样本估计出的句子的概率分布$P(s)$称为语言$𝐿$的语言模型. 语言模型给句子赋以概率，语言$L$中所有句子的概率之和为1. \n$$\n\\sum_{s \\in L} P(s) = 1\n$$\n语言模型应用举例\n\n- 语音识别\n  - I have **too** many books. ( √ )\n  - I have **to** many books. (×)\n  - I have **two** many books. (×)\n- 汉语分词\n  - 别 **把** **手** 伸 进 别人 的 口袋 里 ( √ )\n  - 别 **把手** 伸 进 别人 的 口袋 里 (×)\n- 机器翻译\n  我喜欢吃苹果 ⇒\n  I like eating apple ( √ )\n  I eating like apple (×)\n\n# 语言建模\n\n给定自然语言$L$，$p(𝑠)$未知,  利用给定的语言样本估计$p(𝑠)$的过程被称作语言建模. \n\n给定句子$𝑠 = w_1 w_2 \\dots w_𝑙$ ，如何计算该句子的概率: $p(𝑠)$\n\n直接统计语料库中句子$𝑠$出现的次数. \n\n应用链式规则，分解计算$p(𝑠)$\n$$\n\\begin {aligned}\np(𝑠) &= p (w_1)p (w_2|w_1)p (w_3 | w_1w_2) \\dots p (w_l | w_1w_2… w_{l−1})  \\\\\n\\\\\n&=\\prod_{i=1} p(w_i|w_1w_2… w_{i−1})\n\\end {aligned}\n$$\n\n举例如下：\n\n$$\n\\begin {aligned}\n&p(john\\ read\\ a\\ book) \\\\\n& = p(john)\\times p(read\\ john) \\times p(a\\ john\\ read)\\times p(book|john\\ read\\ a)\n\\end{aligned}\n$$\n\n事实上不能用这种方式计算一个句子的概率，原因有两个：\n\n- 直接这样计算会导致参数空间过大. 一个语言模型的参数就是所有的这些条件概率. \n  比如，按上面方式计算$P(w_5 |w_1 ,w_2 ,w_3 ,w_4 )$，这里每个$w_i$可能的取值有$|V|$个, 即一个词典大小. 则该模型的参数个数是$|V|^5$，而且这还不包含$P(w4 | w1, w2, w3)$的个数，可以看到这样去计算一个句子的概率会使语言模型参数个数过多而无法实用. \n- 数据稀疏严重. 存在大量可能的字符串是在语料库中未出现过的. \n\n# n元模型\n\n## 定义\n\n为了解决參数空间过大的问题. 引入了马尔科夫假设：**随意一个词出现的概率只与它前面出现的有限的一个或者几个词有关. ** \n\n $w_i$ 的出现只与其之前的$n−1$个词有关，即n元组(n-gram). \n$$\np(w_i|w_1w_2… w_{i−1}) = p(w_i|w_{i-n+1}w_{i-n+2}… w_{i−1})\n$$\n此时：\n$$\n\\begin {aligned}\np(𝑠) &= p (w_1)p (w_2|w_1)p (w_3 | w_1w_2) \\dots p (w_l | w_{i-n+1}w_{i-n+2}\\dots w_{l−1})  \\\\\n\\\\\n&=\\prod_{i=1}  p(w_i|w_{i-n+1}w_{i-n+2}\\dots w_{i−1})\n\\end {aligned}\n$$\n根据$n$ 的不同取值可分为:\n\n- 一元模型(n=1, unigram)\n- 二元模型(n=2, bigram)\n- 三元模型(n=3, trigram)\n\n\n### n元模型的参数\n\n|         | 参数形式                                 | 参数数量           |\n| :-----: | :----------------------------------- | :------------- |\n| unigram | $p(w_i)$                             | $\\mid V\\mid$   |\n| bigram  | $p(w_i\\mid w_{i-1})$                 | $\\mid V\\mid^2$ |\n| trigram | $p(w_i\\mid w_{i-2}w_{i-1})$          | $\\mid V\\mid^3$ |\n| n-gram  | $p(w_i\\mid w_{i-n+1} \\dots w_{i-1})$ | $\\mid V\\mid^n$ |\n\n$w \\in V$, $V$只词表，|V|代表词表中词的数量\n可以发现：\n- n越大，模型需要的参数越多\n- 参数数量指数增长\n\n\n小结：\n\nn元模型认为：句子中前面出现的词对后面可能出现的词有很强的预示作用. \n\n$n$越大，历史信息越多，模型越准确. \n\n### n的选择\n\n|       | n 较大时              | n 较小时       |\n| ----- | ------------------ | ----------- |\n| 语境区别性 | 提供了更多的语境信息，语境更具区别性 | 境信息少，不具区别性  |\n| 参数    | 参数个数多、计算代价大        | 参数个数少、计算代价小 |\n| 训练语料  | 需要更多的训练语料          | 训练语料无需太多    |\n| 结果    | 参数估计不可靠            | 参数估计可靠      |\n\n# n元模型构建过程\n\n1. 数据准备: \n   - 确定训练语料\n   - 对语料进行词例化(tokenization) 或切分\n   - 句子边界标记，增加两个特殊的词<bos>和<eos> \n     I eat . → <bos> I eat . <eos>\n     I sleep . → <bos> I sleep . <eos>\n2. 参数估计\n   利用训练语料，估计模型参数\n3. 模型评价\n\n## 参数估计\n\n如何计算其中的每一项条件概率(即参数)呢? **极大似然估计（Maximum Likelihood Estimation，MLE）**\n\n假设语料库中句子和句子互相独立, 是从服从分布为$p(\\Theta) $的总体随机抽取的. $\\Theta$ 为模型参数, 即上面的条件概率.\n\n一个句子的概率为: $p(s \\mid \\Theta) $ .\n\n整个语料库的概率(似然函数):\n$$\np(T \\mid \\theta) = \\prod_{s_i \\in T} p(s \\mid \\Theta)\n$$\n使训练样本似然值(概率)最大的参数$\\Theta$ 为\n$$\n\\Theta_{ML} = \\arg\\max p(T \\mid \\Theta)\n$$\n该优化问题具有解析解, 其解表示如下:\n\n令 $c(w_1w_2… w_n)$表示$n$元组 $w_1,w_2… w_n$ 在训练语料中出现的次数. 则：\n$$\np(w_n \\mid w_1… w_{n−1})=\\frac{c(w_1w_2 \\dots w_n)}{c(w_1w_2 \\dots w_{n−1})}\n$$\n该方法称为**相对频率法(relative frequency estimation)**.  \n\n如对于如下训练语料：\n```\n<bos> John read Moby Dick <eos>\n<bos> Mary read a different book <eos>\n<bos> She read a book by Cher <eos>\n```\n\n使用相对频率发计算模型参数如下：\n\n\n$$\n\\begin {aligned}\n& p( john \\mid bos) =\\frac {c( bos, john)}{c( bos )}= \\frac 13 \\\\\n& p (a \\mid read) =\\frac {c(read, a)}{c(read)}=\\frac 23 \\\\\n& p( eos \\mid book) =\\frac {c (book, eos)}{c (book)}=\\frac 12 \\\\\n& p( book \\mid a) =\\frac {c(a, book)}{c(a)}=\\frac 12 \\\\\n& p( read \\mid john) =\\frac {c(john, read)}{c (john)}=\\frac 11\n\\end {aligned}\n$$\n\n**note** : 取对数避免下溢\n\n# 模型评价\n\n语言模型常用的评价指标有两个,  交叉熵(Cross-Entropy)和困惑度(Perplexity)).\n\n## Cross-Entropy\n\n语言$L = (X_i) \\sim p(x)$ 与其模型q的交叉熵定义为:\n$$\nH(L, q) = - \\lim \\frac 1n \\sum_{x_1^n}p(x_1^n) \\log q(x_1^n)\n$$\n 其中：$x_1^n = x_1, \\dots, x_n$ 为语言$L$ 中的句子， $p(x_1^n)$ 为句子$x_1^n$ 在语言$L$中出现的概率(真实)概率，$q(x_1^n)$ 为模型$q$ 对句子 $x_1^n$ 出的概率估计. \n\n现在仍然无法计算这个语言的交叉熵，因为我们并不知道真实概率$p(x_1^n)$，不过可以假设这种语言是理想的，即$n$趋于无穷大时，其全部 word 的概率之和为1. 也就是说，根据信息论的定理：假定语言$L$ 是稳态(stationary)遍历的(ergodic)随机过程，$L$ 与其模型$q$的交叉熵计算公式就变为:\n$$\nH(L, q) = - \\lim \\frac 1n  \\log q(x_1^n)\n$$\n\n一般地，在$n$足够大时我们近似地采用如下计算方法：\n$$\nH(L, q) \\approx -  \\frac 1n  \\log q(x_1^n)\n$$\n\n在测试语料上推导如下:\n\n令$T=w_1 w_2 \\dots w_N$为测试语料, 此处假设$N$ 是测试语料的文本长度, 是一个足够大的值. 此时模型$q$ 在测试语料上的交叉熵定义为:\n$$\nH(T, q) = - \\frac 1N \\log q(T)\n$$\n对于n-gram模型来说 \n\n$$\n\\begin {align}\n& q(T) = \\prod_{w_1^n \\in V^n} q(w_n \\mid w_{1}^{n-1}) \\\\\n& p(w_1^n)= \\frac {c(w_1^n)}{N}\n\\end {align}\n$$\n\n则其交叉熵定义为:\n\n$$\n\\begin {align}\nH_{\\mathrm{n-gram}}(T, q) &= - \\frac 1N \\log q(T)  \\\\ \n&= - \\frac 1N \\log  \\prod_{w_1^n \\in V^n} q(w_n \\mid w_{1}^{n-1}) \\\\\n&= - \\frac 1N \\sum_{w_1^n \\in V^n} \\log   q(w_n \\mid w_{1}^{n-1}) \\\\\n&= - \\sum_{w_1^n \\in V^n} \\frac 1N  \\log   q(w_n \\mid w_{1}^{n-1}) \\\\\n&= - \\sum_{w_1^n \\in V^n} p(w_1^n)  \\log   q(w_n \\mid w_{1}^{n-1}) \\\\\n\\end {align}\n$$\n\n交叉熵越小, 语言模型质量越好. \n\n例如unigram:\n$$\n\\left .\n\\begin {align}\nq(T) =  \\prod_{i=1}^{N} q(w_i) \\\\\np(w_i)= \\frac {c(w_i)}{N}\n\\end {align}\n\\right \\} \n\\Rightarrow H_1(T, q) = -  \\sum_{i=1}^{N} p(w_i) \\log q(w_i)\n$$\n推导过程如下:\n$$\nH_1(T, q) = - \\frac 1N \\log q(T)  = - \\frac 1N \\log  \\prod_{i=1}^{N} q(w_i) =  -  \\sum_{i=1}^{N} \\frac 1N \\log q(w_i) = -  \\sum_{i=1}^{N} p(w_i) \\log q(w_i) \n$$\n## Perplexity\n\n给定语言$L$ 的样本$T=w_1 w_2 \\dots w_N$, 语言 $L$ 的困惑度定义为:\n$$\n\\begin {align}\nPP_q &= 2^{H(L, q)} \\approx 2^{-  \\frac 1N  \\log q(x_1^N)} \\\\\n&=q(T) ^{-\\frac 1N}\n\\end {align}\n$$\n对于n-gram模型来说: $q(T) = \\prod_{w_1^n \\in V^n} q(w_n \\mid w_{1}^{n-1})$\n$$\nPP_q = \\{\\prod_{w_1^n \\in V^n} q(w_n \\mid w_{1}^{n-1}) \\} ^{-\\frac 1N}\n$$\n\n- 困惑度越小, 语言模型质量越好. \n- 从以上推导可以看出 交叉熵 和 困惑度 本质是一致的. \n- 在设计语言模型时，我们通常用困惑度来代替交叉熵衡量语言模型的好坏. \n  比如你对模型进行了一版改进: \n  使用交叉熵评价时, 交叉熵减小了 9.9 - 9.1 =0.8\n  使用困惑度评价时, 困惑度减小了 950 - 540 = 410\n  给老板汇报时你会选用哪个? 反正主流的论文都是用的困惑度作为评价指标. \n\n# 数据稀疏问题\n\n由于训练样本不足而导致所估计的分布不可靠的问题，称为数据稀疏问题\n\n举例如下: 有如下训练语料：\n\n```\n<bos> John read Moby Dick <eos>\n<bos> Mary read a different book <eos>\n<bos> She read a book by Cher <eos>\n```\n对于一个新的句子Cher read a book. 由于c(Cher read) = 0. 所以$p(Cher\\ read\\ a\\ book)=0$ 这个结论是不合理的. 问题出在现有语料没有覆盖所有情况.\n\nNLP数据稀疏问题汇总如下:\n\n- zipf定律: 在自然语言的语料库里，一个单词出现的次数与它在频率表里的排名成反比.\n- 语言中只有很少的常用词, 大部分词都是低频词, 大多数词( n元组)在语料中的出现是稀疏的.\n- 词的分布是长尾分布，n元组分布亦是如此.\n- 语料库可以提供少量常用词( n元组)的可靠样本.\n- 语料库无论怎么扩大, 总是会出现未覆盖的词或( n元组).\n- **语料库规模扩大，主要是高频词词例的增加, 扩大语料规模不能从根本上解决稀疏问题.**\n\n\n**由于数据稀疏，MLE估计值不是理想的参数估计值**\n\n## 平滑技术\n\n解决数据稀疏问题的方法为平滑技术(smoothing), 它的基本思想为: 把在训练样本中出现过的事件(句子)的概率适当减小, 把减小得到的概率值分配给训练语料中没有出现过的事件(句子). \n\n根据概率的重新分配方法的不同, 平滑技术分为不同的方法. \n\n## 简单平滑\n\n简单平滑 认为未出现的n元组是等概率分布\n\n这些方法包括 加法平滑、留存平滑、Good-Turing平滑\n\n### 加法平滑\n\n####  Add-one\n\nAdd-one平滑规定n元组比真实出现次数多一次.\n\n$$\n\\begin {aligned}\n& new\\_count(n-gram)  = count(n-gram) +1 \\\\\n\\\\\n& p_{ML}(w_n \\mid w_1… w_{n−1})=\\frac{c(w_1w_2 \\dots w_n)}{c(w_1w_2 \\dots w_{n−1})} \\\\\n\\\\\n& p_{+1}(w_n \\mid w_1… w_{n−1})=\\frac{c(w_1w_2 \\dots w_n)+1}{c(w_1w_2 \\dots w_{n−1})+ \\mid V\\mid} \\\\\n\\end {aligned}\n$$\n\n$ \\mid V\\mid$ 为语料库中词的数量. \n\n此时:\n\n- 没有出现的n元组的频率是1, 具有一个较小的概率.\n- 出现过的n元组的频率+1, 但是其**概率减小了**.\n\n\n下面举例说明Add-one平滑存在的问题.\n\nbi-gram平滑前后二元组的频率计数\n\n![](n-gram-model/add-one-counts.png)\n\nbi-gram平滑前后二元组的概率统计:\n\n![](n-gram-model/add-one-prob.png)\n\n\n\n- 由于训练语料中未出现n元组数量太多, 平滑后, 所有未出现的n元组占据了整个概率分布中的一个很大的比例(所有蓝色概率的和). 因此, 在NLP中, Add-one给训练语料中没有出现过的n元组分配了太多的概率空间.  同时大幅减小了出现过的n元组的概率.  这样做显然是不合理的. \n\n\n- add-one 将出现在训练语料中的那些n元组, 都增加同样的频度值, 这是否公平? 不合理\n- add-one 认为所有未出现的n元组概率相等, 这是否合理? 不合理\n\n优点: Very simple to implement\n缺点: Takes away too much probability mass from seen events. Assigns too much total probability mass to unseen events.  实际实验中发现未出现的n-gram占的概率和==99.96% .\n\n#### Add-K\n\n在Add-one的基础上做了一点小改动, 原本是加一, 现在加上一个小于1的常数$K$. \n$$\np_{+K}(w_n \\mid w_1… w_{n−1})=\\frac{c(w_1w_2 \\dots w_n)+K}{c(w_1w_2 \\dots w_{n−1})+ K\\mid V\\mid}\n$$\n- Add-K 效果比Add-one好, 仍不理想.\n- 缺点是这个常数K仍然需要人工确定, 对于不同的语料库$K$可能不同.\n\n简单平滑方法还有 留存平滑, [Good-Turing平滑](https://en.wikipedia.org/wiki/Good%E2%80%93Turing_frequency_estimation) 等.\n\n## 组合平滑(插值和回退)\n\n简单平滑认为未出现的n元组等概率分布. 组合平滑.\n\n那么未出现的n元组概率均匀分布，是否合理？其实是不合理的.\n例如，假设下面三个bigram均未在训练预料中出现\n> journal of \n> journal from \n> journal never \n\n但是根据经验  journal of  应该更常见，概率应该更大.  \n\n同时我们发现越是高阶n元组, 稀疏问题越严重. \n\n组合平滑的思想就是参考低阶n元组估算高阶n元组的概率分布. 比如: 通过统计发现unigram 中 \n\n- “of”  频率高于“from” 和 “never” \n- 概率p (of) >p (from) >p(never)\n\n\n所以  journal of 的概率大与另外两个. \n\n组合平滑分为 插值和回退 两类.\n\n### 插值平滑\n\n#### 简单线性插值平滑\n\n它的核心思想是，既然高阶组合可能出现次数为0，那稍微低阶一点的组合总有不为0的. 如下是一个三阶组合，假设$p(w_n|w_{n−1}w_{n−2})=0$，而$p(w_n|w_{n−1})>0$且$p(w_n)>0$，则加权平均后的概率不为$0$，从而达到平滑的效果. \n$$\n\\hat p(w_n|w_{n−1}w_{n−2})=\\lambda_3 p(w_n|w_{n−1}w_{n−2})+\\lambda_2 p(w_n|w_{n−1})+\\lambda_1 p(w_n)\n$$\n其中: $\\sum_i\\lambda_i = 1$ ,  $\\lambda_i$ 根据经验取值,  也可以基于开发集自动学习\n\n简单线性插值平滑可以表示为如下递归式:\n$$\np_{interp} (w_i \\mid w_{i-n+1}^{i-1}) = \\lambda_i p_{MLE} (w_i \\mid  w_{i-n+1}^{i-1}) + (1- \\lambda_i) p_{interp}(w_i \\mid  w_{i-n+2}^{i-1})\n$$\n#### Jelinek-Mercer平滑\n\n简单线形插值平滑中，权值 $\\lambda_i$ 一旦确定就固定不变了.\n\n Jelinek-Mercer平滑认为若高阶n元组可靠，$\\lambda$应该大;  若高阶n元组不可靠，$\\lambda$应该小. n元组的可靠程度与 n 元组$w_{i-n+1}^{i}$具体的历史$w_{i-n+1}^{i-1}$出现的频次正相关. 即: $\\lambda$应该和 n 元组$w_{i-n+1}^{i}$具体的历史$w_{i-n+1}^{i-1}$的频次关联起来.\n\nJelinek-Mercer平滑可以表示为递归的插值模型\n$$\np_{JM} (w_i \\mid w_{i-n+1}^{i-1}) = \\lambda_{w_{i-n+1}^{i-1}} p_{MLE} (w_i \\mid  w_{i-n+1}^{i-1}) + (1- \\lambda_{w_{i-n+1}^{i-1}}) p_{JM}(w_i \\mid  w_{i-n+2}^{i-1})\n$$\n递归的终止条件: \n\n1. 终止于平滑后的一元模型 $p_{smooth}(w_i)$. \n\n\n2. 终止于0元模型. 0元模型定义为均匀分布: $\\frac {1}{\\mid V \\mid}$. \n\n$\\lambda_{w_{i-n+1}^{i-1}}$的估计方法\n\n1. 统计频次$c(w_{i-n+1}^{i-1})$, 按照频次将$c(w_{i-n+1}^{i-1})$分为若干(k)个区间.\n2. 每个区间对应一个 $\\lambda_{w_{i-n+1}^{i-1}}$ 值, 共$k$个.\n3. 通过海量训练数据训练确定 $k$个 $\\lambda$ 值.\n\n### 回退平滑\n\n回退平滑认为在高阶模型可靠时，尽可能使用高阶模型,  否则, 才使用低阶模型.\n\n回退模型的一般形式如下:\n$$\np_{smooth} (w_i \\mid w_{i-n+1}^{i-1}) =\n\\left \\{\n\t\\begin {aligned}\n\t\t&p_{MLE} (w_i \\mid  w_{i-n+1}^{i-1})    & c( w_{i-n+1}^{i-1}) > 0 \\\\\n\t   \t\t&\\alpha_{w_{i-n+1}^{i-1}} p_{smooth}(w_i \\mid  w_{i-n+2}^{i-1})  &  otherwise\\\\\n\t\\end {aligned}\n\\right .\n$$\n其中: $\\alpha_{w_{i-n+1}^{i-1}}$ 是为了保证 $\\sum_i p_{smooth} (w_i \\mid w_{i-n+1}^{i-1}) = 1$ 的归一化参数.\n\n常见的回退平滑模型如下:\n\n- [Katz平滑](https://en.wikipedia.org/wiki/Katz%27s_back-off_model)\n\n\n- 绝对减值法\n\n\n- [Kneser–Ney平滑](https://en.wikipedia.org/wiki/Kneser%E2%80%93Ney_smoothing) :绝对减值法的改进\n\n\n\n回退模型和插值模型是两种比较相似的平滑方法, 先总结其异同如下:\n\n- 在回退模型和插值模型中，当高阶n 元组未出现时，使用低阶n元组估算高阶n元组的概率分布\n- 在回退模型中，高阶n元组一旦出现，就不再使用低阶n元组进行估计\n- 在插值模型中，无论高阶n元组是否出现，低阶n元组都会被用来估计高阶n元组的概率估值\n\n# 总结\n\n语言模型 : 语言中每个句子的概率\n\n语言建模\n\nn-gram <- 马尔科夫假设\n\n​\tn的选择\n\n​\t参数估计(相对频率法) <- MLE\n\n​\t平滑\n\n# 参考资料\n\nhttps://courses.engr.illinois.edu/cs447/fa2017/Slides/Lecture04.pdf\n\n[自然语言处理NLP中的N-gram模型](https://blog.csdn.net/songbinxu/article/details/80209197)\n\n\n\n\n\n","tags":["NLP"],"categories":["Model"]},{"title":"dropout","url":"%2Fblog%2Fdropout.html","content":"\n\n\n# Dropout简介\n\n##  Dropout 解决过拟合\n\n先介绍dropout是干什么的。\n\n在机器学习的模型中，如果模型的参数太多，而训练样本又太少，训练出来的模型很容易产生过拟合的现象。在训练神经网络的时候经常会遇到过拟合的问题，过拟合具表现在：模型在训练数据上损失函数值较小，预测准确率较高；但是在验证数据集上损失函数值比较大，预测准确率较低。如下图中 baseline的交叉熵损失函数在训练集和验证集上的曲线所示：随着训练迭代次数的增加，训练集和验证集的gap越来越大。\n![](dropout/dropout.png)\n\nDropout可以比较有效的缓解过拟合的发生，在一定程度上达到正则化的效果。\n\n## 1.2 Dropout 相关的几篇论文\n\n在2012年，Hinton在其论文《Improving neural networks by preventing co-adaptation of feature detectors》中提出Dropout。当一个复杂的前馈神经网络被训练在小的数据集时，容易造成过拟合。为了防止过拟合，可以通过阻止特征检测器(神经网络中的节点)的共同作用来提高神经网络的性能。\n\n在2012年，Alex、Hinton在其论文《ImageNet Classification with Deep Convolutional Neural Networks》中用到了Dropout算法，用于防止过拟合。并且，这篇论文提到的AlexNet网络模型引爆了神经网络应用热潮，并赢得了2012年图像识别大赛冠军，使得CNN成为图像分类上的核心算法模型。\n\n随后，又有一些关于Dropout的文章《Dropout:A Simple Way to Prevent Neural Networks from Overfitting》、《Improving Neural Networks with Dropout》、《Dropout as data augmentation》。\n\nDropout可以作为训练深度神经网络的一种trick供选择。在每个训练批次中，通过忽略一半的特征检测器（让一半的隐层节点值为0），可以明显地减少过拟合现象。这种方式可以减少特征检测器（隐层节点）间的相互作用，检测器相互作用是指某些检测器依赖其他检测器才能发挥作用。\n\nDropout说的简单一点就是：我们在前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征，如下图所示：\n\n![](dropout/dropout-prin-0.png)\n\n\n\n# 神经网络中dropout的工作原理\n\n假设我们要训练这样一个神经网络，如图所示。\n\n![](dropout/dropout-prin-1.png)\n\n输入是x输出是y，正常的流程是：我们首先把x通过网络前向传播，然后把误差反向传播以决定如何更新参数让网络进行学习。使用Dropout之后，过程变成如下：\n\n（1）首先随机（临时）删掉网络中一半的隐藏神经元，输入输出神经元保持不变（图3中虚线为部分临时被删除的神经元）\n\n![](dropout/dropout-prin-2.png)\n\n（2） 然后把输入x通过修改后的网络前向传播，然后把得到的损失通过修改的网络反向传播，在没有被删除的神经元上按照随机梯度下降法更新对应的参数（w，b）。\n\n（3）继续重复 1、 2 两步：最终训练处一个完整的神经网络。\n\n后续则可以使用这个NN模型用于预测了。\n\n\n\n# Dropout 更深入探讨\n\n上文简单描述了 Dropout 的工作原理，下面我们深入到代码和数学原理层面了解一下。\n\n对于一个神经网络，变量定义如下：\n- $L$： hidden layer的数量， $l \\in \\{1, \\dots, L\\}$；\n- $z^{(l)}$: 第 $l$ 层的激活因子；\n- $y^{(l)}$: 第 $l$ 层的输出向量，也是第 $l+1$ 等的输入向量。\n- $W^{(l)}$ 和 $b^{(l)}$: 第 $l$ 层的 weights 和 biases\n\n\n在标准的神经网络的前向过程中， 第 $l$ 和 $l+1$层可以用下图和公式所示：\n\n![](dropout/standard-nn.png)\n$$\n\\begin {align}\nz_i^{(l+1)} &= w_i^{(l+1)} y^{(l)} + b_i^{(l+1)} \\\\\ny_i^{(l+1)} &= f(z_i^{(l+1)})\n\\end {align}\n$$\n其中 $f$ 为神经网络的激活函数。\n\n当使用dropout以后 前向传播可以用下图和公式表示：\n\n![](dropout/dropout-nn.png)\n\n\n$$\n\\begin {align}\nr_j^{(l)} &= \\mathrm{Bernoulli}(p) \\\\\n\\tilde{y}^{(l)} &= r_j^{(l)} \\times   y^{(l)} \\\\\nz_i^{(l+1)} &= w_i^{(l+1)} \\tilde{y}^{(l)} + b_i^{(l+1)} \\\\\ny_i^{(l+1)} &= f(z_i^{(l+1)})\n\\end {align}\n$$\n其中 $r^{(l)}$ 是一个向量，大小与其对应的隐藏层的节点数相同，其每个值相互独立，并且有概率 $p$ 的可能性是1，$1-p$ 的概率是0。 即上述公式中 Bernoulli 分布的含义。\n\n代码层面实现让某个神经元以概率$p$停止工作(输出值为0)，其实就是让它的激活函数值以概率$p$变为0。比如我们某一层网络神经元的个数为1000个，其激活函数输出值为$y_1, y_2, y_3, \\dots , y_{1000}$，我们dropout rate选择0.4，那么这一层神经元经过dropout后，1000个神经元中会有大约400个的值被置为0。\n\n下面我们从代码层面上看看dropout的实现：\n\n在 [CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/) 中提供展示了两种 dropout的实现逻辑：\n\n```python\np = 0.5  # probability of keeping a unit active. higher = less dropout\n\ndef train_step(X):\n    \"\"\" X contains the data \"\"\"\n    # forward pass for example 3-layer neural network\n    H1 = np.maximum(0, np.dot(W1, X) + b1) \n    U1 = np.random.rand(*H1.shape) < p  # first dropout mask\n    H1 *= U1  # drop!\n    H2 = np.maximum(0, np.dot(W2, H1) + b2) \n    U2 = np.random.rand(*H2.shape) < p  # second dropout mask\n    H2 *= U2  # drop!\n    out = np.dot(W3, H2) + b3\n    # backward pass: compute gradients... (not shown)\n    # perform parameter update... (not shown)\n\ndef predict(X):\n    # ensembled forward pass\n    H1 = np.maximum(0, np.dot(W1, X) + b1) * p  # NOTE: scale the activations\n    H2 = np.maximum(0, np.dot(W2, H1) + b2) * p  # NOTE: scale the activations\n    out = np.dot(W3, H2) + b3\n```\n\n可以看到在模型训练的 forward 环节 是严格按照上面的介绍的dropout的公式进行处理的。但是 模型的predict环节需要在每一个使用dropout的地方 乘以 概率 $p$ 来对该层的输出进行缩放。缩放的原因很简单：在训练的时候每个节点是用其上一层网络节点总数 乘以 $p$ 个节点计算得到的， 但是在predict环节却是使用了所有的上一层节点得到的，为了保持训练和预测一致，所以需要对其进行缩放。\n\n但是在预测环节乘以概率$p$ 不符合我们代码开发的逻辑， 总不能对所有现有模型单独开发一个 dropout版本的 predict函数。最好是所有的predict 函数都保持不变就可以实现 scale功能。其实是可以做到的。我们只需要在模型的训练阶段 对每一层dropout的输出进行缩放就可以了，逻辑代码如下：\n\n```python\np = 0.6 # probability of keeping a unit active. higher = less dropout\n\ndef train_step(X):\n  # forward pass for example 3-layer neural network\n  H1 = np.maximum(0, np.dot(W1, X) + b1)\n  U1 = (np.random.rand(*H1.shape) < p) / p # first dropout mask. Notice /p!\n  H1 *= U1 # drop!\n  H2 = np.maximum(0, np.dot(W2, H1) + b2)\n  U2 = (np.random.rand(*H2.shape) < p) / p # second dropout mask. Notice /p!\n  H2 *= U2 # drop!\n  out = np.dot(W3, H2) + b3\n  \n  # backward pass: compute gradients... (not shown)\n  # perform parameter update... (not shown)\n  \ndef predict(X):\n  # ensembled forward pass\n  H1 = np.maximum(0, np.dot(W1, X) + b1) # no scaling necessary\n  H2 = np.maximum(0, np.dot(W2, H1) + b2)\n  out = np.dot(W3, H2) + b3\n```\n\n可以看到 U1，U2计算的使用都 除以 p 即达到了缩放的功能， 在预测环境不需要做任何改动。\n\n在 keras代码中以 theano 为 backend时 dropout的实现如下，可以看到倒数第二行 `x /= retain_prob` 即是我们所说的在训练环境对使用dropout 的输出节点进行 缩放(scale)。 tensorflow的dropout代码跳转比较负责，需要的可以自行查找。\n\n```python\ndef dropout(x, level, noise_shape=None, seed=None):\n    \"\"\"Sets entries in `x` to zero at random,\n    while scaling the entire tensor.\n\n    # Arguments\n        x: tensor\n        level: fraction of the entries in the tensor\n            that will be set to 0.\n        noise_shape: shape for randomly generated keep/drop flags,\n            must be broadcastable to the shape of `x`\n        seed: random seed to ensure determinism.\n    \"\"\"\n    if level < 0. or level >= 1:\n        raise ValueError('Dropout level must be in interval [0, 1[.')\n    if seed is None:\n        seed = np.random.randint(1, 10e6)\n    if isinstance(noise_shape, list):\n        noise_shape = tuple(noise_shape)\n\n    rng = RandomStreams(seed=seed)\n    retain_prob = 1. - level\n\n    if noise_shape is None:\n        random_tensor = rng.binomial(x.shape, p=retain_prob, dtype=x.dtype)\n    else:\n        random_tensor = rng.binomial(noise_shape, p=retain_prob, dtype=x.dtype)\n        random_tensor = T.patternbroadcast(random_tensor,\n                                           [dim == 1 for dim in noise_shape])\n    x *= random_tensor\n    x /= retain_prob\n    return x\n```\n\n> 当前Dropout被大量利用于全连接网络，而且一般认为设置为0.5或者0.3，而在卷积网络隐藏层中由于卷积自身的稀疏化以及稀疏化的ReLu函数的大量使用等原因，Dropout策略在卷积网络隐藏层中使用较少。总体而言，Dropout是一个超参，需要根据具体的网络、具体的应用领域进行尝试。\n\n\n\n# 参考资料\n\n[深度学习中Dropout原理解析](https://blog.csdn.net/program_developer/article/details/80737724) (该blog为本文的主要参考，部分内容完全摘抄，基于扩展阅读后产生了本文)\n\nSrivastava, Nitish, et al. \"Dropout: a simple way to prevent neural networks from overfitting.\" *The Journal of Machine Learning Research* 15.1 (2014): 1929-1958.\n\n[http://cs231n.github.io/neural-networks-2/](http://cs231n.github.io/neural-networks-2/)\n\n","tags":["Regularization"],"categories":["Neural Networks"]},{"title":"Simhash","url":"%2Fblog%2FSimhash.html","content":"\nsimhash是一种**局部敏感hash**。即，假定两个字符串具有一定的相似性，在hash之后，仍然能保持这种相似性，就称之为局部敏感hash。simhash被Google用来在海量文本中去重。\n\n# SimHash算法思想\n\n假设我们有海量的文本数据，我们需要根据文本内容将它们进行去重。对于文本去重而言，目前有很多NLP相关的算法可以在很高精度上来解决，但是我们现在处理的是大数据维度上的文本去重，这就对算法的效率有着很高的要求。而局部敏感hash算法可以将原始的文本内容映射为数字（hash签名），而且较为相近的文本内容对应的hash签名也比较相近。SimHash算法是Google公司进行海量网页去重的高效算法，它通过将原始的文本映射为64位的二进制数字串，然后通过比较二进制数字串的差异进而来表示原始文本内容的差异。\n\n# SimHash流程实现\n\nsimhash是由 Charikar 在2002年提出来的，参考 [《Similarity estimation techniques from rounding algorithms》](http://dl.acm.org/citation.cfm?id=509965) 。 这个算法主要步骤如下：\n\n1. 分词：将Doc进行关键词抽取(其中包括分词和计算权重)，抽取出n个(关键词，权重)对， 即图中的多个`(feature, weight)`。 记为 `feature_weight_pairs = [fw1, fw2 … fwn]`，其中 `fwn = (feature_n,weight_n)`。\n2. hash：对每个**feature_weight_pairs**中的`feature`进行hash。 图中假设hash生成的位数bits_count = 6。\n3. 加权合并：然后对**hash_weight_pairs**进行位的纵向累加，如果该位是1，则`+weight`,如果是0，则`-weight`，最后生成bits_count个数字，如图所示是`[13, 108, -22, -5, -32, 55]`, 这里产生的值和hash函数所用的算法相关。\n4. sign：`[13,108,-22,-5,-32,55] -> 110001`这个就很简单啦，正1负0。\n\n现在通过这样的转换，我们把库里的文本都转换为simhash 代码，并转换为long类型存储，空间大大减少。\n\n# SimHash签名距离计算\n\n使用海明距离（Hamming distance）就可以计算出两个simhash的相似度。两个simhash对应二进制（01串）取值不同的数量称为这两个simhash的海明距离。举例如下： **1**01**01** 和 **0**01**10** 从第一位开始依次有第一位、第四、第五位不同，则海明距离为3。对于二进制字符串的a和b，海明距离为等于在a XOR b运算结果中1的个数（普遍算法）。\n\n# SimHash存储和索引\n\n经过simhash映射以后，我们得到了每个文本内容对应的simhash签名，而且也确定了利用汉明距离来进行相似度的衡量。那剩下的工作就是两两计算我们得到的simhash签名的汉明距离了，这在理论上是完全没问题的，但是考虑到我们的数据是海量的这一特点，我们是否应该考虑使用一些更具效率的存储呢？其实SimHash算法输出的simhash签名可以为我们很好建立索引，从而大大减少索引的时间，那到底怎么实现呢？\n\n我们使用的方法就是类似于hashmap的方案。在hashmap中我们要查找一个key值时，通过传入一个key就可以很快的返回一个value，hashmap的内部结构如下：\n\n![](Simhash/hashmap.png)\n\nhashmap的运作原理：如果我们需要得到key对应的value，需要经过这些计算，传入key，计算key的hashcode，得到7的位置；发现7位置对应的value还有好几个，就通过链表查找，直到找到v72。其实通过这么分析，如果我们的hashcode设置的不够好，hashmap的效率也不见得高。\n\n借鉴这个算法，来设计我们的simhash查找。通过顺序查找肯定是不行的，能否像hashmap一样先通过键值对的方式减少顺序比较的次数。看下图：\n\n![](Simhash/simhashindex.png)\n\n**存储**：\n1、将一个64位的simhash code拆分成4个16位的二进制码。（图上红色的16位）\n2、分别拿着4个16位二进制码查找当前对应位置上是否有元素。（放大后的16位）\n3、对应位置没有元素，直接追加到链表上；对应位置有则直接追加到链表尾端。（图上的 S1 — SN）\n\n**查找**：\n1、将需要比较的simhash code拆分成4个16位的二进制码。\n2、分别拿着4个16位二进制码每一个去查找simhash集合对应位置上是否有元素。\n2、如果有元素，则把链表拿出来顺序查找比较，直到simhash小于一定大小的值，整个过程完成。\n\n**原理**：\n借鉴hashmap算法找出可以hash的key值，因为我们使用的simhash是局部敏感哈希，这个算法的特点是只要相似的字符串只有个别的位数是有差别变化。那这样我们可以推断两个相似的文本，至少有16位的simhash是一样的。具体选择16位、8位、4位，大家根据自己的数据测试选择，虽然比较的位数越小越精准，但是空间会变大。分为4个16位段的存储空间是单独simhash存储空间的4倍。之前算出5000w数据是 382 Mb，扩大4倍1.5G左右，还可以接受：）\n\n通过这样计算，我们的simhash查找过程全部降到了1毫秒以下。就加了一个hash效果这么厉害？我们可以算一下，原来是5000w次顺序比较，现在是少了2的16次方比较，前面16位变成了hash查找。后面的顺序比较的个数是多少？ 2^16 = 65536， 5000w/65536 = 763 次。。。。实际最后链表比较的数据也才 763次！所以效率大大提高！\n\n到目前第一点降到3.6毫秒、支持5000w数据相似度比较做完了。还有第二点同一时刻发出的文本如果重复也只能保留一条和短文本相识度比较怎么解决。其实上面的问题解决了，这两个就不是什么问题了。\n\n- 之前的评估一直都是按照线性计算来估计的，就算有多线程提交相似度计算比较，我们提供相似度计算服务器也需要线性计算。比如同时客户端发送过来两条需要比较相似度的请求，在服务器这边都进行了一个排队处理，一个接着一个，第一个处理完了在处理第二个，等到第一个处理完了也就加入了simhash库。所以只要服务端加了队列，就不存在同时请求不能判断的情况。\n- simhash如何处理短文本？换一种思路，simhash可以作为局部敏感哈希第一次计算缩小整个比较的范围，等到我们只有比较700多次比较时，就算使用我们之前精准度高计算很慢的编辑距离也可以搞定。当然如果觉得慢了，也可以使用余弦夹角等效率稍微高点的相似度算法。\n\n\n\n# 适用情况\n\n通过大量测试，simhash用于比较大文本，比如500字以上效果都还蛮好，距离小于3的基本都是相似，误判率也比较低。但是如果我们处理的是微博信息，最多也就140个字，使用simhash的效果并不那么理想。看如下图，在距离为3时是一个比较折中的点，在距离为10时效果已经很差了，不过我们测试短文本很多看起来相似的距离确实为10。如果使用距离为3，短文本大量重复信息不会被过滤，如果使用距离为10，长文本的错误率也非常高。\n\n![](Simhash/simhash2.png)\n\n# python 工具（Simhash）\n\n安装\n\n```shell\npip install Simhash\n```\n\n查看simhash值\n\n``` python\nfrom simhash import Simhash\nprint '%x' % Simhash(u'I am very happy'.split()).value\n# 9f8fd7efdb1ded7f\n```\n\n计算两个simhash值距离\n\n```python\nhash1 = Simhash(u'I am very happy'.split())\nhash2 = Simhash(u'I am very sad'.split())\nprint hash1.distance(hash2)\n# 5\n```\n\nSimhashIndex使用\n\n```python\nfrom simhash import Simhash, SimhashIndex\n# 建立索引\ndata = {\n    u'1': u'How are you I Am fine . blar blar blar blar blar Thanks .'.lower().split(),\n    u'2': u'How are you i am fine .'.lower().split(),\n    u'3': u'This is simhash test .'.lower().split(),\n}\nobjs = [(id, Simhash(sent)) for id, sent in data.items()]\nindex = SimhashIndex(objs, k=10)  # k是容忍度；k越大，检索出的相似文本就越多\n# 检索\ns1 = Simhash(u'How are you . blar blar blar blar blar Thanks'.lower().split())\nprint index.get_near_dups(s1)\n# 增加新索引\nindex.add(u'4', s1)\n```\n\n# 参考资料\n\n[海量数据相似度计算之simhash和海明距离](http://www.lanceyan.com/tech/arch/simhash_hamming_distance_similarity.html)\n\n[海量数据相似度计算之simhash短文本查找](http://www.lanceyan.com/tech/arch/simhash_hamming_distance_similarity2-html.html)\n\n[simhash原理及使用](https://blog.csdn.net/qq_16912257/article/details/72156277)\n\n","tags":["Application"],"categories":["Application"]},{"title":"字串相似度-编辑距离","url":"%2Fblog%2Fedit-distance.html","content":"\n字符串编辑距离 即 Levenshtein 距离\n\npython库安装：\n\n​\tpip install python-Levenshtein\n\n使用\n\n```python\nimport Levenshtein\nstr1=\"abc\"\nstr2=\"bac\"\n```\n\n## edit distance(Levenshtein距离)\n\n一个字串转化成另一个字串最少的操作次数(包括插入、删除、替换) \n\n```python\nLevenshtein.distance(str1,str2)\n```\n\n## hamming distance(汉明距离)\n\n要求str1和str2必须长度一致 两个等长字串之间对应位置上不同字符的个数 \n\n```python\nLevenshtein.hamming(str1, str2)\n```\n\n## Levenshtein ratio(莱文斯坦比)\n\n计算公式 $$r = \\frac{sum - ldist}{sum}$$, 表示两个字符串的相似度。\n\n其中$\\text{sum}$是指str1 和 str2 字串的长度总和，$\\text{ldist}$是**类编辑距离** .其中：删除、插入依然+1，但是替换+2 。\n\n这样设计的目的：ratio('a', 'c')，$sum=2$,如果按编辑距离计算$ldist$，则$ratio =\\frac{2-1}2 = 0.5$,但是’a','c'没有重合，显然不合算，但是替换操作+2，就可以解决这个问题。\n\n```\nLevenshtein.ratio(str1, str2)\n```\n\n\n\npython-Levenshtein 还提供了Jaro distance 和 [Jaro–Winkler distance](https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance) 的文本距离的计算。用的时候再查。\n\n\n\n参考资料\n\nhttp://www.coli.uni-saarland.de/courses/LT1/2011/slides/Python-Levenshtein.html\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Application"],"categories":["Mathematics"]},{"title":"条件独立性","url":"%2Fblog%2FConditional-Independence.html","content":"\n# 条件独立性\n\n## 定义\n\n多变量概率分布中的一个重要概念就是条件独立性(conditional independence)。\n\n考虑三个变量$a$, $b$, $c$， 并且假设给定$b$, $c$的条件下$a$的条件概率分布不依赖于$b$的值，即：\n$$\np(a| b, c) = p(a |c)\n$$\n此时我们说，给定$c$的条件下，$a$条件独立于b。\n\n推论：给定$c$的条件下，对于$a$条件独立于b ，有下式成立：\n$$\n\\begin {aligned}\np(a,b|c) & = p(a|b,c)p(b|c)  \\\\\n         & =p(a|c)p(b|c) \\\\\n\\end {aligned}\n$$\n当使用概率模型时，条件独立性起着重要的作用，它简化了模型的结构，降低了模型的训练和推断的计算量。\n\n## 证明\n\n在图模型中，对于是三个变量$a$, $b$, $c$来说要证明 given $c$， $a$条件独立与$b$。按照 $c$ 是否被观察到分两种情况讨论：\n\n如果$c$被观察到了， given $c$， $a$条件独立与$b$ 等价于\n$$\np(a,b|c)  =p(a|c)p(b|c)\n$$\n如果$c$是隐变量， given $c$， $a$条件独立与$b$等价于\n$$\np(a,b)  =p(a)p(b)\n$$\n即，此时需要marginalizing with respect to $c$。\n\n# 贝叶斯网条件独立性（D-separation）\n\n如上文所述，条件独立性能够大大的简化模型结构, 降低模型的训练和推断的计算量。\n\n对于有向图来说，我们可以使用图中变量的联合分布来表示这张图,  即, 图中相关变量的条件概率的乘积.  表示的这些变量的联合分布时，怎么确定其中哪些变量之间是条件独立的呢？有两种方案：\n\n- 使用概率公式推导。该方法已经验证是非常复杂的一个过程。\n- d-separation。本文所要论述的内容。\n\n图模型的一个重要特征是，图中所有变量之间的条件独立性可以直接从图中读出来，不需要进行任何计算。从图中读出条件独立性的方法叫做d-separation，其中”d“即directed。\n\n## 三个例子\n\n下面首先使用三个简单的例子来说明d-separation中的核心概念。 这三个例子都是讨论 **given $c$， $a$条件独立与$b$**是否成立的。\n\n### tail-2-tail\n\n![](Conditional-Independence/tail-2-tail1.png)\n\n$$\n\\begin {aligned}\np(a,b,c) & = p(a|c)p(b|c)p(c) \\\\\n\\\\\np(a,b|c) & = \\frac{p(a,b,c)}{p(c)} \\\\\n         & = p(a|c)p(b|c)\n\\end {aligned}\n$$\n\ngiven $c$， $a$条件独立于$b$ 成立。\n\n\n![](Conditional-Independence/tail-2-tail0.png)\n\n$$\n\\begin {aligned}\np(a,b,c)  & = p(a|c)p(b|c)p(c) \\\\\n\\\\\np(a,b)    & =\\sum_c p(a,b,c) \\\\\n          & =\\sum_c p(a|c)p(b|c) p(c) \\neq p(a)p(b)\n\\end {aligned}\n$$\ngiven $c$， $a$条件独立于$b$ 不成立。\n\n### head-2-tail\n\n\n\n![](Conditional-Independence/head-2-tail1.png)\n\n$$\n\\begin {aligned}\np(a,b,c)  & =p(a)p(c|a)p(b|c)\\\\\n\\\\\np(a,b|c)  & = \\frac{p(a,b,c)}{p(c)} \\\\\n          & = \\frac{p(a)p(c|a)p(b|c)}{p(c)} \\\\\n          & = p(a|c)p(b|c)\n\\end {aligned}\n$$\ngiven $c$， $a$条件独立于$b$ 成立。\n\n\n\n\n![](Conditional-Independence/head-2-tail0.png)\n\n$$\n\\begin {aligned}\np(a,b,c)  & =p(a)p(c|a)p(b|c)\\\\\n \\\\\np(a,b)    & =p(a)\\sum_c p(c|a)p(b|c)=p(a)p(b|a) \\neq p(a)p(b)\n\\end {aligned}\n$$\n\ngiven $c$， $a$条件独立于$b$ 不成立。\n\n### head-2-head\n\n\n\n![](Conditional-Independence/head-2-head1.png)\n$$\n\\begin {aligned}\np(a,b,c)  & =p(a)p(b)p(c|a,b) \\\\\n\\\\\np(a,b|c)  & =\\quad \\frac{p(a,b,c)}{p(c)} \\\\\n          & = \\frac{p(a)p(b)p(c|a,b)}{p(c)} \\neq p(a|c)p(b|c)\n\\end {aligned}\n$$\ngiven $c$， $a$条件独立于$b$ 不成立。\n\n\n\n![](Conditional-Independence/head-2-head0.png)\n\n$$\n\\begin {aligned}\np(a,b,c)  & =p(a)p(b)p(c|a,b) \\\\\n\\\\\np(a,b)    & =\\sum_c p(a,b,c) = p(a)p(b)\n\\end {aligned}\n$$\ngiven $c$， $a$条件独立于$b$ 成立。\n\n作为原因的多个因素(a,b)，即使它们之间是相互独立的，确定结果(c)之后这些原因就可能变的相关了。当结果(c)不作为观测变量的时候，原因是相互独立的，也叫做边缘独立（Marginal Independence）.\n\n如果一个节点$y$是$x$的一个子节点，则\n\n如果存在从结点$x$到结点$y$的一条路径，其中路径的每一步都沿着箭头的方向，那么我们说结点$y$是结点$x$的后代(descendant)。可以证明，在类似于上图中的head-2-head的路径中，如果结点$c$或者它的任意后代节点被观测到，那么路径会unblocked，即a和b是条件相关的。\n\n## 总结\n\n一个tail-2-tail结点或者head-2-tail结点使得一条路径**没有被阻隔(unblocked)**，当它被观测到时，它就\n阻隔了路径；\n\n一个head-2-head结点如果没有被观测到那么它阻隔了路径(block)，如果它被观测到或者他的后代节点被观测到了，\n那么路径就**没有被阻隔(unblocked)**了。\n\n|             | unobserved  |       observed        |\n| :---------: | :---------: | :-------------------: |\n| tail-2-tail |  unblocked  |      **blocked**      |\n| head-2-tail |  unblocked  |      **blocked**      |\n| head-2-head | **blocked** | unblocked(descendant) |\n\n## 定义\n\nd-separation研究的是：\n\n> **given C**，判断 A 和 B 是否是关于 C 条件独立的。\n>\n> 其中C是所有被观测到的点的子集。\n\n下面给出d-separation的定义。\n\n对于 DAG 图 G，如果A，B，C是三个**集合**（可以是单独的节点或者是节点的集合）C是由观测到的点组成的，为了判断 A 和 B 是否关于 C 条件独立的(即，在**给定/观测到**C时 A和B是否条件独立)， 我们考虑G中所有A和B之间的无向路径 。 对于其中的一条路径，如果她满足以下两个条件中的任意一条，则称这条路径是阻塞（block）的：\n\n（1）路径中存在某个节点 X 是 head-to-tial 或者tail-to-tail 节点，并且 X 是包含在 C 中的；\n\n（2）路径中存在某个节点 X 是 head-to-head节点，并且 X 或 X的儿子是不包含在 C 中的；\n\n如果 A，B 间所有的路径都是阻塞的，那么 A，B 就是关于 C 条件独立的；否则， A，B 不是关于 C 条件独立的。\n\n举例如下：\n\n\n\n![](Conditional-Independence/d-separation.png)\n\n\n\n对于图(a)， $A= \\{a\\},B=\\{b\\},C=\\{c\\}$ 。**given C**，判断 A 和 B 是否是关于 C 条件独立的。分析方法如下：\n\n1. 从a到b的无向路径上包含两个节点：e和f；\n2. e：head-to-head节点，其子节点属于C，不符合第（2）条，unblocked。\n3. f：tail-to-tail节点，f不属于C，不符合第（1）条，unblocked。\n\n结论：given C， A 和 B 是否是关于 C 条件独立的 **不成立**。\n\n对于图(b)， $A= \\{a\\},B=\\{b\\},C=\\{f\\}$ 。**given C**，判断 A 和 B 是否是关于 C 条件独立的。分析方法如下：\n\n1. 从a到b的无向路径上包含两个节点：e和f；\n2. e：head-to-head节点，e与其子节点不属于C，符合第（2）条，blocked。\n3. f：tail-to-tail节点，f属于C，符合第（1）条，blocked。\n\n结论：given C， A 和 B 是否是关于 C 条件独立的 **成立**。\n\n\n\n# 马尔可夫随机场的条件独立性\n\n在有向图的情形下，我们看到可以通过使用被称为d-separation的图检测法判断一个特定的条件独立性质是否成立。这涉及到判断链接两个结点集合的路径是否被\"阻隔\"(blocked), 其中涉及到的三种情形(head-2-head, head-2-tail, tail-2-tail)中head-2-head是比较特殊的(D-separation的第二个条件)。\n\n对应于无向图模型。通过移除图中链接的方向性，一个结点和另一个结点的非对称性也被移除了，因此head-2-head结点的特殊性质也就不再存在了。\n\n## 第一种方法：\n\n假设在一个无向图中，我们有三个结点集合，记作A，B， C。我们考虑条件独立性质，其中C是被观测点的集合。\n考虑连接集合A的结点和集合B的结点的所有可能路径。如果所有这些路径 **都** 通过了集合C中的一个或多个结点，那么所有这样的路径都被“阻隔”(blocked)，因此条件独立性质成立, 如果存在至少一条未被阻隔的路径，那么条\n件独立的性质不成立. \n\n这与d划分的准则完全相同，唯一的差别在于没有头到头的现象。因此，无向图的条件独立性的检测比有向图简单。\n\n## 第二种方法：\n\n另一种条件独立性的检测的方法是假设从图中把集合C中的结点以及与这些结点相连的链接全部删除，如果不存在一条从A中任意结点到B中任意结点的路径，那么条件独立的性质便定成立.\n\n举例：\n\n![](Conditional-Independence/markov-ci.png)\n\n如上图，其中从集合A中的任意结点到集合B中的任意结点的每条路径都通过集合C中的至少一个结点。所以given C，A与B条件独立。\n\n移除集合C中的所有节点和与之相关的连接，不存在一条从A中任意结点到B中任意结点的路径，所以given C，A与B条件独立。\n\n# 参考资料\n\nPattern Recognition and Machine Learning\n\n[概率图模型4：贝叶斯网络](https://blog.csdn.net/github_36326955/article/details/69569032#141-d-%E5%88%86%E7%A6%BB)\n\n\n\n\n\n\n\n\n\n","tags":["Bayesian"],"categories":["Mathematics"]},{"title":"python中类的实例化 __new__","url":"%2Fblog%2FInstance-New-in-Python.html","content":"\n\n\n\n\n`__new__()`是在新式类中新出现的方法，在Python2.7以前的版本在定义类时都要显示的继承object才能使用。\n\n**`__new__()`方法始终都是类的静态方法，即使没有被加上静态方法装饰器。**`__new__`方法接受的参数虽然也是和`__init__`一样，但`__init__`是在类实例创建之后调用。\n\nobject类中对`__new__()`方法的定义：\n\n```python\nclass object:\n  @staticmethod # known case of __new__\n  def __new__(cls, *more): # known special case of object.__new__\n    \"\"\" T.__new__(S, ...) -> a new object with type S, a subtype of T \"\"\"\n    pass\n```\n\n# **`__new__ `的作用**\n\n依照Python官方文档的说法:\n\n1. `__new__`方法主要是当你继承一些**不可变的class**时(比如int, str, tuple)， 提供给你一个自定义这些类的实例化过程的途径；\n2. 实现自定义的metaclass。\n\n首先我们来看一下第一个功能，具体我们可以用int来作为一个例子：\n\n假如我们需要一个永远都是正数的整数类型，通过继承int，我们可能会写出这样的代码。\n\n```python\nclass PositiveInteger(int):\n  def __init__(self, value):\n    super(PositiveInteger, self).__init__(self, abs(value))\n\ni = PositiveInteger(-3)\nprint i\n\n# -3\n```\n\n但运行后会发现，结果根本不是我们想的那样，我们任然得到了-3。这是因为对于int这种不可变的对象，我们只有重载它的`__new__`方法才能起到自定义的作用。\n\n```python\nclass PositiveInteger(int):\n  def __new__(cls, value):\n    return super(PositiveInteger, cls).__new__(cls, abs(value))\n\ni = PositiveInteger(-3)\nprint i\n\n# 3\n```\n\n关于[实现自定义的metaclass]我会在另一篇文章中单独论述。\n\n# 类的实例化\n\n接下来我们来了解一下，Python解释器是如何实例化一个类的：\n1. 当我们实例化`A`类对象时，Python中首先调用的是该`A`类对象的`__new__`方法，如果该`A`类对象没有定义`__new__`方法，则去父类中依次查找，直到`object`类；\n2. `object`类有一个`__new__`方法，该方法接收一个参数(一般为类对象)，将该参数进行实例化并返回一个对象；\n3. Python解释器会将调用`__new__`方法并将`A`类对象作为第一个参数传入，最后会返回一个实例对象(这个对象就是`A`类的实例对象，我们称之为`a1`)；`__new__()`必须要有返回值，返回实例化出来的实例，可以`return`父类`__new__()`出来的实例，也可以直接将object的`__new__()`出来的实例返回。\n4. Python解释器默认会调用`a1`对象的`__init__`方法，并将参数传入。\n\n## 实例化举例\n\n### 实例化自身\n\n\n```python\nmyclass = MyClass(*args, **kwargs)\n```\n\n正如以上所示，一个类可以有多个位置参数和多个命名参数，而在实例化开始之后，在调用 `__init__()`方法之前，Python首先调用`__new__()`方法：\n\n```python\ndef __new__(cls, *args, **kwargs):\n    return super(MyClass, cls).__new__(cls, *args, **kwargs)\n```\n\n第一个参数cls是当前正在实例化的类。\n\n如果（新式）类中没有重写`__new__()`方法，即在定义新式类时没有重新定义`__new__()`时 ，Python默认是调用该类的直接父类的`__new__()`方法来构造该类的实例，如果该类的父类也没有重写` __new__()`，那么将一直按此规矩追溯至object的`__new__()`方法，因为object是所有新式类的基类。\n\n而如果新式类中重写了`__new__()`方法，那么你可以自由选择**任意一个与该类有继承关系的类**的`__new__()`方法来制造实例，包括这个新式类的所有前代类和后代类，但是**不能造成递归死循环**。\n\n### 实例化祖先类\n\n```python\nclass Foo(object):\n    def __init__(self, *args, **kwargs):\n        pass\n\n    def __new__(cls, *args, **kwargs):\n        return object.__new__(cls, *args, **kwargs)\n    \nclass Child(Foo):\n    def __new__(cls, *args, **kwargs):\n        return object.__new__(cls, *args, **kwargs)  # 直接调用了父类的父类的 new方法\n\nchild = Child()\n```\n\n### 实例化后代类\n\n```python\nclass Foo(object):\n    def __init__(self, *args, **kwargs):\n        self.name = 'Foo'\n        print 'Foo init'\n        \n    def __new__(cls, *args, **kwargs):\n        print 'Foo new'\n        return super(Foo, cls).__new__(Stranger, *args, **kwargs)   #此处实例化的是Stranger\n    \nclass Stranger(Foo):\n    def __init__(self, *args, **kwargs):\n        self.name = 'Stranger'\n        print 'Stranger init'\n    \n    def __str__(self):\n        return 'stranger'\n    \nfoo = Foo()  # 此事调用了Foo的__new__ 方法和 Stranger的__init__方法\nprint foo.name\n\n# Foo new\n# Stranger init\n# Stranger\n```\n\n### 实例化无继承关系的类\n\n> 在[文章](https://www.cnblogs.com/liunnis/p/4634417.html)中实验说明如果`__new__()`没有返回`cls`（即当前类）的实例，那么当前类的`__init__()`方法是不会被调用的。如果`__new__()`返回其他类的实例，那么只会调用被返回的那个类的构造方法。\n\n我也尝试了这个实验，实验结论与以上说法不同：\n\n如果`__new__()`返回其他类的实例，那么只会实例化其他类，但不会调用其他类的`__init__`方法。\n\n```python\nclass Foo(object):\n    def __init__(self, *args, **kwargs):\n        self.name = 'Foo'\n        print 'Foo init'\n        \n    def __new__(cls, *args, **kwargs):\n        print 'Foo new'\n        return super(Foo, cls).__new__(Stranger, *args, **kwargs)   #此处实例化的是Stranger\n    \nclass Stranger(object):\n    def __init__(self, *args, **kwargs):\n        self.name = 'Stranger'\n        print 'Stranger init'\n    \n    def __str__(self):\n        return 'stranger'\n    \nfoo = Foo()  # 只调用了Foo的__new__方法实例化了Stranger。\nprint type(foo)\nprint foo.name  # 可以发现name没有被赋值，__init__方法没有被调用\n\n# Foo new\n# <class '__main__.Stranger'>\n# ---------------------------------------------------------------------------\n# AttributeError                            Traceback (most recent call last)\n# <ipython-input-38-15ce8af5d890> in <module>()\n#      20 foo = Foo()\n#      21 print type(foo)\n# ---> 22 print foo.name\n\n# AttributeError: 'Stranger' object has no attribute 'name'\n```\n\n# 参考资料\n\n[Python中的__new__()方法与实例化](https://www.cnblogs.com/liunnis/p/4634417.html)\n\n[实例解析Python中的__new__特殊方法](https://www.jb51.net/article/85724.htm)\n\n\n\n\n\n","tags":["Python"],"categories":["Python"]},{"title":"Sum Rule and Product Rule in Probability","url":"%2Fblog%2FSum-Rule-and-Product-Rule-in-Probability.html","content":"\n# 举例\n\n假设我们有两个盒子，一个红色的，一个蓝色的，红盒子中有2个苹果和6个橘子，蓝盒子中有3个苹果和1个橘子。现在假定我们随机选择一个盒子，从这个盒子中我们随机选择一个水果，观察选择了哪种水果，然后放回盒子中。我们重复这个过程很多次。\n\n在这个例子中，我们要选择的盒子的颜色是一个随机变量，这个随机变量可以取两个值中的一个，即r(红盒子)或b(蓝盒子)。类似地，水果的种类也是一个随机变量 ，它可以取a（苹果）或者o（橘子）。\n\n![](Sum-Rule-and-Product-Rule-in-Probability/box-fruit.png)\n\n# 推导\n\n这个例子涉及到两个随机变量$X$和$Y$ (如盒子的颜色和水果的种类)。我们假设$X$可以取任意的$x_i$ ，其中$i = 1,\\dots, M$ ，并且$Y$ 可以取任意的$y_j$ ，其中$j = 1,\\dots,L$。考虑一共进行$N$ 次试验，其中我们对$X$和$Y $都进行取样，把$X = x_i$ 且$Y = y_j$ 的试验的数量记作$n_{ij}$ 。并且，把$X$取值$x_i$（与$Y$ 的取值无关）的试验的数量记作$c_i$ ，把$Y $取值$y_j$ 的试验的数量记作$r_j$ 。\n\n![](Sum-Rule-and-Product-Rule-in-Probability/sum-product.png)\n\n对于两个随机变量$X$和$Y$，$X$可能的取值为$\\{x_1, \\dots, x_M \\}$， $Y$可能取值为$\\{x_1, \\dots, x_L \\}$。\n\n那么 $X=x_i, Y=y_j$ 的联合概率为:\n$$\np(X=x_i, Y=y_j)=\\frac{n_{ij}}{N}\n$$\n那么 $X=x_i$ 的概率为:\n$$\np(X=x_i)=\\frac{c_i}{N} = \\sum_{j=1}^L p(X=x_i, Y=y_j)\n$$\n这是概率的加和规则（**sum rule**）。$p(X=x_i)$也被称为边 缘 概 率(**marginal probability**)，因为它通过把其他变量（本例中的Y ）边缘化或者加和得到。\n\n给定$X = x_i$ ，$Y = y_j$ 的条件概率（conditional probability）：\n$$\np(Y = y_j | X = x_i)=\\frac{n_{ij}}{c_i}\n$$\n那么：\n$$\np(X=x_i, Y=y_j)=\\frac{n_{ij}}{N} = \\frac{n_{ij}}{c_i}\\cdot \\frac{c_i}{N} = p(Y = y_j | X = x_i)p(X=x_i)\n$$\n这被称为概率的乘积规则（product rule）。\n\n# 总结\n\nsum  rule, 其实就是全概率公式\n$$\np(X)= \\sum_{Y} p(X, Y)\n$$\nproduct rule, 其实就是条件概率\n$$\np(X,Y)=p(Y|X)p(X)\n$$\n\n\n# 参考资料\n\nPattern Recognition and Machine Learning","tags":["Probability"],"categories":["Mathematics"]},{"title":"贝叶斯网-贝叶斯回归","url":"%2Fblog%2FBayesian-Networks-regression.html","content":"\n# 概述\n\n概率在现代机器学习模型中起着重要的作用。然而我们会发现，使用概率分布的图形表示进行分析很有好处。这种概率分布的图形表示被称为**概率图模型**（probabilistic graphical models）。概率模型的这中图形表示有如下性质：\n\n- 它们提供了一种简单的方式将概率模型的结构可视化，可以用于设计新的模型。\n- 通过观察图形，我们可以更深刻地认识模型的性质，如条件独立性。\n- 在复杂模型中，复杂的计算可以表示称为图的操作。（这些图的操作实际上代表了复杂的数据表达式的推导）\n\n一个图有两部分组成节点（nodes）和连接（links）。其中节点表示模型中的变量，连接表示节点之间的关系。根据连接是否具有方向性可以将概率图模型分为两类：\n\n1. **贝叶斯网**(Bayesian Networks)： 连接具有方向，用箭头表示方向，连接的方向也表示了变量之间的条件关系，如A-->B对应条件概率$p(B|A)$。贝叶斯网也称为有向图模型(directed graphical models)。有向图对于表达随机变量之间的因果关系很有用。\n2. **马尔科夫随机场**(Markov random fields)： 连接无方向性，也称为无向图模型(undirected graphical models)。无向图对于表示随机变量之间的软限制比较有用。\n\n为了求解推断问题，通常比较方便的做法是把有向图和无向图都转化为一个不同的表示形式，被称为**因子图**(factor graph)。\n\n本文讨论有贝叶斯网。\n\n贝叶斯网络是贝叶斯方法的扩展。它描述的是贝叶斯模型，比如贝叶斯线性回归模型，贝叶斯逻辑回归模型。\n\n# 数学表达式与图的对应\n\n如上文所述，图模型将数学表达式与图对应起来，从而提供了一种简单的方式将概率模型的结构可视化。\n\n在有向图模型中是怎样将复杂的概率表达式和图对应起来的？\n\n直接举例如下：\n\n![](Bayesian-Networks-regression/Bayesian-Networks01.png)\n\n根据上图可以直接将所有随机变量的联合概率分布分解为下式的右边，多个因子的乘积。\n$$\np(x_1,x_2,x_3,x_4,x_5,x_6,x_7) = p(x_1)p(x_2)p(x3)p(x_4|x_1,x_2,x_3)p(x_5|x_1,x_3)p(x_6|x_4)p(x_7|x_4,x_5)\n$$\n\n具体理论请见PRML 8.1。\n\n对于有$K$个节点的图，这$K$个节点的联合分布可以表示为：\n$$\np(\\mathbf X) = \\prod_{k=1}^K p(x_k|pa_k)\n$$\n其中$pa_k$是节点$x_k$的所有父节点的集合，$\\mathbf XS = \\{ x_1, \\dots x_K\\}$ 。\n\n贝叶斯网络这的图必须是有向无环图。\n\n# 贝叶斯回归的图模型\n\n先回顾一下贝叶斯回归。\n\n假设训练集有N个样本，样本集的特征用$\\mathrm X$表示，$x_i$表示第$i$个样本。样本集的lable值用$\\mathrm T$表示，$t_i$表示第$i$个样本的lable值。即  $\\mathbf{X}\\equiv (x_{1} \\dots x_{N})^{\\mathrm{T}}$，$\\mathrm{T}=\\{t_{1} \\dots t_{N} \\}^{\\mathrm{T}}$ ，样本集表示为$\\mathcal D = \\{\\mathrm X, \\mathrm{T} \\}$ 。 基于该数据集训练一个回归模型$y(x;\\mathrm w)$ ，使用该模型根据新数据的特征预测其lable值。\n\n线性回归：$y(x ,\\mathrm w) = \\mathrm w ^{\\mathrm T} x $\n\n在回归问题中，认为lable值$t$服从均值为$y(x,\\mathrm w)$，方差为$\\beta^{-1}$的**高斯分布**。\n$$\np(t|x,\\mathrm w, \\beta)=\\mathcal N(t|y(x , \\mathrm w),\\beta^{-1})\n$$\n$\\beta$为高斯噪声，反应的是样本集的采样误差即噪声。\n\n贝叶斯学派认为模型中的参数$\\mathrm w$是一个不确定的值，使用概率分布对其进行建模。此处我们假设$\\mathrm{w}$的是服从均值为$0$方差为${\\alpha }^{-1}\\mathbf{I}$的高斯分布(也可以进行其他假设，其他情况可参考[贝叶斯线性回归与贝叶斯逻辑回归](https://weirping.github.io/blog/Bayesian-Probabilities-in-ML.html))。\n$$\np(\\mathrm{w}|\\alpha )=\\ \\mathcal{N}(\\mathrm{w}|0,{\\alpha }^{-1}\\mathbf{I})=(\\frac{\\alpha }{2\\pi })^{(M +1)/2}\\ \\exp \\{-\\frac{\\alpha }{2}\\mathrm{w}^{\\mathrm{T}}\\mathrm{w}\\}\n$$\n总结一下上面涉及到到符号：\n\n| 符号           | 含义                  |\n| ------------ | ------------------- |\n| $x$ or $x_i$ | 一个样本的特征             |\n| $\\mathbf X$  | 样本集的特征              |\n| $t$ or $t_i$ | 一个样本的lable          |\n| $\\mathrm T$  | 样本集的lable           |\n| $\\mathbf w$  | 模型的参数               |\n| $\\beta$      | 样本记得噪声              |\n| $\\alpha$     | $\\mathbf w$所服从分布的参数 |\n\n\n\n**贝叶斯网络考虑的主要是随机变量。与之等价的是所有随机变量的联合分布**那么在贝叶斯模型中的随机变量有哪些呢？\n\n在模型训练阶段只有$\\mathbf w$和$\\mathrm T =(t_1,...,t_N)$是随机变量，  $\\mathbf{X}= (x_{1} \\dots x_{N})^{\\mathrm{T}}$， $\\beta$ 和$\\alpha$被称为deterministic parameters，他们是模型的（超）参数而不是随机变量。\n\n## 随机变量的贝叶斯网\n\n所有随机变量的联合分布可以表示为：\n$$\np(\\mathrm T,  \\mathbf w)=p(\\mathbf w)\\prod _{n=1}^{N}p(t_n|\\mathbf{w})\n$$\n注意，每一个样本中的lable $t$ 都是联合分布中的一个元素，也是图模型的一个节点。使用圆圈表示随机变量，其图模型表示为如下如所示。\n\n\n\n![](Bayesian-Networks-regression/line-bayesian01.png)\n\n可以看到上图中需要显示重复表示$N$个$t$节点，太复杂了。对于重复的节点可以改成下图的表示方法。使用一个方框(box)表示重复节点，其中右下角的$N$ 表示重复次数。\n\n![](Bayesian-Networks-regression/line-bayesian02.png)\n\n## 增加模型参数\n\n有时候显示的表达出模型的参数，对于问题的分析是有帮助的。包含模型参数的随机变量的联合分布表示如下。\n$$\np(\\mathrm T,  \\mathbf w | \\mathbf{X},\\alpha ,\\beta)=p(\\mathbf w|\\alpha )\\prod _{n=1}^Np(t_n|\\mathbf w,x_n,\\beta)\n$$\n在图模型中，模型参数表示为实心小圆点。\n\n![](Bayesian-Networks-regression/line-bayesian03.png)\n\n## observed variables\n\n在模型训练过程中，所有的随机变量 $\\mathrm T =(t_1,...,t_N)$ 对于模型来说都是已知的，即观测到的变量(observed variables)。 相应的，$\\mathbf w$ 是未被观测到的，称为隐变量(latent variable)。\n\n在贝叶斯网中，观测到的变量使用实心圆圈表示，隐变量使用空心圆圈表示。如下图所示：\n\n![](Bayesian-Networks-regression/line-bayesian04.png)\n\n## 增加预测变量\n\n我们的最终目标是对新输入的变量进行预测。假设给定一个输如值$\\hat x$，我们想找到以观测数据为条件的对应的$\\hat t$的概率分布。描述这个问题的图模型如下图所示：\n\n![](Bayesian-Networks-regression/line-bayesian05.png)\n\n这个模型的所有随机变量的联合分布为:\n$$\np(\\hat t,  \\mathrm T,  \\mathbf w | \\mathbf{X},\\alpha ,\\beta)=\\{\\prod _{n=1}^Np(t_n|\\mathbf w,x_n,\\beta)\\}p(\\mathbf w|\\alpha )p(\\hat t|\\hat x, \\mathbf w,\\beta)\n$$\n\n## 总结\n\n- 使用圆圈表示随机变量；\n\n- 观测到的变量使用实心圆圈表示，隐变量使用空心圆圈表示；\n\n- 使用一个方框(box)表示重复节点，其中右下角的$N$ 表示重复次数；\n\n- 模型参数表示为实心小圆点，连随机变量的联合分布中是条件变量部分，如$p(\\mathrm T,  \\mathbf w | \\mathbf{X},\\alpha ,\\beta)$；\n\n\n# 参数的后验分布\n\n对于训练数据来书，所有随机变量的联合分布表示如下：\n$$\np(\\mathrm T,  \\mathbf w | \\mathbf{X},\\alpha ,\\beta)=p(\\mathbf w|\\alpha )\\prod _{n=1}^Np(t_n|\\mathbf w,x_n,\\beta)\n$$\n根据贝叶斯公式有参数$\\mathbf w$的后验分布：\n$$\np( \\mathbf w |\\mathrm T,  \\mathbf{X},\\alpha ,\\beta) = \\frac {p(\\mathrm T,  \\mathbf w | \\mathbf{X},\\alpha ,\\beta)}{p(\\mathrm T|\\mathbf{X},\\alpha ,\\beta)}\n$$\n其中$\\mathrm T$是观察到的变量，$p(\\mathrm T|\\mathbf{X},\\alpha ,\\beta)$ 是一个常数，所以：\n$$\np( \\mathbf w |\\mathrm T,  \\mathbf{X},\\alpha ,\\beta) \\propto p(\\mathrm T,  \\mathbf w | \\mathbf{X},\\alpha ,\\beta) = p(\\mathbf w|\\alpha )\\prod _{n=1}^Np(t_n|\\mathbf w,x_n,\\beta)\n$$\n\n# 预测分布\n\n由公式\n$$\np(\\hat t,  \\mathrm T,  \\mathbf w | \\mathbf{X},\\alpha ,\\beta)=\\{\\prod _{n=1}^Np(t_n|\\mathbf w,x_n,\\beta)\\}p(\\mathbf w|\\alpha )p(\\hat t|\\hat x, \\mathbf w,\\beta)\n$$\n对于新数据$\\hat t$在给定训练数据集$\\{\\mathbf{X},\\mathrm T\\}$时的预测分布\n$$\np(\\hat t | \\mathbf{X},\\mathrm T, \\alpha ,\\beta) = \\frac {p(\\hat t,  \\mathrm T | \\mathbf{X},\\alpha ,\\beta)}{p(\\mathrm T|\\mathbf{X},\\alpha ,\\beta)}\n$$\n其中$\\mathrm T$是观察到的变量，$p(\\mathrm T|\\mathbf{X},\\alpha ,\\beta)$ 是一个常数，所以：\n$$\np(\\hat t | \\mathbf{X},\\mathrm T, \\alpha ,\\beta) \\propto p(\\hat t,  \\mathrm T | \\mathbf{X},\\alpha ,\\beta) = \\int p(\\hat t,  \\mathrm T,  \\mathbf w | \\mathbf{X},\\alpha ,\\beta) d{\\mathbf w}\n$$\n\n# 参考资料\n\nPattern Recognition and Machine Learning\n\n\n\n","tags":["Bayesian"],"categories":["Model"]},{"title":"Decorators in Python","url":"%2Fblog%2FDecorators-in-Python.html","content":"\n本文参考之前阅读过的文章[Python 函数装饰器](http://www.runoob.com/w3cnote/python-func-decorators.html) 和[Python进阶](https://eastlakeside.gitbooks.io/interpy-zh/content/decorators/)中关于装饰器的内容整理而得。原文中存在一些内容我已经较为熟悉，稍微带过，重点记录不太熟悉的部分。\n\n装饰器(Decorators)是 Python 的一个重要部分。简单地说：他们是修改其他函数的功能的函数。他们有助于让我们的代码更简短，也更Pythonic（Python范儿）。\n\n本文讨论如何写你自己的装饰器。在正式开始之前，先明确几个概念：\n\n- 在python中一切皆是对象。函数，类对事对象；\n- 一个函数可以是另一个函数的参数、返回值；\n- 函数内部可以定义函数\n- 闭包：python中的装饰器实际上是一个闭包。嵌套定义在非全局作用域里面的函数能够记住它在被定义的时候它所处的封闭命名空间。\n\n# 第一个装饰器\n\n## 装饰器函数\n\n```python\ndef a_decorator(a_func):\n\n    def wrapTheFunction():\n        print(\"I am doing some boring work before executing a_func()\")\n        a_func()\n        print(\"I am doing some boring work after executing a_func()\")\n    return wrapTheFunction\n\ndef a_function_requiring_decoration():\n    print(\"I am the function which needs some decoration to remove my foul smell\")\n\na_function_requiring_decoration()\n#outputs: \"I am the function which needs some decoration to remove my foul smell\"\n\na_function_requiring_decoration = a_decorator(a_function_requiring_decoration)\n\na_function_requiring_decoration()\n#outputs:I am doing some boring work before executing a_func()\n#        I am the function which needs some decoration to remove my foul smell\n#        I am doing some boring work after executing a_func()\n```\n\n上面的代码定义了一个需要装饰的函数`a_function_requiring_decoration`，用函数`a_decorator`作为装饰器，对`a_function_requiring_decoration`的行为进行修饰。\n\n装饰器的作用就是对一个函数进行封装，并且用这样或者那样的方式来对它的行为进行修饰。\n\n## 使用@符号\n\n现在你也许疑惑，我们在代码里并没有使用@符号？那只是一个简短的方式来生成一个被装饰的函数。这里是我们如何使用@来运行之前的代码。\n\n```python\ndef a_decorator(a_func):\n\n    def wrapTheFunction():\n        print(\"I am doing some boring work before executing a_func()\")\n        a_func()\n        print(\"I am doing some boring work after executing a_func()\")\n    return wrapTheFunction\n\n@a_decorator\ndef a_function_requiring_decoration():\n    print(\"I am the function which needs some decoration to remove my foul smell\")\n# 等价于 a_function_requiring_decoration = a_decorator(a_function_requiring_decoration)\n    \na_function_requiring_decoration()\n#outputs: I am doing some boring work before executing a_func()\n#         I am the function which needs some decoration to remove my foul smell\n#         I am doing some boring work after executing a_func()\n```\n\n可以发现@符号和`a_function_requiring_decoration = a_decorator(a_function_requiring_decoration)`是等价的。\n\n## 函数属性\n\n如果我们运行如下代码会存在一个问题：\n\n```python\nprint(a_function_requiring_decoration.__name__)\n# Output: wrapTheFunction\n```\n\n这并不是我们想要的！Ouput输出应该是“a_function_requiring_decoration”。这里的函数被warpTheFunction替代了。它重写了我们函数的名字和注释文档(docstring)。幸运的是Python提供给我们一个简单的函数来解决这个问题，那就是functools.wraps。我们修改上一个例子来使用functools.wraps：\n\n```python\nfrom functools import wraps\n\ndef a_decorator(a_func):\n\n    @wraps(a_func)\n    def wrapTheFunction():\n        print(\"I am doing some boring work before executing a_func()\")\n        a_func()\n        print(\"I am doing some boring work after executing a_func()\")\n    return wrapTheFunction\n\n@a_decorator\ndef a_function_requiring_decoration():\n    print(\"I am the function which needs some decoration to remove my foul smell\")\n\nprint(a_function_requiring_decoration.__name__)\n# Output: a_function_requiring_decoration\n```\n\n@wraps接受一个函数来进行装饰，并加入了复制函数名称、注释文档、参数列表等等的功能。这可以让我们在装饰器里面访问在装饰之前的函数的属性。\n\n# 应用场景\n\n现在我们来看一下装饰器在哪些地方特别耀眼，以及使用它可以让一些事情管理起来变得更简单。\n\n## 授权\n\n装饰器能有助于检查某个人是否被授权去使用一个web应用的端点(endpoint)。它们被大量使用于Flask和Django web框架中。这里是一个例子来使用基于装饰器的授权：\n\n```python\nfrom functools import wraps\n\ndef requires_auth(f):\n    @wraps(f)\n    def decorated(*args, **kwargs):\n        auth = request.authorization\n        if not auth or not check_auth(auth.username, auth.password):\n            authenticate()\n        return f(*args, **kwargs)\n    return decorated\n```\n\n## 日志\n\n日志是装饰器运用的另一个亮点。这是个例子：\n\n```python\nfrom functools import wraps\n\ndef logit(func):\n    @wraps(func)\n    def with_logging(*args, **kwargs):\n        print(func.__name__ + \" was called\")\n        return func(*args, **kwargs)\n    return with_logging\n\n@logit\ndef addition_func(x):\n   \"\"\"Do some math.\"\"\"\n   return x + x\n\n\nresult = addition_func(4)\n# Output: addition_func was called\n```\n\n# 带参数的装饰器\n\n来想想这个问题，难道`@wraps`不也是个装饰器吗？但是，它接收一个参数，就像任何普通的函数能做的那样。那么，为什么我们不也那样做呢？\n\n我们回到日志的例子，并创建一个包裹函数，能让我们指定一个用于输出的日志文件。\n\n```python\nfrom functools import wraps\n\ndef logit(logfile='out.log'):  # 此时是三层函数嵌套\n    def logging_decorator(func):\n        @wraps(func)\n        def wrapped_function(*args, **kwargs):\n            log_string = func.__name__ + \" was called\"\n            print(log_string)\n            # 打开logfile，并写入内容\n            with open(logfile, 'a') as opened_file:\n                # 现在将日志打到指定的logfile\n                opened_file.write(log_string + '\\n')\n            return func(*args, **kwargs)\n        return wrapped_function\n    return logging_decorator\n\n@logit()  # 等价于 myfunc1=logit()(myfunc1)\ndef myfunc1():\n    pass\n# 等价于 myfunc1=logit()(myfunc1)\n\nmyfunc1()\n# Output: myfunc1 was called\n# 现在一个叫做 out.log 的文件出现了，里面的内容就是上面的字符串\n\n@logit(logfile='func2.log')  # 等价于 myfunc1=logit(logfile='func2.log')(myfunc1)\ndef myfunc2():\n    pass\n\nmyfunc2()\n# Output: myfunc2 was called\n# 现在一个叫做 func2.log 的文件出现了，里面的内容就是上面的字符串\n```\n\n\n\n# 装饰器类\n\n现在我们有了能用于正式环境的logit装饰器，但当我们的应用的某些部分还比较脆弱时，异常也许是需要更紧急关注的事情。比方说有时你只想打日志到一个文件。而有时你想把引起你注意的问题发送到一个email，同时也保留日志，留个记录。这是一个使用继承的场景，但目前为止我们只看到过用来构建装饰器的函数。\n\n幸运的是，类也可以用来构建装饰器。那我们现在以一个类而不是一个函数的方式，来重新构建logit。\n\n```python\nfrom functools import wraps\n \nclass logit(object):\n    def __init__(self, logfile='out.log'):\n        self.logfile = logfile\n \n    def __call__(self, func):\n        @wraps(func)\n        def wrapped_function(*args, **kwargs):\n            log_string = func.__name__ + \" was called\"\n            print(log_string)\n            # 打开logfile并写入\n            with open(self.logfile, 'a') as opened_file:\n                # 现在将日志打到指定的文件\n                opened_file.write(log_string + '\\n')\n            # 现在，发送一个通知\n            self.notify()\n            return func(*args, **kwargs)\n        return wrapped_function\n \n    def notify(self):\n        # logit只打日志，不做别的\n        pass\n```\n\n这个实现有一个附加优势，在于比嵌套函数的方式更加整洁，而且包裹一个函数还是使用跟以前一样的语法：\n\n```python\n@logit(logfile='out.log')  # 等价于 myfunc1=logit(logfile='out.log')(myfunc1)\ndef myfunc1():\n    pass\n```\n\n现在，我们给`logit`创建子类，来添加email的功能(虽然email这个话题不会在这里展开)。\n\n```python\nclass email_logit(logit):\n    '''\n    一个logit的实现版本，可以在函数调用时发送email给管理员\n    '''\n    def __init__(self, email='admin@myproject.com', *args, **kwargs):\n        self.email = email\n        super(email_logit, self).__init__(*args, **kwargs)\n\n    def notify(self):\n        # 发送一封email到self.email\n        # 这里就不做实现了\n        pass\n```\n\n从现在起，`@email_logit`将会和`@logit`产生同样的效果，但是在打日志的基础上，还会多发送一封邮件给管理员。\n\n\n\n# 参考资料\n\nhttps://eastlakeside.gitbooks.io/interpy-zh/content/decorators/\n\n\n\n\n\n","tags":["Python"],"categories":["Python"]},{"title":"OneHotEncoder in Sklearn","url":"%2Fblog%2FOneHotEncoder-in-Sklearn.html","content":"\n最近在是有xgboost训练数据。在特征预处理阶段使用了`OneHotEncoder`来处理nominal类型的分类特征，模型训练好以后需要反过来分析特征，那么需要将原始数据中的特征与编码数据的特征对应起来。那么`OneHotEncoder`是怎么对应起来的呢？\n\n通过其官方的例子分析了一下，下面记录如下。\n\n`original data`：原始数据。\n\n`encode data`：经过one hot编码以后的数据。\n\n本文要分析的就是`OneHotEncoder`怎么将数据从`original data`变成`encode data`的。其规则如下：\n\n- 编码后的特征prepend在新数据上，并删除原始特征。非分类特征直接保留\n- `original data`中每个分类特征可以编码成新特征的个数依次记录在`n_values_`属性中\n- `original data`中每个分类特征在`encode data`中对应的新的特征维度选取方式记录在`feature_indices_`中\n\n\n\n\n\n```python\nfrom sklearn.preprocessing import OneHotEncoder\nori_data = [[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]]\nenc = OneHotEncoder(categorical_features=[1, 2])\nenc.fit(ori_data)\nprint 'categorical_features:', enc.categorical_features\nprint 'n_values:', enc.n_values_\nprint 'feature_indices:', enc.feature_indices_\nprint 'transform:', enc.transform([[1, 1, 1]]).toarray()\n\n# categorical_features: [1, 2]\n# n_values: [3 4]\n# feature_indices: [0 3 7]\n# transform: [[ 0.  1.  0.  0.  1.  0.  0.  1.]]\n```\n\n方法如下图所示\n\n![](OneHotEncoder-in-Sklearn/onehotencode.png)\n\n如上例子：\n\n- `original data`中第1、2两个维度为分类特征`categorical_features=[1, 2]`。\n- 这两个特征每个特征包含的可能的值的数量分别为3和4。 `n_values: [3 4]`\n- 产生的新的特征被prepend在`encode data`中靠前的若干列中。`feature_indices: [0 3 7]`:\n  - 原始特征的 首个分类特征 Feature1 => EncodeData[:, 0: 3]\n  - 原始特征的 第二个分类特征 Feature2 => EncodeData[:, 3: 7]\n\n参考资料\n\n[`sklearn.preprocessing`.OneHotEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#)\n\n","tags":["Sklearn"],"categories":["Sklearn"]},{"title":"Xgboost Rank in Sklearn","url":"%2Fblog%2Fxgboost-rank-in-sklearn.html","content":"\n\nxgboost提供了python接口，同时部分支持sklearn。在分类任务和回归任务中提供了XGBClassifier和XGBRegressor两个类，这两个类可以当做sklearn中的estimator使用，与sklearn无缝衔接。\n\nxgboost是支持rank任务的，但是它却没有提供rank功能的sklearn的支持。这对于像我这样的做ltr并且常用sklearn的开发人员是何等的不爽。\n\n自己动手丰衣足食，实现一下。命名为XGBRanker。\n\n*note: 在我正在做这个事的时候发现github上已经有人在做这个事了，[地址在此](https://github.com/bigdong89/xgboostExtension)， 通过阅读他的代码我发现关于group的处置方法，我们的想法是一样的。所以我有一部分代码直接参考了他的。*\n\n主要工作如下：\n\n1. XGBRanker中`fit`和`predict`的实现（参考https://github.com/bigdong89/xgboostExtension）\n2. ndcg_score的实现\n3. 支持GridSearchCV\n\n# group问题\n\n在sklearn中estimator的签名是这样的`estimater.fit(X, y)`和`estimator.predict(X, y)`，即，任务训练数据分为特征`X`和lable`y`。 但是在ltr任务中，数据分为三部分`X`、 `y`、 `group`，如下如所示：\n\n![](xgboost-rank-in-sklearn/dataset.png)\n\n为了保持签名一致，我的做法是将`group`合并到featrue中，在XGBRanker的`fit`，`predict`等方法中再将其分离。\n\n# ndcg_score\n\n评价ltr模型的一个重要标准就是ndcg。我实现了`ndcg_at_5_scoring, ndcg_at_3_scoring, ndcg_at_10_scoring` 三个指标。\n\nnote: 我没有使用继承`_BaseScorer`的方法实现以上三个scoring。如果有需求我在增加。\n\n\n\n# GridSearchCV\n\nsklearn提供了一些方便的工具用于Hyperparameter Tuning，如cross_val_score、validation curves和GridSearchCV，其中GridSearchCV是我常用的一个工具。\n\n其实在GridSearchCV中的fit方法签名`GridSearchCV.fit(X[, y, groups])`中可以看出GridSearchCV是支持groups参数的，通过阅读代码发现该参数是用于像`GroupKFold`这样的数据分割类做交叉验证的，这个groups参数并没有传如estimater中。这也可以从侧面说明sklearn中的estimater最初的设计上只考虑了回归，分类和聚类这样的传统任务，为考虑ltr类型的任务。\n\n# 代码介绍\n\n- ndcg_scorer.py：实现`ndcg_at_5_scoring, ndcg_at_3_scoring, ndcg_at_10_scoring`\n- rank_GroupKFold.py：用于ltr的交叉验证数据分割方法，基于GroupKFold.py实现。\n- rank_sklearn.py ： XGBRanker实现类\n- rank_util.py：工具类，用于第一列为group信息的数据\n- xgbranker_sklearn_example.ipynb： 实例代码，包括模型训练，预测，GridSearchCV的使用\n\n\n\n代码地址：https://github.com/Weirping/xgbranker_sklearn.git\n\n\n\n# 参考\n\nhttps://github.com/bigdong89/xgboostExtension\n","tags":["Sklearn"],"categories":["Sklearn"]},{"title":"Hyperparameter Tuning in Sklearn","url":"%2Fblog%2FHyperparameter-Tuning-in-Sklearn.html","content":"\n本文整理记录在sklearn中提供的模型调参的几个工具。涉及内容有cross_val_score、validation curves和GridSearchCV。\n\n在机器学习中一般存在两种类型的参数：\n\n- 从训练数据中学习到的参数，如逻辑回归的权重参数$W$ 。\n- 超参数(hyperparameters)，如逻辑回归中的正则化系数，决策树中的depth参数(控制树的深度)。\n\n超参数是在模型训练前人为指定的，它在一定程度上决定了模型效果的好坏。Sklean提供了来选取超参数的工具。\n\n# 交叉验证-模型效果的评价\n\n选取超参的标准是模型效果，通常我们对模型效果的评价方法就是模型的泛化能力。评价模型泛化能力的方法就是交叉验证。\n\n交叉验证设计到两个方面：1. 数据集分割； 2. 泛化指标计算。\n\n## 数据分割方式\n\nnote: 交叉验证的方法是和数据集分割方法紧密相连的，本节介绍数据分割方式也是介绍交叉验证方法。\n\n常用的交叉验证方法如下：\n\n- holdout cross-validation ：将数据分割成训练集和测试集，训练集用于模型训练，测试集用于评估模型效果(泛化能力)\n  holdout方法的不足: 对数据分割方法敏感，原始数据的不同分割方法影响模型效果。\n\n- holdout cross-validation V2：将原始数据分割为训练集和验证集和测试集，通过调整模型参数(超参)不停的在训练集上训练模型，并用验证集验证模型效果只能找到一个较好的模型，最后用测试集评估模型效果(泛化能力)。其实该方法已经具有了模型调优的功能。\n  holdout方法的不足: 对数据分割方法敏感，原始数据的不同分割方法影响模型效果。\n  ![](Hyperparameter-Tuning-in-Sklearn/holdout.png)\n\n- K-fold cross-validation： 随机将数据分割为$k$个folds，用其中的$k-1$个作为训练集，剩下的一个作为测试集。那么可以得到该模型在$k$个测试集上的表现。取其算法平均值做为模型的泛化能力\n  `from sklearn.model_selection import KFold`\n\n  ![](Hyperparameter-Tuning-in-Sklearn/kfold.png)\n\n- stratified k-fold cross-validation ：用在分类为题中，与K-fold相比stratified k-fold保证每一个fold中各类别的比例和整个训练数据集的比例相同。实验验证该方法相对于K-fold能够更好的平衡bias and variance。\n  `from sklearn.cross_validation import StratifiedKFold`\n\n- leave-one-out(LOO) cross-validation：是K-fold的极端形式，将K-fold中的k等于样本量。\n\n- **GroupKFold**： 用于搜索问题中，搜索训练数据是按照doc-query pair的形式存在的，一个query对应若干行，这就是一个group。在ltr问题中模型评价时计算的最小单位就是一个query，如ndcg。所以需要保证在训练集分割的时候一个query对应的这些行分割到相同的fold内。\n  `from sklearn.model_selection import GroupKFold`\n\nsklearn中提供的数据分割方式如下表所示：\n\n| 类名                                       | 描述                                       |\n| ---------------------------------------- | ---------------------------------------- |\n| [`model_selection.GroupKFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html#sklearn.model_selection.GroupKFold)([n_splits]) | K-fold iterator variant with non-overlapping groups. |\n| [`model_selection.GroupShuffleSplit`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html#sklearn.model_selection.GroupShuffleSplit)([…]) | Shuffle-Group(s)-Out cross-validation iterator |\n| [`model_selection.KFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)([n_splits, shuffle, …]) | K-Folds cross-validator                  |\n| [`model_selection.LeaveOneGroupOut`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut)() | Leave One Group Out cross-validator      |\n| [`model_selection.LeavePGroupsOut`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut)(n_groups) | Leave P Group(s) Out cross-validator     |\n| [`model_selection.LeaveOneOut`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut)() | Leave-One-Out cross-validator            |\n| [`model_selection.LeavePOut`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePOut.html#sklearn.model_selection.LeavePOut)(p) | Leave-P-Out cross-validator              |\n| [`model_selection.PredefinedSplit`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.PredefinedSplit.html#sklearn.model_selection.PredefinedSplit)(test_fold) | Predefined split cross-validator         |\n| [`model_selection.RepeatedKFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html#sklearn.model_selection.RepeatedKFold)([n_splits, …]) | Repeated K-Fold cross validator.         |\n| [`model_selection.RepeatedStratifiedKFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.html#sklearn.model_selection.RepeatedStratifiedKFold)([…]) | Repeated Stratified K-Fold cross validator. |\n| [`model_selection.ShuffleSplit`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit)([n_splits, …]) | Random permutation cross-validator       |\n| [`model_selection.StratifiedKFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold)([n_splits, …]) | Stratified K-Folds cross-validator       |\n| [`model_selection.StratifiedShuffleSplit`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html#sklearn.model_selection.StratifiedShuffleSplit)([…]) | Stratified ShuffleSplit cross-validator  |\n| [`model_selection.TimeSeriesSplit`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit)([n_splits, …]) | Time Series cross-validator              |\n\n\n\n##  泛化指标计算\n\n使用sklearn计算泛化指标的方式\n\n1. sklearn按照任务的不同分别定义了常用的模型评价指标 [`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) 。如**分类任务**中定义的`metrics.precision_score` 、`metrics.recall_score`。 **回归任务**中定义的`metrics.mean_squared_error`和`metrics.r2_score` 。聚类任务中定义的`metrics.mutual_info_score` 等。\n   预定义的metrics还有其对应的字符串名称，其对应关系见 [预定义的scoring参数](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) ，这些字符串常用语 scoring参数。\n\n2. score函数。sklearn中的estimator都会用一个默认的score函数，该函数可以用于计算预定义的泛化指标。\n   如下面的例子所示，lr模型默认的score函数就是`accuracy_score` 。\n\n   ```python\n   import numpy as np\n   from sklearn.datasets import load_iris\n   from sklearn.model_selection import StratifiedKFold\n   from sklearn.preprocessing import StandardScaler\n   from sklearn.pipeline import Pipeline\n   from sklearn.linear_model import LogisticRegression\n   from sklearn.metrics import accuracy_score\n   from sklearn.metrics import precision_score\n\n   np.random.seed(0)\n   iris = load_iris()\n   X, y = iris.data, iris.target\n   indices = np.arange(y.shape[0])\n   np.random.shuffle(indices)\n   X, y = X[indices], y[indices]\n   y = y > 1\n   pipe_lr = Pipeline([('scl', StandardScaler()),\n                       ('clf', LogisticRegression(penalty='l2', random_state=0, C=0.7))])\n   kfold = StratifiedKFold(n_splits = 5)\n   scores = []\n   for i, (train_ind, test_ind) in enumerate(kfold.split(X=X, y=y)):\n       trainX, trainy = X[train_ind], y[train_ind]\n       testX, testy = X[test_ind], y[test_ind]\n       pipe_lr.fit(trainX, trainy)\n       print \"[CV %d] default score %f\" % (i, pipe_lr.score(testX, testy))\n       test_pred = pipe_lr.predict(testX)\n       acc_score = accuracy_score(testy, test_pred)\n       print \"[CV %d] accuracy score %f\" % (i, acc_score)\n       pre_score = precision_score(testy, test_pred)\n       print \"[CV %d] precision score %f\" % (i, pre_score)\n       scores.append(acc_score)\n   print \"mean accuracy score %f\" % np.mean(scores)\n\n   # [CV 0] default score 1.000000\n   # [CV 0] accuracy score 1.000000\n   # [CV 0] precision score 1.000000\n   # [CV 1] default score 0.833333\n   # [CV 1] accuracy score 0.833333\n   # [CV 1] precision score 0.777778\n   # [CV 2] default score 1.000000\n   # [CV 2] accuracy score 1.000000\n   # [CV 2] precision score 1.000000\n   # [CV 3] default score 1.000000\n   # [CV 3] accuracy score 1.000000\n   # [CV 3] precision score 1.000000\n   # [CV 4] default score 0.933333\n   # [CV 4] accuracy score 0.933333\n   # [CV 4] precision score 0.833333\n   # mean accuracy score 0.953333\n   ```\n\n   \n\n3. `cross_val_score` \n   上面两种方式都需要使用循环才能得到每一组测试集的score。cross_val_score是对以上两种方式的简化，用户只需要传入cv(交叉验证分割器)和scoring(使用的泛化误差评价方式)，直接返回每一组测试集的score。\n\n   ```python\n   import numpy as np\n   from sklearn.datasets import load_iris\n   from sklearn.model_selection import StratifiedKFold\n   from sklearn.preprocessing import StandardScaler\n   from sklearn.pipeline import Pipeline\n   from sklearn.linear_model import LogisticRegression\n   from sklearn.model_selection import cross_val_score\n\n   np.random.seed(0)\n   iris = load_iris()\n   X, y = iris.data, iris.target\n   indices = np.arange(y.shape[0])\n   np.random.shuffle(indices)\n   X, y = X[indices], y[indices]\n   y = y > 1\n\n   pipe_lr = Pipeline([('scl', StandardScaler()),\n                       ('clf', LogisticRegression(penalty='l2', random_state=0, C=0.7))])\n\n   kfold = StratifiedKFold(n_splits = 5)\n\n   scores = cross_val_score(estimator=pipe_lr, \n                            X=X, \n                            y=y, \n                            #cv=5,  # 可以为一个数组，该例中使用 5-fold的交叉验证\n                            cv=kfold, # 也可以使用一个 split对象\n                            scoring=None, # None：使用estimator的score函数；string：预定义的metrics；callable：自定义metrics，签名需为scorer(estimator, X, y)\n                            n_jobs=1)\n   print 'CV accuracy scores: %s' % scores\n   print \"mean accuracy score %f +/- %f\" % (np.mean(scores) ,np.std(scores))\n\n   # CV accuracy scores: [ 1.          0.83333333  1.          1.          0.93333333]\n   # mean accuracy score 0.953333 +/- 0.065320\n   ```\n\n# GridSearchCV\n\n交叉验证是评估具有相同超参的模型的泛化能力的方法，即，一个交叉验证中使用的模型超参是一样的。所以对于同一个模型来说，交叉验证实际上就是评价一组超参好坏的。\n\n下面举一个例子，一个模型有三个超参数：param1, param2, param3。为了说明方便，假设他们都是去整数。\n\n这三个超参数可能的取值范围是：\n\n- param1 : [1, 3]\n- param2 : [1:2]\n- param3 : [2: 3]\n\n那么就有 $3 \\times 2 \\times 2 = 12$ 中可能的参数组合。我们的目标就是寻找其中的一个组合使模型效果最好。如果使用`cross_val_score`，我们需要人工穷举每一种组合，计算每一种可能的`mean score` ，找出mean score最小的一组。\n\nsklearn已经帮我们实现了以上方法，即[`model_selection.GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) 。\n\n> estimator：所使用的分类器，如estimator=RandomForestClassifier(min_samples_split=100,min_samples_leaf=20,max_depth=8,max_features='sqrt',random_state=10), 并且传入除需要确定最佳的参数之外的其他参数。每一个分类器都需要一个scoring参数，或者score方法。\n>\n> param_grid：值为字典或者列表，即需要最优化的参数的取值，param_grid =param_test1，param_test1 = {'n_estimators':range(10,71,10)}。\n>\n> scoring :准确度评价标准，\n>\n> - None： 默认这时需要使用estimator的score函数；\n> - string：使用预定义score， 参考 [预定义的scoring参数](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)， 如scoring='roc_auc'，\n> - callable: 需要其函数签名形如：scorer(estimator, X, y)；\n>\n> cv :交叉验证参数，默认None，使用三折交叉验证。指定fold数量，默认为3，也可以是yield训练/测试数据的生成器。\n>\n> refit :默认为True,程序将会以交叉验证训练集得到的最佳参数，重新对所有可用的训练集与开发集进行，作为最终用于性能评估的最佳模型参数。即在搜索参数结束后，用最佳参数结果再次fit一遍全部数据集。\n>\n> iid:默认True,为True时，默认为各个样本fold概率分布一致，误差估计为所有样本之和，而非各个fold的平均。\n>\n> verbose：日志冗长度，int：冗长度，0：不输出训练过程，1：少量信息，>1：对每个子模型都输出。建议用2\n>\n> n_jobs: 并行数，int：个数,-1：跟CPU核数一致, 1:默认值。\n\n```python\nfrom sklearn import svm, datasets\nfrom sklearn.model_selection import GridSearchCV\niris = datasets.load_iris()\nparameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\nsvc = svm.SVC()\ngsearch = GridSearchCV(svc, parameters, scoring='accuracy',)\ngsearch.fit(iris.data, iris.target)\nprint gsearch.best_score_\nprint gsearch.best_params_\nprint gsearch.best_estimator_\nprint gsearch.grid_scores_ # 没组参数对应的score\n\n# 0.98\n# {'kernel': 'linear', 'C': 1}\n# SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n#   decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n#   max_iter=-1, probability=False, random_state=None, shrinking=True,\n#   tol=0.001, verbose=False)\n# [mean: 0.98000, std: 0.01602, params: {'kernel': 'linear', 'C': 1}, mean: 0.97333, std: 0.00897, params: {'kernel': 'rbf', 'C': 1}, mean: 0.97333, std: 0.03697, params: {'kernel': 'linear', 'C': 10}, mean: 0.98000, std: 0.01601, params: {'kernel': 'rbf', 'C': 10}]\n```\n\n# nested cross-validation\n\n该方法用于比较两种模型效果。\n\n其思路如下图所示\n\n![](Hyperparameter-Tuning-in-Sklearn/nested-cross-validation.png)\n\n外部循环是一个`cross_val_score` ，内部循环是GridSearchCV。每一个内部循环只使用外部的训练集作为全部数据。\n\n其好处如下\n\n> in a nice study on the bias in error estimation, Varma and Simon concluded that the true error of the estimate is almost unbiased relative to the test set when nested cross-validation is used\n\n举例如下：比较SVM和DecisionTree在iris数据集上做分类任务的效果\n\n```python\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nimport numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\n\nnp.random.seed(0)\niris = load_iris()\nX, y = iris.data, iris.target\nindices = np.arange(y.shape[0])\nnp.random.shuffle(indices)\nX, y = X[indices], y[indices]\n\npipe_svc = Pipeline([('scl', StandardScaler()),\n            ('clf', SVC(random_state=1))])\nparam_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\nparam_grid = [{'clf__C': param_range, \n               'clf__kernel': ['linear']},\n                 {'clf__C': param_range, \n                  'clf__gamma': param_range, \n                  'clf__kernel': ['rbf']}]\n\ngs = GridSearchCV(estimator=pipe_svc, \n                  param_grid=param_grid,\n                  scoring='accuracy', \n                  cv=10, \n                  n_jobs=-1)\nscores = cross_val_score(gs, X, y, scoring='accuracy', cv=5)\nprint('CV SVM accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))\n\n\ngs = GridSearchCV(estimator=DecisionTreeClassifier(random_state=0),\n                  param_grid=[{'max_depth': [1, 2, 3, 4, 5, 6, 7, None]}],\n                  scoring='accuracy', \n                  cv=5)\nscores = cross_val_score(gs, \n                         X, \n                         y, \n                         scoring='accuracy',\n                         cv=5)\nprint('CV DecisionTree accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))\n\n# CV SVM accuracy: 0.960 +/- 0.039\n# CV DecisionTree accuracy: 0.947 +/- 0.027\n```\n\n可以发现SVM的效果更好。\n\n# validation curves\n\n[`model_selection.validation_curve`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html#sklearn.model_selection.validation_curve)\n\nvalidation curves可以理解为一张图表，其纵坐标为模型performance (score) ，行坐标为模型的**一个参数**。其表示的是随着参数的变化，模型在训练集和测试集上达到的效果。\n作用：模型调参(只能针对一个特征)\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import validation_curve\n\nnp.random.seed(0)\niris = load_iris()\nX, y = iris.data, iris.target\nindices = np.arange(y.shape[0])\nnp.random.shuffle(indices)\nX, y = X[indices], y[indices]\ny = y > 1\n\npipe_lr = Pipeline([('scl', StandardScaler()),\n                    ('clf', LogisticRegression(penalty='l2', random_state=0, C=0.7))])\n\nparam_range = np.logspace(-1, 6, 7)\ntrain_scores, test_scores = validation_curve(\n                estimator=pipe_lr, \n                X=X, \n                y=y, \n                param_name='clf__C', \n                param_range=param_range,\n                cv=10)\n\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\n\nplt.plot(param_range, train_mean, \n         color='blue', marker='o', \n         markersize=5, label='training accuracy')\n\nplt.fill_between(param_range, train_mean + train_std,\n                 train_mean - train_std, alpha=0.15,\n                 color='blue')\n\nplt.plot(param_range, test_mean, \n         color='green', linestyle='--', \n         marker='s', markersize=5, \n         label='validation accuracy')\n\nplt.fill_between(param_range, \n                 test_mean + test_std,\n                 test_mean - test_std, \n                 alpha=0.15, color='green')\n\nplt.grid()\nplt.xscale('log')\nplt.legend(loc='lower right')\nplt.xlabel('Parameter C')\nplt.ylabel('Accuracy')\nplt.ylim([0.8, 1.0])\nplt.tight_layout()\n# plt.savefig('./figures/validation_curve.png', dpi=300)\nplt.show()\n```\n\n![](Hyperparameter-Tuning-in-Sklearn/validation-curves.png)\n\n\n\n\n\n# 参考资料\n\nPython Machine Learning\n\n [`sklearn.model_selection`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)\n\n","tags":["Sklearn"],"categories":["Toolkit"]},{"title":"Jensen不等式","url":"%2Fblog%2FJensen-Inequality.html","content":"\nJensen不等式以丹麦数学家约翰·詹森（Johan Jensen）命名。**它给出均值的凸函数值和凸函数的均值间的大小关系。**\n\n> if $X$ is a random variable and $\\varphi$ is a convex function, then\n> $$\n> \\varphi(E[X]) \\le E[\\varphi (X)].\n> $$\n> 特别地，如果$\\varphi$是严格凸函数，当且仅当$X$是常量时，上式取等号。Jensen不等式应用于凹函数时，不等号方向反向。\n\n从凸函数说起, 设$\\varphi$ 是定义域为实数的函数，如果对于所有的实数$x$，$\\varphi(x)$的二次导数大于等于0，那么$\\varphi(x)$是凸函数。如果$f(x)$的二次导数只大于0，不等于0，那么称 $\\varphi(x)$ 是严格凸函数。当 $x$ 是向量时，如果$\\varphi(x)$ 的 Hessian 矩阵H是半正定的，那么$\\varphi(x)$是凸函数。如果 Hessian 矩阵H是正定的那么称$\\varphi(x)$是严格凸函数。\n\n凸函数又如下性质: 过一个凸函数上任意两点所作割线, 割线一定在这两点间的函数图象的上方，即：\n$$\nf( tx_1 + (1-t)x_2)\\leq tf(x_1)+(1-t)f(x_2). \\tag{1}\n$$\n\n\n其中, $f$ 为如函数, 如下图所示:\n\n![](Jensen-Inequality/ConvexFunction.png)\n\n将（1）推广到一般情形:\n\n$$\nf(\\sum_{i=1}^n t_i x_i) \\le \\sum_{i=1}^n t_i f(x_i). \\tag{2}\n$$\n其中: $x_i \\in I, t_i \\ge 0, \\sum_{i=1}^n t_i =1, 1 \\le i \\le n$\n\n令:\n$$\nt_i = \\frac {p_i}{\\sum_{i=1}^n p_i}.\n$$\n则 (2) 可以改写成\n$$\nf(\\frac{\\sum_{i=1}^n p_i x_i}{\\sum_{i=1}^n p_i}) \\le \\frac{\\sum_{i=1}^n p_i f(x_i)}{\\sum_{i=1}^n p_i}. \\tag{3}\n$$\n\n这就是jensen不等式的形式之一.\n\n如果是$p_i$都取特殊的值，如：$p_i =1，i =1,2,\\dots,n$ 则（3）可表示为\n\n$$\nf(\\frac{\\sum_{i=1}^n  x_i}{n}) \\le \\frac{\\sum_{i=1}^n  f(x_i)}{n}\n$$\n\n即: \n$$\nf(E[X]) \\le E[f(X)]. \\tag{4}\n$$\n其中: $X=\\{x_1, x_2, \\dots, x_n\\}$.\n\n式(4)就是均值形式Jensen不等式.\n\n# reference\n\n[Jensen's inequality]([https://en.wikipedia.org/wiki/Jensen%27s_inequality](https://en.wikipedia.org/wiki/Jensen's_inequality))","tags":["Optimization"],"categories":["Mathematics"]},{"title":"马氏距离与其推导","url":"%2Fblog%2FMahalanobis-distance.html","content":"\n本文曾发表在[博客园](https://www.cnblogs.com/Weirping/articles/6613013.html)中，重新修订发表于此。\n\n马氏距离就是用于度量两个坐标点之间的距离关系，表示数据的协方差距离。与尺度无关的(scale-invariant)，即独立于测量尺度。\n\n# 基本思想（intuition）\n\n如下图的过程（以两个维度作为例子），此例的数据重心为原点，$P1$,$P2$到原点的欧氏距离相同，但点$P2$在$y$轴上相对原点有较大的变异，而点$P1$在$x$轴上相对原点有较小的变异。所以$P1$点距原点的**直观距离**是比$P2$点的小的。\n\n![Mahalanobis distance img 1](Mahalanobis-distance/p1.png)\n\n马氏距离就是解决这个问题，它将直观距离和欧式距离统一。为了做到这一点， **它先将数据不同维度上的方差统一（即各维度上的方差相同），此时的欧式距离就是直观距离**。\n\n![Mahalanobis distance img 2](Mahalanobis-distance/p2.png)\n\n如图：统一方差后的图，$\\hat{P1}$到原点的距离小于$\\hat{P2}$。$P1$到原点的欧式距离和$P2$的相同。**以上所说的直观距离就是马氏距离 **。但是，如果不同维度之间具有相关性，则压缩的效果就不好了。如下图只在横向和纵向上压缩，则达不到上图的压缩效果。\n\n![Mahalanobis distance img 3](Mahalanobis-distance/p3.png)\n\n![Mahalanobis distance img 3](Mahalanobis-distance/p4.png)\n\n所以在$F1$方向和$F2$方向上压缩数据才能达到较好的效果。所以需要将原始数据在**XY坐标系**中的坐标 表示在**F坐标系**中。然后再分别沿着坐标轴压缩数据。\n\n所以，计算样本数据的马氏距离分为两个步骤：\n1. 坐标旋转\n2. 数据压缩\n\n**坐标旋转的目标**：使旋转后的各个维度之间线性无关，所以该旋转过程就是主成分分析的过程。\n**数据压缩的目标**：所以将不同的维度上的数据压缩成为方差都是1的的数据集。\n\n# 推导过程\n\n有一个原始的多维样本数据$X_{n \\times m}$(m列，n行):\n\n$$\n\\begin {matrix}\nx_{11} & x_{12} &  \\cdots  & x_{1m}  \\\\\nx_{21} & x_{22} &  \\cdots  & x_{2m}  \\\\\n\\vdots  &  \\vdots  &  \\ddots  &  \\vdots   \\\\\nx_{n1} & x_{n2} &  \\cdots  & x_{nm}  \\\\\n\\end {matrix}\n$$\n\n其中每一行表示一个测试样本（共$n$个）；$X_i$表示样本的第$i$个维度（共$m$个） $X_i=(x_{1i}, x_{2i}, \\dots, x_{ni})^{\\mathrm{T}}$ ，以上多维样本数据记为${\\bf{X}} = \\left( {X_1}, {X_2} \\cdots {X_m} \\right)$。样本的总体均值为$\\bf{\\mu }_{\\bf{X}} = \\left( \\mu _{X1}, \\mu _{X2} \\cdots \\mu _{Xm} \\right)$。其协方差为：\n$$\n\\bf{\\Sigma }_\\bf{X} \n= E\\left\\{ (\\bf{X} - \\bf{\\mu}_{\\bf{X}})^{\\bf{T}}(\\bf{X} - \\bf{\\mu}_{\\bf{X}}) \\right\\}\n= {\\frac 1n}{(\\bf{X} - \\bf{\\mu}_{\\bf{X}})^{\\bf{T}}}(\\bf{X} - \\bf{\\mu}_{\\bf{X}})\n$$\n\n\n协方差矩阵表示样本数据各维度之间的关系的。**其中n是样本的数量**\n\n假设将原始数据集$\\bf{X}$通过坐标旋转矩阵$\\bf{U}$旋转到新的坐标系统中得到一个新的数据集$\\bf{F}$。（其实$\\bf{X}$和$\\bf{F}$表示的是同一组样本数据集，只是由于其坐标值不同，为了易于区分用了两个字母表示）\n$$\n\\bf{F}^\\bf{T} = \n(\\bf{F}_\\bf{1}\\bf{,}\\bf{F}_\\bf{2} \\cdots \\bf{F}_\\bf{m})^\\mathrm{T} = \\bf{U}\\bf{X}^\\mathrm{T}\n$$\n新数据集$\\bf{F}$的均值记为$\\mu _F = \\mu_{F1},\\mu_{F2} \\cdots \\mu_{Fm})$ , $\\mu _F = U\\mu_X$\n\n由于将数据集旋转后数据的各维度之间是不相关的，所以新数据集${\\bf{F}}$的协方差矩阵${\\Sigma_F}$应该为对角阵。\n由于:\n$$\n(\\bf{F} - \\bf{\\mu}_{\\bf{F}})^{\\mathrm{T}} = \\bf{U}(\\bf{X} - \\bf{\\mu}_{\\bf{X}})^{\\mathrm{T}} \\\\\n(\\bf{F} - \\bf{\\mu}_{\\bf{F}}) = (\\bf{X} - \\bf{\\mu}_{\\bf{X}})\\bf{U}^{\\mathrm{T}}\n$$\n所以：\n$$\n\\begin {aligned}\n\\bf{\\Sigma}_{\\bf{F}} &= \\bf{E}\\left\\{\\left(\\bf{F} - \\bf{\\mu}_{\\bf{F}} \\right)^{\\bf{T}}\\left(\\bf{F} - \\bf{\\mu }_{\\bf{F}} \\right) \\right\\} \\\\\n& = \\frac{\\bf{1}}{\\bf{n}}\\left(\\bf{F} - \\bf{\\mu}_{\\bf{F}} \\right)^{\\bf{T}}\\left(\\bf{F} - \\bf{\\mu}_{\\bf{F}} \\right) \\\\\n&= \\frac{\\bf{1}}{\\bf{n}}\\bf{U}\\left(\\bf{X} - \\bf{\\mu }_{\\bf{X}} \\right)^{\\bf{T}}\\left(\\bf{X} - \\bf{\\mu }_{\\bf{X}} \\right)\\bf{U}^{\\bf{T}}  \\\\\n& = \\bf{U}\\bf{\\Sigma }_X\\bf{U}^{\\bf{T}}  \\\\\n& = \\left( {\\matrix{   {\\lambda 1} & {} & {} & {}  \\cr\n{} & {\\lambda 2} & {} & {}  \\cr\n{} & {} &  \\ddots  & {}  \\cr\n{} & {} & {} & {\\lambda m}  \\cr  } } \\right)\n\\end {aligned}\n$$\n\n其中 $\\sqrt{\\lambda_i}$ 就是第$i$个维度的方差。 \n\n由于$\\bf \\Sigma_{\\bf X}$是实对角阵，所以$\\bf U$是一个正交矩阵 $\\bf U^{\\bf T} = \\bf U^{-1}$。\n\n以上是准备知识，下面推导一个样本点$\\bf{x} = \\left( x_1,x_2 \\cdots x_m \\right)$到重心$\\bf{\\mu }_{\\bf X} = \\left( \\mu _{X1},\\mu _{X2} \\cdots \\mu _{Xm} \\right)$的马氏距离。等价于求点 $\\bf{f} = (f_1,f_2 \\cdots f_m)$ **压缩后的坐标**值到数据重心压缩后的坐标值 $\\bf{\\mu }_\\bf{F} = \\left( \\mu _{F1},\\mu _{F2} \\cdots \\mu _{Fm} \\right)$的欧式距离。\n\n$$\n\\begin {aligned}\n& d^2(\\bf{f},\\bf{\\mu }_{\\bf{F}} ) = (\\frac {f_1 - \\mu_{F1}}{\\sqrt{\\lambda_1}})^2 + (\\frac{f_2 - \\mu_{F2}}{\\sqrt{\\lambda_2}})^2 +  \\cdots  + (\\frac{f_m - \\mu_{Fm}}{\\sqrt{\\lambda_m}})^2  \\\\\n& = ( f_1 - \\mu_{F1},{f_2} - \\mu_{F2} \\cdots f_m - \\mu_{Fm} )\n\\left (\n\t\\begin  {matrix}\n\t\t{\\frac 1{\\lambda_1}} & {} & {} & {}    \\\\\n\t\t{} & {\\frac 1 {\\lambda _2}} & {} & {}  \\\\\n\t\t{} & {} &  \\ddots & {}                 \\\\\n\t\t{} & {} & {} & {\\frac 1 {\\lambda _m}}  \\\\\n\t\\end {matrix}\n\\right) \n\\left(\n\t\\begin {matrix}\n\t\t{f_1 - \\mu_{F1}}  \\\\\n\t\t{f_2 - \\mu_{F2}}  \\\\\n\t\t\\vdots            \\\\\n\t\t{f_m - \\mu_{Fm}}  \\\\\n\t\\end {matrix} \n\\right)  \\\\\n& = (\\bf{f} - \\bf{\\mu}_{\\bf{F}})(\\bf{U}\\bf{\\Sigma}_X \\bf{U}^{\\bf{T}})^{-1}(\\bf{f} - \\bf{\\mu}_{\\bf{F}})^T  \\\\\n&   \\\\\n& = (\\bf{x} - \\bf{\\mu}_X)\\bf{U}^T(\\bf{U}\\bf{\\Sigma}_X \\bf{U}^\\bf{T})^{-1}\\bf{U}(\\bf{x} - \\bf{\\mu}_X )^T  \\\\\n&   \\\\\n& = (\\bf{x} - \\bf{\\mu}_X )\\bf{U}^T \\bf{U}\\bf{\\Sigma}_X^{-1}\\bf{U}^{\\bf{T}}\\bf{U}(\\bf{x} - \\bf{\\mu}_X )^T  \\\\\n&   \\\\\n& = (\\bf{x} - \\bf{\\mu }_X )\\bf{\\Sigma}_X^{-1}(\\bf{x} - \\bf{\\mu }_X)^T \\\\\n\\end {aligned}\n$$\n这就是马氏距离的的计算公式了。\n\n如果$\\bf{x}$是列向量\n$$\n{d^2} = \\left( \\bf{x} - \\bf{\\mu }_X \\right)^T\\bf{\\Sigma }_X^{-1}\\left( \\bf{x} - \\bf{\\mu }_X \\right)\n$$\n\n如果并把上文的重心$\\bf{\\mu }_{\\bf{X}} = \\left( \\mu _{X1},\\mu _{X2} \\cdots \\mu_{Xm} \\right)$改为任意一个样本点$\\bf{y}$，则可以得到$\\bf{x}$和$\\bf{y}$两个样本点之间的马氏距离公式为：\n$$\nd^2 = \\left( \\bf{x} - \\bf{y} \\right)^{\\bf{T}}\\bf{\\Sigma }_{\\bf{X}}^{-1}\\left( \\bf{x} - \\bf{y} \\right)\n$$\n\n# 参考资料\n\n细说马氏距离\n\n\n\n\n\n","tags":["Similarity and DisSimilarity"],"categories":["Mathematics"]},{"title":"Vim中正则表达式汇总","url":"%2Fblog%2FRegex-in-Vim.html","content":"\n在windows系统下用notepad++ 处理文本时最长用的就是正则表达式了，但是在linux的vim中用正则表达式的时候和notepad++ 中是有所不同的。 这些区别也不能全都记住，每次用的时候在上网搜索严重影响效率。 所以把一些基本的知识点记录下来，遂成此文。\n\n\n# 查找替换\n\nvim 中正则表达式主要用在 查找替换 中。其语法如下\n查找： /pattern\n替换： [range]s/{pattern}/{string}/[flags]\n例子：\n\n    :1,10s/from/to/ 表示在第1到第10行（包含第1，第10行）之间搜索替换\n    :10s/from/to/ 表示只在第10行搜索替换\n    :%s/from/to/ 表示在所有行中搜索替换\n    1,$s/from/to/ 同上\n\nflags 有如下四个选项\nc confirm，每次替换前询问；\ne error， 不显示错误；\ng globle，不询问，整行替换。如果不加g选项，则只替换每行的第一个匹配到的字符串；\ni ignore，忽略大小写\n这些选项可以合并使用，如cgi表示不区分大小写，整行替换，替换前询问\n\n# vim中的正则表达式\n\n## 元字符\n```\n    . 匹配任意字符\n    [abc] 匹配方括号中的任意一个字符，可用-表示字符范围。如[a-z0-9]匹配小写字母和数字\n    [^abc] 匹配除方括号中字符之外的任意字符\n    \\d 匹配阿拉伯数字，等同于[0-9]\n    \\D 匹配阿拉伯数字之外的任意字符，等同于[^0-9]\n    \\x 匹配十六进制数字，等同于[0-9A-Fa-f]\n    \\X 匹配十六进制数字之外的任意字符，等同于[^0-9A-Fa-f]\n    \\l 匹配[a-z]\n    \\L 匹配[^a-z]\n    \\u 匹配[A-Z]\n    \\U 匹配[^A-Z]\n    \\w 匹配单词字母，等同于[0-9A-Za-z_]\n    \\W 匹配单词字母之外的任意字符，等同于[^0-9A-Za-z_]\n    \\t 匹配<TAB>字符\n    \\s 匹配空白字符，等同于[\\t]\n    \\S 匹配非空白字符，等同于[^\\t]\n```\n## vim中表示数量的元字符\n注意：下面除了 `*` 以外 其他都需要在前面加上 `\\`\n```\n    *  *  匹配0-任意个\n    \\+ 匹配1-任意个\n    \\? 匹配0-1个\n    \\{n,m} 匹配n-m个\n    \\{n}   匹配n个\n    \\{n,}  匹配n-任意个\n    \\{,m}  匹配0-m个\n```\n\n## 需转义的字符\n\n```\n    \\* 匹配* 字符\n    .  匹配. 字符\n    \\/ 匹配 / 字符\n    \\  匹配 \\ 字符\n    \\[ 匹配 [ 字符\n    \\] 匹配 ] 字符\n```\n\n## 替换变量\n注意 ： vim中替换变量需要在括号前面加上 `\\`\n在正则式中以`\\(`和 `\\)`括起来的正则表达式，在后面使用的时候可以用` \\1`、`\\2`等变量来访问`\\(`和`\\)`中的内容\n\n## 多选一匹配\n```\n    在一个查找模式中，\"或\" 运算符是 \"\\|\"。例如:\n    /foo\\|bar\n    这个命令匹配了 \"foo\" 或 \"bar\"。更多的抉择可以连在后面:\n    /one\\|two\\|three\n    匹配 \"one\"，\"two\" 或 \"three\"。\n    如要匹配其多次重复，那么整个抉择结构须置于 \"\\(\" 和 \"\\)\" 之间:\n    /\\(foo\\|bar\\)\\+\n    这个命令匹配 \"foo\"，\"foobar\"，\"foofoo\"，\"barfoobar\"，等等。\n    再举个例子:\n    /end\\(if\\|while\\|for\\)\n    这个命令匹配 \"endif\"，\"endwhile\" 和 \"endfor\"。\n```\n\n## vim中的特殊字符\n**回车** \n输入方式： `ctrl+v+enter`\n回车在vim的输入方法是\n\n​\t先按`ctrl+v`,得到`^` \n\n​\t再按`enter`.得到^M\n\n因此把全文件所有str换成str回车的语句是:\n: % s/str/str^M/g\n\n\n\n# 参考\n\n[Vim查找替换 & 正则表达式](https://blog.csdn.net/u014015972/article/details/50688837)","tags":["Vim"],"categories":["Vim"]},{"title":"Skewness and Kurtosis","url":"%2Fblog%2FSkewness-and-Kurtosis.html","content":"\n偏度和峰度都是统计量 \n\n偏度Skewness(三阶) ：三阶中心距除以标准差的三次方。描述分布偏离对称性程度的一个特征数。\n\n峰度Kurtosis (四阶) ：四阶中心矩除以标准差的平方 减去三。 用来反映频数分布曲线顶端尖峭或扁平程度的指标。\n\n# skew\n\n是研究数据分布对称的统计量。通过对偏度系数的测量，我们能够判定数据分布的不对称程度以及方向。\n\n具体来说，对于随机变量X，我们定义偏度为其的三阶标准中心矩:\n$$\n\\mathrm{Skew}(\\mathbf{X}) = E[(\\frac{\\mathbf{X}-\\mu}{\\sigma})^3] = \\frac{E[(\\mathbf{X}-\\mu)^3]}{(E[(\\mathbf{X}-\\mu)^2])^{3/2}}=\\frac{k_3}{k_2^{3/2}}\n$$\n其中： $\\mu$为随机变量均值，$\\sigma$为随机变量标准差\n\n而对于样本的偏度，我们一般简记为SK，我们可以基于矩估计，得到有：\n$$\n\\mathrm{SK} =\\frac{m_3}{m_2^{3/2}} = \\frac{\\frac{1}{n}\\sum(x_i-\\bar x)^3}{[\\frac{1}{n}\\sum(x_i-\\bar x)^2]^{3/2}}\n$$\n其中： $\\bar x$为样本均值，$m_3$为样本三阶中心矩，$m_2$为样本的二阶中心矩。**样本偏度的计算结果都属于有偏估计。**\n\n偏度的衡量是相对于正态分布来说，正态分布的偏度为0。因此我们说，若数据分布是对称的，偏度为0。\n\n若偏度>0，则可认为高峰在左，分布为右偏，即分布有一条长尾在右；\n\n若偏度<0，则可认为高峰在右，分布为左偏，即分布有一条长尾在左。\n\n若偏度 = 0 - mean = median, the distribution is symmetrical around the mean.\n\n同时偏度的绝对值越大，说明分布的偏移程度越严重。\n\n![](Skewness-and-Kurtosis/skew.png)\n\n![](Skewness-and-Kurtosis/skew2.png)\n\n\n\n# Kurtosis\n\n峰度，Kurtosis，是研究数据分布陡峭或平滑的统计量，通过对峰度系数的测量，我们能够判定数据分布相对于正态分布而言是更陡峭(peakedness)还是平缓(flattening)。\n\n对于随机变量X，我们定峰度为其的四阶标准中心矩:\n$$\n\\mathrm{Kurtosis}(\\mathbf{X}) = E[(\\frac{\\mathbf{X}-\\mu}{\\sigma})^4] = \\frac{E[(\\mathbf{X}-\\mu)^4]}{(E[(\\mathbf{X}-\\mu)^2])^{2}}\n$$\n此时正太分布的峰度系数是3，但是为了比较起来方便，很多软件（spss，python中的pandas工具）将峰度系数减去3，即使用如下公式计算。对于样本的峰度，我们一般简记为K，可通过如下公式计算样本的峰度系数：\n$$\n\\mathrm{K} =\\frac{m_4}{m_2^{2}} - 3 = \\frac{\\frac{1}{n}\\sum(x_i-\\bar x)^4}{[\\frac{1}{n}\\sum(x_i-\\bar x)^2]^{2}} -3\n$$\n上式的分子分母都不是无偏估计量。\n\n- Kurtosis > 3: Leptokurtic distribution, sharper than a normal distribution, with values concentrated around the mean and longer tails.This means high probability for extreme values.\n- Kurtosis < 3: Platykurtic distribution, flatter than a normal distribution with a wider peak. The probability for extreme values is less than for a normal distribution, and the values are wider spread around the mean.\n- Kurtosis = 3: Mesokurtic distribution - normal distribution for example.\n\n**峰度其实是一个相对于正态分布的对比量，正态分布的峰度系数为3，但是为了比较起来方便，很多软件（spss，python中的pandas工具）将峰度系数减去3，此时正态分布峰度值定为0。而均匀分布的峰度为-1.2，指数分布的峰度为6。 **\n\n![](Skewness-and-Kurtosis/kretosis.png)\n\n\n\n常见分布的 skewness 和 kurtosis 值见下表\n\n![](Skewness-and-Kurtosis/dist-kretosis.png)\n\nnote：此表中列出的 kurtosis 是未减去 3 的版本。\n\n# 参考资料\n\n### [Skewness - Wikipedia](https://en.wikipedia.org/wiki/Skewness)\n\n### [Kurtosis - Wikipedia](https://en.wikipedia.org/wiki/Kurtosis)","tags":["Statistics"],"categories":["Mathematics"]},{"title":"贝叶斯线性回归与贝叶斯逻辑回归","url":"%2Fblog%2FBayesian-Probabilities-in-ML.html","content":"\n在机器学习中经常会遇到概率问题，而在概率问题中经常出现的就是频率学派和贝叶斯学派。\n\n频率学派：使用随机事件的发生的频率描述概率的方法，就是通常说的古典概型，或者称为频率学派。它试图从事件的整体来建模整个事件。如想要计算抛掷一枚硬币时正面朝上的概率，我们需要不断地抛掷硬币，当抛掷次数趋向无穷时正面朝上的频率即为正面朝上的概率。其中最重要的就是不断的重复。\n\n贝叶斯学派：贝叶斯学派认为概率是对事件不确定性的定量描述。如我们想获得这个事件的概率\"whether the Arctic ice cap will have disappeared by the end of the century.\" ，我们不可能通过重复试验来计算。这时贝叶斯观点就派上用场了，首先我们会通过以往的经验对北极冰川的融化速度进行一个合理的估计，当有新的观测数据出现的时候（如气象卫星的观察数据），我们可以利用新的数据对原有预估进行纠正。\n\n关于频率学派和贝叶斯学派可以参考[频率学派(Frequentists) 贝叶斯学派(Bayesians)](https://blog.csdn.net/u012116229/article/details/24636001) 。\n\n本文基于线性回归问题和逻辑回归问题叙述贝叶斯理论在机器学习的应用。\n\n# 变量定义\n\n为了后文论述方便，首先对下文中提到的线性回归和逻辑回归做如下说明。\n\n假设训练集有N个样本，样本集的特征用$\\mathrm X$表示，$x_i$表示第$i$个样本。样本集的lable值用$\\mathrm T$表示，$t_i$表示第$i$个样本的lable值。即  $\\mathbf{X}\\equiv (x_{1} \\dots x_{N})^{\\mathrm{T}}$，$\\mathrm{T}=\\{t_{1} \\dots t_{N} \\}^{\\mathrm{T}}$ ，样本集表示为$\\mathcal D = \\{\\mathrm X, \\mathrm{T} \\}$ 。\n\n基于该数据集训练一个模型$y(x;\\mathrm w)$ ，使用该模型根据新数据的特征预测其lable值。\n\n本文只论述线性回归问题和逻辑回归问题，其形式如下：\n\n线性回归：$y(x ,\\mathrm w) = \\mathrm w ^{\\mathrm T} x $\n\n逻辑回归：$y(x , \\mathrm w) = \\frac {1}{1+ e ^{ - \\mathrm w ^{\\mathrm T} x} }$\n\n在回归问题中，认为目标值$t$服从均值为$y(x,\\mathrm w)$，方差为$\\beta^{-1}$的**高斯分布**。\n$$\np(t|x,\\mathrm w, \\beta)=\\mathcal N(t|y(x , \\mathrm w),\\beta^{-1}) \\tag 1\n$$\n$\\beta$为高斯噪声，反应的是样本集的采样误差即噪声。\n\n在逻辑回归问题中，目标值$t$服从**Bernoulli distribution（伯努力分布，0-1分布）**。$t$的取值为0或1。逻辑回归中使用的sigmoid函数：\n$$\ny = \\sigma(a) \\equiv \\frac 1{1+exp(-a)}\n$$\n的一个重要特性就是：其输出值表示的是概率，即：$y(x , \\mathrm w)$表示取$t=1$的概率，而$(1-y(x , \\mathrm w))$表示取$t=0$的概率。所以对于任何一个样本$\\{ x,t \\}$ 满足参数为$y(x , \\mathrm w)$的伯努力分布:\n$$\np(t|x, \\mathrm w)=y(x, \\mathrm w)^t \\{1-y(x , \\mathrm w)\\}^{(1-t)} \\tag 2\n$$\n\n\n#  贝叶斯概率\n\n在机器学习中，贝叶斯学派认为模型中的参数$\\mathrm w$是一个不确定的值，使用概率分布对其进行建模。\n\n首先我们对$\\mathrm{w}$可能的分布做一个假设，这个假设是基于经验的、和观测数据无关的，这个分布即为先验分布$p(\\mathrm{w})$。依据训练数据集纠正后的$\\mathrm{w}$的概率分布为后验分布$p(\\mathrm{w} | D)$。按照贝叶斯公式对后验概率分解，即：\n\n$$\np(\\mathrm{w}|\\mathcal{D})=\\frac{p(\\mathcal{D}|\\mathrm{w})p(\\mathrm{w})}{p(\\mathcal{D})}\n$$\n\n$\\mathrm{w}$的后验分布$p(\\mathrm{w}| D)$可以分解为三部分:\n1. $p(\\mathrm{w})$ ：先验分布（prior），是关于$\\mathrm{w}$的函数，依赖于先验知识。\n2. $p(\\mathcal{D}|\\mathrm{w})$ ：似然函数（likelihood），是关于$\\mathrm{w}$的函数。表示对于$\\mathrm{w}$的不同值，数据集$\\mathcal D$被观测到的概率。\n     note，似然函数不是关于$\\mathrm{w}$的概率分布函数，所以似然函数对w积分不是1，实际上是$\\mathcal D$的概率分布函数。\n3. $p(\\mathcal{D})$ ：归一化项，用于保证公式右边对$\\mathrm{w}$积分是1，即，保证后验分布是一个概率密度函数。$p(\\mathcal{D})=\\int p(\\mathcal{D}|\\mathrm{w})p(\\mathrm{w})\\mathrm{dw}$。对于固定数据集来说。\n\n\n通过以上分析可知：\n$$\n\\begin {aligned}\n& p(\\mathrm{w}|\\mathcal{D}) \\varpropto p(\\mathcal{D}|\\mathrm{w})p(\\mathrm{w}) \\\\\n& posterior \\varpropto likelihood \\times prior\n\\end{aligned}\n$$\n\n基于贝叶斯概率我们可以做两件事：\n\n1. 确定参数的分布\n2. 确定新样本预测值的分布\n\n# 参数分布\n\n下面论述使用贝叶斯方法计算参数$\\mathrm{w}$的后验分布的方法。\n\n>  若参数的先验概率与模型似然概率共轭，那么参数的后验分布概率与先验概率服从相同的分布。比如说：先验概率服从Beta分布，似然概率服从二项分布，这时先验概率分布与似然概率分布共轭了，那么后验概率也服从Beta分布。\n\n也就是说在使用贝叶斯公式时，如果选择的先验概率分布与似然概率分布共轭，那后验概率分布就很容易计算出来了。\n\n但现实是，它们二者之间经常是不共轭的，从而出现了三种常用的近似计算方法：\n\n- 点估计(Point Estimate--MAP方法)\n- 拉普拉斯近似方法(Laplace approximation)\n- 采样法(Sampling--Metropolis-Hastings)\n\n\n本文主要讲解三种情况：先验与后验同分布的情况、点估计(Point Estimate--MAP方法)、拉普拉斯近似方法(Laplace approximation)\n\n## 先验与后验同分布的情况\n\nnote，在LDA模型中，先验分布和似然分布是共轭，分别为Multinomial分布和 Dirichlet分布。\n\n如上所述，当先验分布与似然函数共轭，即后验分布是同分布时，是怎么求解参数的后验分布呢？下面以回归问题为例介绍。\n\n首先假设参数$\\mathrm{w}$的先验分布和后验分布都服从正态分布，如下：\n\n$\\mathrm{w}$的先验分布与回归问题的似然函数为：\n$$\n\\begin {aligned}\n& p(\\mathrm{w})=\\ \\mathcal{N}(\\mathrm{w}|\\mathbf{m}_{0},\\mathbf{S}_{0}) \\\\ \n& p(\\mathcal{D}| \\mathrm{w})=\\ p(\\mathrm{T}|\\mathbf X,\\mathrm w, \\beta)=\\prod_{i=1}^N \\mathcal N(t_i|y(x_i , \\mathrm w),\\beta^{-1}) \\\\\n\\end {aligned}\n$$\n则后验分布为：\n$$\n\\begin {aligned}\n& p(\\mathrm{w}|\\mathcal{D})= \\mathcal{N}(\\mathrm{w}|\\mathbf{m}_{N},\\mathbf{S}_{N}) \\\\\n\\end {aligned} \\tag 3\n$$\n其中：\n$$\n\\begin {aligned}\n& \\mathbf{m}_{N}= \\mathbf{S}_{N}(\\mathbf{S}_{0}^{-1}\\mathbf{m}_{0}+\\beta \\mathrm{X}^{\\mathrm{T}}\\mathrm{T}) \\\\\n& \\mathbf{S}_{N}^{-1}=\\ \\mathbf{S}_{0}^{-1}+\\beta \\mathrm{X}^{\\mathrm{T}}\\mathrm{X} \\\\\n\\end {aligned} \n$$\n其求解方法来源于《Pattern Recognition and Machine Learning》2.2.3 Bayes’ theorem for Gaussian variables。其结论如下：\n\n![](Bayesian-Probabilities-in-ML\\Bayes-theorem-for-Gaussian-variables.png)\n\n\n\n## MAP\n\n**后验概率公式表示了 在给定数据集$\\mathcal D$的前提下，$\\mathrm w$的概率密度函数，MAP方法认为$\\mathrm w$最可能的取值就是能使后验概率$p(\\mathrm w| \\mathcal D)$最大的$\\mathrm w$ 。该方法称为 maximum posterior ，即 MAP。**\n\n### 线性回归MAP\n\n**先验概率**\n\n相对于上面$\\mathrm{w}$的先验分布的一般化假设，在MAP中我们假设$\\mathrm{w}$的先验分布是服从均值为$0$方差为${\\alpha }^{-1}\\mathbf{I}$的高斯分布， 即上文中的 $\\mathbf{m}_0 = 0, \\mathbf{S}_0 = {\\alpha }^{-1}\\mathbf{I}$:\n$$\np(\\mathrm{w}|\\alpha )=\\ \\mathcal{N}(\\mathrm{w}|0,{\\alpha }^{-1}\\mathbf{I})=(\\frac{\\alpha }{2\\pi })^{(M +1)/2}\\ \\exp \\{-\\frac{\\alpha }{2}\\mathrm{w}^{\\mathrm{T}}\\mathrm{w}\\} \\tag 5\n$$\n\n其中：$\\alpha$为精度，$M+1$为向量$\\mathrm w$的维度。\n\n**似然函数**\n\n$$\np(\\mathrm{T}|\\mathbf X,\\mathrm w, \\beta)=\\prod_{i=1}^N \\mathcal N(t_i|y(x_i , \\mathrm w),\\beta^{-1}) \\tag 6\n$$\n**后验概率**\n\n$$\n\\begin {aligned}\np(\\mathrm w| \\mathcal D) &\\varpropto  p(\\mathrm{T}|\\mathbf X,\\mathrm w, \\beta) \\times p(\\mathrm{w}|\\alpha ) \\\\\n\\end {aligned}  \\tag 8\n$$\n如果套用上面的公式:\n$$\n\\begin {aligned}\np(\\mathrm{w}|\\mathcal{D}) &= \\mathcal{N}(\\mathrm{w}|\\mathbf{m}_{N},\\mathbf{S}_{N}) \\\\\n\\mathrm{where}: & \\mathbf{m}_{N}\\quad =\\beta\\mathbf{S}_{N}\\mathbf{X}^{\\mathrm T}\\mathbf{T} \\\\\n& \\mathbf{S}_{N}^{-1}=\\alpha \\mathbf{I}+\\beta \\mathbf{X}^{\\mathrm{T}}\\mathbf{X}\n\\end {aligned}\n$$\n\n\n**MAP计算**\n\n将公式5、6带入公式8，取两边取负对数： \n$$\n\\begin {aligned}\n-\\ln p(\\mathrm w| \\mathcal D) &\\varpropto  -\\ln \\{p(\\mathrm{T}|\\mathbf X,\\mathrm w, \\beta) \\times p(\\mathrm{w}|\\alpha ) \\} \\\\\n& \\varpropto \\frac{\\beta }{2}\\sum _{n=1}^{N}\\{y(x_{n},\\mathrm{w})-t_{n}\\}^{2}+\\frac{\\alpha }{2}\\mathrm{w}^{\\mathrm{T }}\\mathrm{w} + \\mathrm{const}\n\\end {aligned}  \\tag 8\n$$\n最大化后验概率 等价于 最小化后验概率的负对数 等价于 最小化下式:\n\n$$\n\\frac{\\beta }{2}\\sum _{n=1}^{N}\\{y(x_{n},\\mathrm{w})-t_{n}\\}^{2}+\\frac{\\alpha }{2}\\mathrm{w}^{\\mathrm{T }}\\mathrm{w}\n$$\n可以发现，对于回归问题使用最大似然估计(ML)求解时，其损失函数的正则化系数为$\\lambda =\\alpha / \\beta $时，等价于MAP求解方法。\n\nnote: $\\beta$ 是样本数据的协方差的倒数（精度），与样本数据有关的；$\\alpha$ 是超参。\n\n### 逻辑回归MAP\n\n**先验概率**\n\n相对于上面$\\mathrm{w}$的先验分布的一般化假设，在MAP中我们假设$\\mathrm{w}$的先验分布是服从均值为$0$方差为${\\alpha }^{-1}\\mathbf{I}$的高斯分布， 即上文中的 $\\mathbf{m}_0 = 0, \\mathbf{S}_0 = {\\alpha }^{-1}\\mathbf{I}$:\n$$\np(\\mathrm{w}|\\alpha )=\\ \\mathcal{N}(\\mathrm{w}|0,{\\alpha }^{-1}\\mathbf{I})=(\\frac{\\alpha }{2\\pi })^{(M +1)/2}\\ \\exp \\{-\\frac{\\alpha }{2}\\mathrm{w}^{\\mathrm{T}}\\mathrm{w}\\} \\tag 5\n$$\n其中：$\\alpha$为精度，$M+1$为向量$\\mathrm w$的维度。\n\n**似然函数**\n$$\np(\\mathrm{T}|\\mathbf X, \\mathrm w)=\\prod_{i=1}^N y(x_i, \\mathrm w)^{t_i} \\{1-y(x_i , \\mathrm w)\\}^{(1-t_i)} \\tag 7\n$$\n**后验概率**\n$$\n\\begin {aligned}\np(\\mathrm w| \\mathcal D) &\\varpropto  p(\\mathrm{T}|\\mathbf X, \\mathrm w) \\times p(\\mathrm{w}|\\alpha )\\\\\n\\end {aligned} \\tag 9\n$$\n**MAP计算**\n\n将公式5、7带入公式9，取两边取负对数：\n$$\n\\begin {aligned}\n-\\ln p(\\mathrm w| \\mathcal D) &\\varpropto  -\\ln \\{p(\\mathrm{T}|\\mathbf X, \\mathrm w) \\times p(\\mathrm{w}|\\alpha ) \\} \\\\\n\\end {aligned} \\tag 9\n$$\n最大化后验概率 等价于 最小化后验概率的负对数，能够使后验概率的负对数取最小值的$\\mathrm w$即为$\\mathrm w$的最优解。\n\n逻辑回归的似然函数没有正态分布的特点，不能利用《Pattern Recognition and Machine Learning》2.2.3 Bayes’ theorem for Gaussian variables的结论，但是可以使用牛顿法求解。\n\n\n## Laplace approximation\n\n很多时候，在使用贝叶斯方法时，似然函数和先验分布不是共轭了，在这种情况下可使用拉普拉斯近似来求解参数的后验分布。\n\n本节以逻辑回归问题为例拉普拉斯近似在该问题中的应用。\n\n拉普拉斯就是使用一个正态分布来近似一个未知分布，在本节中，我们是用一个正态分布来近似参数$\\mathbf{w}$的后验分布的。\n\n假设参数$\\mathrm{w}$的先验分布为正态分布，参数为$\\mathbf{m}_{0}$ 和 $\\mathbf{S}_{0}$，则其先验分布和似然函数如下：\n$$\n\\begin {aligned}\n& p(\\mathrm{w})=\\ \\mathcal{N}(\\mathrm{w}|\\mathbf{m}_{0},\\mathbf{S}_{0}) \\\\ \n& p(\\mathcal{D}| \\mathrm{w})=p(\\mathrm{T}|\\mathbf X, \\mathrm w)=\\prod_{i=1}^N y(x_i, \\mathrm w)^{t_i} \\{1-y(x_i , \\mathrm w)\\}^{(1-t_i)} \\\\\n\\end {aligned}\n$$\n将上式带入后验分布公式$p(\\mathrm{w}|\\mathcal{D}) \\varpropto f(\\mathbf {w}) = p(\\mathcal{D}|\\mathrm{w})p(\\mathrm{w}) $左边并对两边取对数为：\n$$\n\\begin {aligned}\n\\ln p(\\mathbf w|\\mathcal{D}) &\\varpropto \\ln f(\\mathbf{w})= -\\frac{1}{2}(\\mathbf w - \\mathbf m_0)^{\\mathrm T} \\mathbf{S}_0^{-1}(\\mathbf w - \\mathbf m_0) \\\\\n&+\\sum_{n=1}^{N}\\{t_n \\ln y_n+(1-t_{n})\\ln (1-y_{n})\\}+\\mathrm{const}\n\\end {aligned}\n$$\n其中:$y_n = y(x_n, \\mathbf w)$。为了说明方便，增加$f(\\mathbf {w}) = p(\\mathcal{D}|\\mathrm{w})p(\\mathrm{w})$。 \n\n我们是用一个正态分布来近似参数$\\mathbf{w}$的后验分布的，那么后验分布的均值应该是能够使后验分布最大的$\\mathbf{w}$的值，即为$\\mathbf{w}_{MAP}$。后验分布的方差即为$\\ln f(\\mathbf w)$在$\\mathbf{w}_{MAP}$处二阶导数的倒数，即：\n$$\n\\mathbf{S}_{N}=-\\nabla \\nabla \\ln f(\\mathbf{w})=\\ \\mathbf{S}_{0}^{-1}+\\sum _{n=1}^{N}y_{n}(1-y_{n})x_nx_n^{\\mathrm T}\n$$\n$\\mathbf{w}$的后验分布即为：\n$$\np(\\mathrm{w}|\\mathcal D)=\\ \\mathcal{N}(\\mathbf{w}|\\mathbf{m}_{MAP},\\mathbf{S}_{N}) \\\n$$\n\n# 预测分布\n\n实际应用中我们更关注的是对新数据的预测值，即，对于新数据预测值的后验分布$p(t|x,\\mathcal{D}, \\mathbf{m}_0, \\mathbf{S}_0, \\beta)$，而不太关注模型参数的值到底是多少。\n\n如上文所述，线性回归问题中我们假设预测值服从正态分布即:\n$$\np(t|x,\\mathrm w, \\beta)=\\mathcal N(t|y(x , \\mathrm w),\\beta^{-1})\\tag 1\n$$\n对于参数$ \\mathrm w$的**先验分布和后验分布都为正态分布**的情况，$ \\mathrm w$的后验分布为：\n$$\n\\begin {aligned}\n& p(\\mathrm{w}|\\mathcal{D})= \\mathcal{N}(\\mathrm{w}|\\mathbf{m}_{N},\\mathbf{S}_{N}) \\\\\n\\end {aligned} \\tag 3\n$$\n其中：\n$$\n\\begin {aligned}\n& \\mathbf{m}_{N}= \\mathbf{S}_{N}(\\mathbf{S}_{0}^{-1}\\mathbf{m}_{0}+\\beta \\mathrm{X}^{\\mathrm{T}}\\mathrm{T}) \\\\\n& \\mathbf{S}_{N}^{-1}=\\ \\mathbf{S}_{0}^{-1}+\\beta \\mathrm{X}^{\\mathrm{T}}\\mathrm{X} \\\\\n\\end {aligned}\n$$\n注意：上面的后验分布只是标记的简化，可以写成如下形式：\n$$\n\\begin {aligned}\n& p(\\mathrm{w}|\\mathcal{D},  \\mathbf{m}_0, \\mathbf{S}_0, \\beta) =  p(\\mathrm{w}|\\mathcal{D})= \\mathcal{N}(\\mathrm{w}|\\mathbf{m}_{N},\\mathbf{S}_{N}) \\\\\n\\end {aligned}\n$$\n对于新数据的观测值$x$，其预测值的(后验)分布为：下面的分解需要参考贝叶斯网的理论(概率图模型)分解。\n$$\np(t|x,\\mathcal{D}, \\mathbf{m}_0, \\mathbf{S}_0, \\beta )=\\int p(t|x, \\mathrm{w},\\beta )p(\\mathrm{w}|\\mathcal{D},  \\mathbf{m}_0, \\mathbf{S}_0, \\beta )\\mathrm{dw}\n$$\n直接将式1、3带入上式可解。\n\n同时该后验分布也可以通过《Pattern Recognition and Machine Learning》2.2.3 Bayes’ theorem for Gaussian variables 中结论 2.115式直接得到。\n\n贝叶斯方法的逻辑回归的预测分布还没看懂，看懂了再补充。\n\n\n\n\n# 参考资料\n\nPattern Recognition and Machine Learning\n\n[频率学派(Frequentists) 贝叶斯学派(Bayesians)](https://blog.csdn.net/u012116229/article/details/24636001)\n\n[贝叶斯推断之最大后验概率(MAP)](https://www.cnblogs.com/hapjin/p/8834794.html)\n","tags":["Probability"],"categories":["Mathematics"]},{"title":"信息检索评价指标","url":"%2Fblog%2FMetrics-in-IR.html","content":"\n# nDCG(Normalized Discounted Cumulative Gain)\n\n源自一篇参考维基百科的文章\n\nNormalized Discounted Cumulative Gain：一种对搜索引擎或相关程序有效性的度量。\n\n2个假设：\n\n​    1.强相关的文档应该出现在结果列表前面，且越靠前（rank越高）越有用。\n\n​    2.强相关文档比弱相关文档有用，比不相关文档有用。\n\n$DCG$来源于一个更早的、更基础的方法---$CG$。\n\n## CG\n\n$CG$不考虑结果集中的序信息，单纯把分级相关度相加。前个$P$个位置的$CG$值是：\n\n$$\nCG_p = \\sum\\limits_{i=1}^{p}{rel_i}\n$$\n\n$rel_i$是搜索结果列表的位置$i$处结果的分级相关度。\n\n## DCG\n\n$DCG$取代$CG$作为一个更准确的测量方法。\n\n 如果一个强相关的文档排名靠后则应该受到惩罚，前个$P$个位置的$DCG$值是：\n\n$$\nDCG_p = rel_1 + \\sum_{i=2}^{p}\\frac {rel_i}{log_2 i}\n$$\n\n另一个$DCG$计算公式更加强调相关性\n\n$$\nDCG_p = \\sum_{i=1}^{p} \\frac{2^{rel_i}-1}{log_2(1+i)}\n$$\n\n若分级相关度只在0和1取二值的话，二公式效果相同\n\n## nDCG\n\n根据Query的不同，结果列表的长度也不同，所以这一度量考虑了正规化问题\n\n$$\nnDCG_p =\\frac{DCG_p}{IDCG_p}\n$$\n\n$IDCGp$（Ideal DCG）是在一个完美的排序下，$p$所具有的最大$DCG$值\n\n这样一来无论Query是什么，$nDCG$都可以得到一个平均值，因此不同的Query之间的效能就可以做比较了。\n\n完美的排序算法会使$DCG_p$和$IDCG_p$相同，从而使$nDCG_p$为1，$nDCG$的取值在0到1之间\n\n例：查询结果列表中的6篇文档$D1,D2,D3,D4,D5,D6$，判定了他们的相关度是 $3,2,3,0,1,2$ ，则：\n$$\nCG_6=\\sum_{i=1}^6 rel_i = 3+2+3+0+1+2=11\n$$\n\n| $i$  | $rel_i$ | $\\log _{2}(i+1)$ | $\\frac {rel_{i}}{\\log _{2}(i+1)}$ |\n| ---- | ------- | ---------------- | --------------------------------- |\n| 1    | 3       | 1                | 3                                 |\n| 2    | 2       | 1.585            | 1.262                             |\n| 3    | 3       | 2                | 1.5                               |\n| 4    | 0       | 2.322            | 0                                 |\n| 5    | 1       | 2.585            | 0.387                             |\n| 6    | 2       | 2.807            | 0.712                             |\n\n所以 $DCG_6$ 的值为：\n$$\n{DCG_{6}} =\\sum _{i=1}^{6}{\\frac {rel_{i}}{\\log _{2}(i+1)}}=3+1.262+1.5+0+0.387+0.712=6.861\n$$\n\n\n一个理想的排序应该是：$3，3，2，2，1，0$ ，所以\n$$\n\\begin {aligned}\n&IDCG_{6} =8.740 \\\\\n\\\\\n& nDCG_{6} ={\\frac {DCG_{6}}{IDCG_{6}}}={\\frac {6.861}{8.740}}=0.785 \\\\\n \\end {aligned}\n$$\n\n$nDCG$的缺点是：当排序的数很少（比如：只有1-3个），那么任何排序的$nDCG$值都比较接近，所以可以考虑使用AUC（area under the ROC curve）。\n\nAUC学习参考文章：http://blog.csdn.net/chjjunking/article/details/5933105 \n\n自己用python写的一个计算ndcg函数。 该函数计算一个query下 的 nDCG\n\n```python\ndef calc_dcg(sorted_vec, at):\n    '''\n    sorted_vec: list[tuple], type of element is tuple,\n    \ttuple(v0, v1), v0: predict score; v1: label score\n    at: int, calculate dcg@at\n    '''\n    import math\n    ranking = [t[1] for t in sorted_vec[0: at]]\n    dcg_ = sum([(2**r - 1) / math.log(i + 2, 2) for i, r in enumerate(ranking)])\n    return dcg_\n\n\ndef calc_ndcg(vec, at):\n    '''\n    vec: list[tuple], type of element is tuple,\n    \ttuple(v0, v1), v0: predict score; v1: label score\n    at: int, calculate ndcg@at\n    '''\n    sorted_vec = sorted(vec, key=lambda t: t[1], reverse=True)\n    ideal_dcg = calc_dcg(sorted_vec, at)\n    sorted_vec = sorted(vec, key=lambda t: t[0], reverse=True)\n    cur_dcg = calc_dcg(sorted_vec, at)\n    if ideal_dcg == 0:\n        return 0\n    else:\n        return cur_dcg / ideal_dcg\n```\n\n整个训练集: $nDCG = \\frac {nDCG\\ sum}{query\\ count}$\n\nnote: 当 ideal_dcg = 0 时, 我见过两种处理方法:\n\n1. nDCG sum += 0, query count += 1;\n2. nDCG sum += 0, query count += 0, 即抛弃该query, tf_ranking 采用的是该方案.\n\n实际应用中一定要同意标准\n\n# RR（reciprocal rank）\n\n RR（reciprocal rank）倒数排名，指检索结果中第一个相关文档的排名的倒数。\n$$\nRR = \\frac 1  {rank_i}\n$$\n具体来说：**对于一个query，若第一个正确答案排在第n位，则RR得分就是$\\frac1n$。**（如果没有正确答案，则得分为0）。\n\n## MRR(Mean Reciprocal Rank)\n\n\n\n\nMRR的核心思想很简单：返回的结果集的优劣，跟第一个正确答案的位置有关，第一个正确答案越靠前，结果越好。MRR为所有query的RR的平均值。\n\n公式为： \n\n$$\nMRR = \\frac1 {\\left| Q \\right|}\\sum_{i = 1}^{\\left| Q \\right|} \\frac 1  {rank_i}\n$$\n\n其中，$Q$为样本query集合，${\\left| Q \\right|}$表示$Q$中query个数，$rank_i$ 表示在第$i$个query中，第一个正确答案的排名\n\n## 例子\n\n比如，设测试集有4个query，他们的结果中，前三个query的第一个正确答案分别被排在第3，1，5位，而第四个query没有找到正确答案。则该系统的MRR得分就是： \n\n$$\nMRR = \\frac14(\\frac13+\\frac11+\\frac15+0 )=0.383\n$$\n\n##  ERR（Expected reciprocal rank）\n\nERR是受到cascade model的启发。点击模型中的cascade model，考虑到在同一个检索结果列表中各文档之间的位置依赖关系，假设用户从上至下查看，如果遇到某一检索结果项满意并进行点击，则操作结束；否则跳过该项继续往后查看。第 i 个位置的文档项被点击的概率为：\n$$\nP(C_i) = r_i \\prod_{j=1}^{i-1} (1 - r_j)\n$$\n其中 $r_i$ 表示第 $i$ 个文档被点击的概率，前 $i-1$ 个文档则没有被点击，概率均为 $1-r_j$；\n\nERR (倒数排名的期望)，表示用户的需求被满足时**停止的位置**的倒数的期望，与 MRR 计算第一个相关文档的位置倒数不同。\n\n首先用户在位置 $r$ 处停止的概率 $P_r$ 计算公式如下：\n$$\nP_r = R_r \\prod_{i=1}^{r-1}(1 - R_i)\n$$\n\n\n其中 $R_i $是关于文档相关度等级的函数，现假设该函数为：\n$$\nR_i = \\frac {2^{l_i} - 1}{2^{l_m}}\n$$\n$l_m$表示相关性评分最高的一档。$l_i$ 表示样本中第$i$ 个结果的相关度标记。\n\nERR 的计算公式如下：\n\n$$\nERR = \\sum_{r} \\frac1r P_r = \\sum_{r} \\frac1r R_r \\prod_{i=1}^{r-1}(1 - R_i)\n$$\n\n注： 当将上式中 的 reciprocal rank 部分 $\\frac 1r$ 换成  $\\frac 1{\\log_2 {r + 1}}$ ， 则和 DCG是等价的。\n\n# MAP(mean average precision)\n\n## Precision\n\nPrecision is the fraction of the documents retrieved that are relevant  to the user's information need.\n\n$$\nprecision = \\frac {\\left| {\\{ relevant\\;documents\\}  \\cap \\{ retrieved\\;documents\\} } \\right|}  {\\left| {\\left\\{ {retieved\\;documents} \\right\\}} \\right|}\n$$\n\nPrecision takes all retrieved documents into account. It can also be evaluated at a given cut-off rank, considering only the topmost results returned by the system. This measure is called *precision at n* or *P@n*.\n\n## Average precision\nPrecision and recall are single-value metrics based on the whole list of documents returned by the system. For systems that return a ranked sequence of documents, it is desirable to also consider the order in which the returned documents are presented. By computing a precision and recall at every position in the ranked sequence of documents, one can plot a precision-recall curve, plotting precision $p(r)$ as a function of recall $r$. Average precision computes the average value of $p(r)$ over the interval from $r=0$ to $r=1$\n\n$$\nAveP=\\int_0^1p\\left(r\\right)dr \n$$\n\n这个值就是AUC(rea under the precision-recall curve)\n\nThat is the area under the precision-recall curve. This integral is in practice replaced with a finite sum over every position in the ranked sequence of documents:\n\n$$\nAveP = \\sum _{k=1}^n{P\\left(k\\right)}\\Delta{r\\left(k\\right)}\n$$\n\n\nwhere $ k$ is the order in the sequence of retrieved documents, $n$ is the number of retrieved documents, $P(k)$ is the precision at cut-off $k$ in the list, and $\\Delta r(k) $is the change in recall from items $k-1$ to $k$.\n\nThis finite sum is equivalent to:\n\n$$\n{AveP} = \\frac{\\sum_{k=1}^n (P(k) \\times {rel}(k))}{number\\; of\\; relevant \\;documents}\n$$\n\nwhere ${rel} (k)$  is an indicator function equaling 1 if the item at k is a relevant document, zero otherwise. Note that the average is over all relevant documents and the relevant documents not retrieved get a precision score of zero.\n\n## Mean average precision\n\nMean average precision for a set of queries is the mean of the average precision scores for each query.\n\n$$\nMAP=\\frac{\\sum_{q=1}^Q{AveP(q)}}{Q}\n$$\n\nwhere *Q* is the number of queries.\n\n\n\n# 参考\n\nhttp://en.wikipedia.org/wiki/Discounted_cumulative_gain\n\n\n\n\n\n","tags":["LTR"],"categories":["Concepts"]},{"title":"TF-IDF","url":"%2Fblog%2FTF-IDF.html","content":"\n在信息检索中每个term都会赋予一定的权值，TF-IDF是其最常见的权重，本节叙述term的TF-IDF的计算。如其名称，TF-IDF分为两个部分：词频TF和逆文档频率IDF。\n\n# 词频TF权重\n\n词频（TF），即一个term在**一个文档**中出现的次数，一般来说，在某个文档中反复出现的term，往往能够表征文档的主题信息，即TF值越大，越能代表文档所反映的内容，那么应该给予这个term更大的权值。这是为何引入词频作为计算权值的重要因子的原因。\n\n计算词频权重主要目的是通过一个term在**一个文档**中出现的次数(TF)来衡量这个term在该文档中的重要性($W_{TF}$)。\n\n具体计算词频因子的时候，基于不同的出发点，可以采纳不同的计算公式。\n\n## 直接统计法\n\n$$\nW_{TF} = TF\n$$\n\n即一个term在docment中出现了几次TF就等于几。\n\n## 对数\n\n$$\nW_{TF} = 1+ \\log (TF)\n$$\n\n其中$$TF$$是term在document中实际出现的次数。对其通过对数变换后的$W_{TF}$作为term在该document中的权重。该公式是基于如下观点设计的：\n\n- 取对数：即使一个term出现了10次，也不应该在计算特征权值时，比出现1次的情况权值大10倍，所以加入$\\log$机制抑制这种过大的差异。\n- 数字1：公式中的数字1是为了平滑计算用的，因为如果TF值为1的情况下，取$\\log$后值为0，即本来出现了一次的term，按照这种方法计算会认为这个term从来没有在文档中出现过，为了避免这种情形，采用加1的方式来进行平滑。\n\n## 增强型规范化TF\n\n$$\nW_{TF} = a+(1-a)\\times \\frac{TF}{\\max(TF)}\n$$\n\n公式中的TF代表这个term的实际词频数目，$而\\max(TF)$代表了文档中所有单term出现次数最多的那个单term应的词频数目，$a$是调节因子，过去经验取值0.5，新的研究表明取值为0.4效果更好。\n\n之所以要如此操作，主要出于对长文档的一种抑制，因为如果文档较长，与短文档相比，则长文档中所有term的TF值会普遍比短文档的值高，但是这并不意味着长文档与查询更相关。用term实际词频除以文档中最高词频，等于将绝对的数值进行了规范化转换，公式的含义就转换为：同一个文档内term之间的相对重要性。即使一个文档很长，term词频普遍很高，但是除以文档最高词频，那么通过这种计算方式得出的数值比短文档来说并不一定就大。这样就剔除了文档长度因素的影响，长文档和短文档的词频因子就成为可比的了。\n\n# 逆文档频率IDF\n\nIDF代表的是文档集合范围内term的相对重要性。\n\n逆文档频率因子IDF，其计算公式如下：\n$$\nIDF_k = \\log{\\frac{N}{n_k}}\n$$\n其中的$N$代表文档集合中总共有多少个文档，而$n_k$代表特征term $k$在其中多少个文档中出现过，即文档频率。由公式可知，文档频率n_k越高，则其IDF值越小，即越多的文档包含某个term，那么其IDF权值越小。IDF就是衡量不同term对文档的区分能力的，其值越高，则其区分不同文档差异的能力越强，反之则区分能力越弱。整体而言，IDF的计算公式是基于经验和直觉的，有研究者进一步分析认为：IDF代表了term带有的信息量的多少，其值越高，说明其信息含量越多，就越有价值。\n\n# TF-IDF\n\nTF-IDF框架就是结合了上述的词频因子和逆文档频率因子的计算框架，一般是将两者相乘作为特征权值，特征权值越大，则越可能是好的指示词，即：\n$$\nW_{Term} = TF \\times IDF\n$$\n从上述公式可以看出，对于某个文档D来说：\n如果D中某个term的词频很高，而且这个term在文档集合的其他文档中很少出现，那么这个term的权值会很高。\n如果D中某个term的词频很高，但是这个term在文档集合的其他文档中也经常出现，或者term词频不高，但是在文档集合的其他文档中很少出现，那么这个term的权值一般。\n如果D中某个term词频很低，同时这个term在文档集合的其他文档中经常出现，那么这个term权值很低。\n\n# 参考资料\n\n这就是搜索引擎","tags":["Application"],"categories":["Application"]},{"title":"拉普拉斯近似","url":"%2Fblog%2FLaplace-Approximation.html","content":"\n在机器学习问题中，很多时候无法确定一个概率分布的具体密度函数，因而在对这种分布进行后续操作（例如，贝叶斯学派求后验概率时）时难度很大，无法进行。为了简化问题经常需要对这种复杂分布进行近似，从而方便计算或操作。目前常用的近似算法主要有三种：拉普拉斯近似、变分近似、Gibbs采样。拉普拉斯近似便是一种简单且广泛应用的近似方法，并且是很多采样方法的基础思想，本文介绍拉普拉斯近似（Laplace Approximation）。\n\n拉普拉斯近似的基本思想是**使用一个高斯分布来近似复杂分布**，求解过程即为求正态分布的期望$\\mu$和方差$\\sigma^2$(或精度$\\frac{1}{\\sigma^2}$)的过程。注意：该方法是用于对**连续**变量的概率密度函数进行近似的。\n\n# 一维变量的情形\n\n假设有一个变量$z$（标量），其分布为$p(z)$，该分布的具体形式未知，定义如下：\n\n\n$$\np(z)=\\frac{1}{Z}f(z) \\\\\nZ=\\int f(z) dz\n$$\n其中$Z$为归一化项。\n\n使用拉普拉斯近似寻找一个正态分布$q(z)$来近似这个分布$p(z)$。只需要求出$q(z)$的期望$\\mu$和方差$\\sigma^2$(或精度$\\frac{1}{\\sigma^2}$)。\n\n怎么在数学上定义这个近似呢？\n\n在拉普拉斯近似中分布$q(z)$与分布$p(z)$近似定义为：$q(z)$的峰值与$p(z)$的峰值相等。即$q(z)$的期望等于$p(z)$最大值。\n\n先观察一下单变量正态分布公式的形式：\n$$\n\\mathcal{N}(x|\\mu,\\sigma^{2})=\\frac{1}{(2\\pi \\sigma ^{2})^{1/2}}\\ \\exp \\{-\\frac{1}{2\\sigma ^{2}}(x-\\mu)^{2}\\} \\tag1\n$$\n指数项中包含$(x-\\mu)^{2}$，在正态分布$q(z)$中的均值$\\mu$应该为$p(z)$的最大值点。\n\n假设$z_0$是$p(z)$的最大值点，则在$z_0$处的一阶导数为0：\n$$\n\\frac{dp(z)}{dz} \\bigg|_{z=z_0} = 0 \\Leftrightarrow \\frac{df(z)}{dz} \\bigg|_{z = z_0} =0\n$$\n\n借用$\\ln f(z)$在$z_0$处的二阶Taylor展开来构建指数中的平方项，如下：\n$$\n\\begin {aligned}\n\\ln f(z) &\\simeq \\ \\ln f(z_{0}) -\\frac{1}{2} A (z-z_{0})^{2} \\\\\nwhere: &\\ \\ A=-\\frac{d^{2}}{dz^2} \\ln f(z)\\bigg|_{z=z_0}\n\\end {aligned} \\tag 2\n$$\nnote：Taylor展开的一阶项为0。\n\n对式2两边去掉$\\ln$， 则：\n$$\nf(z) \\simeq f(z_{0})\\exp \\{-\\frac{A}{2}(z-z_{0})^{2}\\} \\tag 3\n$$\nnote：上式是未归一化的。\n\n对比式3中的指数项与式1中的指数项可以发现，如果$A= \\frac{1}{\\sigma^2}$ ，则可得归一化的高斯函数$q(z)$为下式：\n$$\nq(z)=(\\frac{A}{2\\pi })^{1/2}\\ \\exp \\{-\\frac{A}{2}(z-z_{0})^{2\\}}\n$$\n **总结：**\n\n$q(z)$的\n\n期望$\\mu=z_0$ ，即，$f(z)$的最大值点；\n\n精度$\\frac{1}{\\sigma^2}=A$，即，$\\ln f(z)$在$z_0$处的二阶导数，由于$z_0$是极大值点，所以要求$A>0$。\n\n# 多维变量的情形\n\n多维的情形推导过程和一维的情形类似，简单推导如下。\n\n多维变量的拉普拉斯近似的目的是寻找一个多维正态分布$q(\\mathbf z)$来近似这个分布$p(\\mathbf z)$。\n\n首先看一下多维变量$\\mathbf x$的高斯分布公式的形式:\n$$\n\\mathcal{N}(\\mathbf{x}|\\mathbf{\\mu },\\mathbf{\\Sigma })=\\frac{1}{(2\\pi )^{D/2}}\\frac{1}{|\\mathbf{\\Sigma }|^{1/2}} \\exp \\{-\\frac{1}{2}(\\mathbf{x}-\\mathbf{\\mu })^{\\mathrm{T}}\\mathbf{\\Sigma }^{-1}(\\mathbf{x}-\\mathbf{\\mu })\\} \\tag 4\n$$\n其中$D$为$\\mathbf x$的维度。\n\n假设有一个变量$\\mathbf z$（$M$维向量，粗体），其分布为$p(\\mathbf z)$，该分布的具体形式未知，定义如下：\n$$\np(\\mathbf z)=\\frac{1}{\\mathbf Z}f(\\mathbf z) \\\\\n\\mathbf Z=\\int f(\\mathbf z) dz\n$$\n其中$\\mathbf Z$为归一化项。\n\n令$\\mathbf z_0$为$f(\\mathbf z) $的驻点，\n$$\n\\ln f(\\mathbf{z}) \\simeq \\ \\ln f(\\mathbf{z}_{0})-\\frac{1}{2}(\\mathbf{z}- \\mathbf{z}_{0})^{\\mathrm{T}}\\mathbf{A}(\\mathbf{z}-\\mathbf{z}_{0}) \\tag 5\n$$\n其中$\\mathbf A$为$M \\times M$的矩阵，是$\\ln f(\\mathbf z)$在驻点$\\mathbf z_0$处的海森矩阵(Hessian matrix)。\n$$\n\\mathbf{A}= \\nabla\\nabla \\ln f(\\mathbf{z}) \\bigg|_{\\mathbf{z}= \\mathbf{z_0}}\n$$\n对于公式5两边去掉$\\ln$，则：\n$$\nf(\\mathbf{z})\\simeq f(\\mathbf{z}_{0})\\exp\\{-\\frac{1}{2}(\\mathbf{z}-\\mathbf{z}_{0})^{\\mathrm T}\\mathbf{A}(\\mathbf{z}-\\mathbf{z}_{0})\\} \\tag6\n$$\n对比式4中的指数项与式6中的指数项可以发现，如果$A= {\\Sigma }^{-1}$ ，则可得归一化的高斯函数$q(\\mathbf z)$为下式：\n$$\nq(\\mathbf z)=\\frac{A^{1/2}}{(2\\pi )^{M/2}} \\exp \\{-\\frac{1}{2}(\\mathbf{z}-\\mathbf{z}_0)^{\\mathrm{T}}\\mathbf{\\Sigma }^{-1}(\\mathbf{z}-\\mathbf{z}_0)\\}\n$$\n其中$|\\mathbf A|$为矩阵$\\mathbf A$的行列式。\n\n# 总结\n\n求一个未知分布的拉普拉斯近似的过程分为两个步骤：\n\n1. 求其分布函数的最大值(mode)，即，驻点。通常是通过一些数值优化算法求的。实际情况下会存在多峰情况的分布，那么可以对不同的波峰进行拉普拉斯近似。\n2. 求海森矩阵。\n\n根据中心极限定理，随着数据量的增加，一个模型的后验分布会越来越与高斯分布相似，所以数据集越大，拉普拉斯近似的作用约理想。\n\n# 参考资料\n\nPattern Recognition and Machine Learning","tags":["Approximation Inference"],"categories":["Mathematics"]},{"title":"可决系数(Coefficient of Determination)","url":"%2Fblog%2FCoefficient-of-Determination.html","content":"\n在scikit-learn中定义的回归问题模型评价指标有：\n\n>explained_variance_score(explained_variance)\n>mean_absolute_error(MAE)\n>mean_squared_error(MSE)\n>mean_squared_log_error(MSLE)\n>median_absolute_error(MedAE)\n>r2_score($R^2$)\n\n可决系数$R^2$是评价回归模型好还的重要指标之一，本文介绍它的数学基础。\n\n# 符号说明\n| 符号          | 涵义                                       |\n| ----------- | ---------------------------------------- |\n| $x_i$       | 样本特征特征，自变量                               |\n| $y_i$       | 样本$x_i$ 的观察值，因变量                         |\n| $\\hat{y}_i$ | 回归模型对于样本$x_i$ 的预测值                       |\n| $\\bar{y}$   | 所有样本观察值（因变量）的平均值 ${\\bar {y}}={\\frac {1}{n}}\\sum _{i=1}^{n}y_{i}$ |\n\n# 可决系数推导过程\n\n离差平方和：因变量$y$相对于其均值的差异：$\\sum_i(y_i- \\bar{y})^2$ 。\n\n对离差平方和进行如下分解：\n$$\n\\begin {aligned}\n\\sum_i(y_i- \\bar{y})^2 &= \\sum_i\\{(y_i - \\hat{y})+(\\hat{y}_i-\\bar{y})\\}^2 \\\\\n&=\\sum_i(y_i - \\hat{y}_i)^2 +\\sum_i(\\hat{y}_i-\\bar{y})^2 + \\sum_i2(y_i - \\hat{y}_i)(\\hat{y}_i-\\bar{y}) \\\\\n&=\\sum_i(y_i - \\hat{y}_i)^2 + \\sum_i(\\hat{y}_i-\\bar{y})^2\n\\end {aligned}\n$$\n\n上式中等号两边分别定义如下：\n\n总体离差平方和： $SST = \\sum_i(y_i- \\bar{y})^2$ 反应因变量的观察值与其均值的总体离差\n\n回归平方和： $SSR= \\sum_i(\\hat{y}_i-\\bar{y})^2=\\sum_i(\\beta x_i-\\bar{y})^2$ 因变量的理论值与样本均值的离差，即有$x$ 与$\\hat y$之间的线性关系引起的$\\hat y$的取值的变化。也就是回归模型能够解释的离差\n\n残差平方和：$SSE=\\sum_i(y_i - \\hat{y}_i)^2\\sum_i e_i^2$ 反应除$x$与$\\hat y$的线性关系以外的其他因素对$y$的取值的影响，及残差\n\n可决系数：\n$$\nR^2=\\frac{SSR}{SST} = 1-\\frac{SSE}{SST}\n$$\n\n# 可决系数总结\n\n可决系数反应了线性回归模型能够解释的离差占总离差的比例，即模型的好坏。\n\n- $R^2 \\in [0,1]$，对于可决系数的改进型，ajusted $R^2$可能出现小于0的情况\n- $R^2$约接近于1说明模型效果越好\n- $R^2$需要在测试集上求的\n- 在一元回归中$R^2 = r^2$，其中$R^2$为可决系数，$r$为相关系数。\n- 在多元回归中，可决系数称为多重可决系数(Maltiple Coefficient of Determination)。\n\n\n# 修正的可决系数\n\n在多元回归中，当样本容量一定时，随着特征的增加可决系数$R^2$总是上升的，即使新特征与因变量不相关，$R^2$也是上升。所以研究人员通常使用修正的可决系数(adjusted $R^2$)$R_a^2$。其定义如下：\n$$\n\\begin {aligned}\nR_a^2 &=1-(1-R^2)\\frac{n-1}{n-p-1} \\\\\n&=1-\\frac{SSE / (n-p-1)}{SST/(n-1)} \\\\\n&=1-\\frac{SSE / df_E}{SST/df_T}\n\\end {aligned}\n$$\n其中: 样本量为$n$， 特征(自变量)数量为$p$， $SST$的自由度(degrees of freedom)为$df_T=n-1$， $SSE$的自由度为$df_E=n-p-1$。 \n\n# 修正的可决系数总结\n\n- 修正的可决系数$R_a^2 \\le R^2$。 \n- 可能是负数，当样本量较少，特征数量较多时可能会出现负值。\n\n\n","tags":["Performance Analysis"],"categories":["Concepts"]},{"title":"偏差-方差分解","url":"%2Fblog%2FBias-Variance-Decomposition.html","content":"\n偏差方差分解(The Bias-Variance Decomposition)是用来衡量模型复杂度的数学工具，也称为(the bias variance trade-off)，是解释学习算法泛化能力的一种工具。\n\n*note: 为了说明方便，我们只讨论回归问题，损失函数使用平方和损失函数*\n\n# 泛化误差\n\n> 假设我们现在有数据集$D=\\{(x_1,t_1),(x_2,t_2),\\dots,(x_N,t_N)\\}$，每个样本的特征用$x$表示，label用$t$表示。\n>\n> 该数据集是从总体$\\Omega$ 中 **独立同分布** 的抽样得到的，即$D \\in \\Omega$。 \n>\n> $\\Omega$中样本服从的分布为$p(x,t)$，存在一个未知函数$h(x)$能够精确计算$x$到$t$的映射。 \n>\n> 在抽样过程中，(观测值)t是存在误差的，所以不能保证$t_i=h(x_i)$。\n>\n> 由于是独立同分布抽样，所以$D$也服从分布$p(x, t)$ 。\n>\n> 我们通过某种方法从数据集$D$中学习到了一个模型$y(x)$ ，即，不同的数据集$D$对应不同的模型超参。\n\n在训练集$D$上的平均误差称为 **经验误差** ：\n$$\nL=\\int\\int{L(t,y(x;D))p(x,t) dx dt}\n$$\n对于回归问题本文使用平方和损失函数（squared loss）则$L$为：\n$$\nL=\\int\\int{ [y(x;D)-t]^2p(x,t) dx dt}\n$$\n\n模型在总体$\\Omega$上的平均误差称为 **泛化误差**。因为我们是无法观察到总体$\\Omega$的，所以泛化误差是无法直接计算的。\n\n但是可以观察到$D$，因为$D$是$\\Omega$的独立同分布采样获得的，所以经验误差的期望等于泛化误差。\n\n$$\n\\begin {aligned}\nE_D[L] =& \\int_D \\int\\int{ [y(x;D)-t]^2p(x,t) dx dt dD} \\\\\n\\end {aligned} \\tag 1\n$$\n\nnote: \n\n1. 泛化误差是经验误差$L$都$D$积分得到的(take the expectation of this expression with respect to $D$)。\n2. 对于不同的数据集$D$，模型的超参是不同的。可以通过贝叶斯理论理解。贝叶斯方法认为超参是一个后验分布，即超参不是一个固定值。频率学派认为超参是一个点估计，对于不同的数据集将得到一个固定估计值，所以超参是不同数据集点估计的期望。\n3. 公式1 的表述我没有在看到的资料中找到，如果个人表达有误，以后修正。\n4. 下面的公式推导都是以公式1 为基础。\n\n# 变量定义\n\n本文中使用的变量定义如下：\n\n| 符号            | 涵义                                 |\n| ------------- | ---------------------------------- |\n| $x$           | 样本特征值                              |\n| $D$           | 数据集                                |\n| $t$           | $x$ 在数据集$D$中的标记                    |\n| $h(x)$        | $x$ 的真实标记                          |\n| $y(x;D)$      | 在数据集 $D$ 学到的模型对$D$中样本$x$的预测标记      |\n| $L$           | 经验误差                               |\n| $E_D[L]$      | 泛化误差，$L$在$D$上的期望                   |\n| $E_D[y(x;D)]$ | 可以理解为有多个数据集$D$，将$x$的预测值在所有的$D$上求期望 |\n\n# 推导过程\n\n偏差-方差分解通过将模型的**泛化误差**( expected  loss)分解成 方差(variance) 偏差(bias) 和 噪声(noise)三部分，来分析一个模型的泛化能力。\n\n当样本量足够大时 $h(x)=E_t[t|x] = \\int tp(t|x)dt$。\n\n使用有限样本集$D$ 训练出来的最优模型 $y(x;D) = E_t[t|x]=\\int tp(t|x)$。(Pattern Recognition and Machine Learning公式 1.87-1.89推导得到)\n\n为了方便下面的公式推导，先列出如下假设：\n\n- 样本的噪声的期望为0（note 区别与下面\"样本噪声\"），即在样本集$D$上 :\n  $$\n  E [t-h(x)] = \\int\\int [t-h(x)] p(t,x) dxdt = 0\n  $$\n\n\n\n\n\n\n\n\n\n\n\n\n由于泛化误差$E_D[L]$是经验误差的期望$E_D[L]=\\int_D L dD$，先将将$L$分解如下：\n$$\n\\begin {aligned}\nL &=\\int\\int{ [y(x;D)-t]^2p(x,t) dx dt} \\\\\n     &=\\int\\int{ [y(x;D)-h(x)+h(x)-t]^2p(x,t) dx dt} \\\\\n     &=\\int\\int{ \\{[y(x;D)-h(x)]+[h(x)-t]\\}^2 p(x,t) dx dt}\\\\\n     &=\\int\\int{ \\{[y(x;D)-h(x)]^2 + 2[y(x;D)-h(x)][h(x)-t] + [h(x)-t]^2\\} p(x,t) dx dt} \\\\\n\\end {aligned}\n$$\n\n前两项对t积分，根据噪声为0的假设，消掉交叉项\n\n$$\n\\begin {aligned}\nL &=\\int{ [y(x;D)-h(x)]^2p(x)dx}  +\\int\\int{ [h(x)-t]^2 p(x,t) dx dt}\n\\end {aligned}\n$$\n\n定义第二项为样本噪声：反应样本抽样值(即观测值)与真实值之间的差异。\n$$\nnoise = E\\{ [t-h(x)]^2\\} = \\int\\int [t-h(x)]^2p(t,x) dxdt \\tag 2\n$$\n$$\n\\begin {aligned}\nE_D[L] &=\\int_D \\int{ [y(x;D)-h(x)]^2p(x)dxdD}  + \\int_D noise dD \\\\\n&=\\int \\int_D{ [y(x;D)-h(x)]^2p(x)dDdx}  + noise \\\\\n\\end {aligned}\n$$\n\n继续分解第一项，在被积分项中添加$E_D[y(x;D)]$：\n$$\n\\begin {aligned}\n\\int \\int_D{ [y(x;D)-h(x)]^2p(x)dDdx} =& \\int\\int_D{ \\{y(x;D)-E_D[y(x;D)]+E_D[y(x;D)]-h(x)\\}^2p(x)dDdx} \\\\\n=& \\int\\int_D\\{y(x;D)-E_D[y(x;D)]\\}^2p(x)dDdx \\\\\n&+ \\int\\int_D2\\{y(x;D)-E_D[y(x;D)]\\}\\{E_D[y(x;D)]-h(x)\\}p(x)dDdx\\\\\n&+ \\int\\int_D\\{E_D[y(x;D)]-h(x)\\}^2 p(x)dDdx\n\\end {aligned}\n$$\n\n三项分别表示如下:\n\n第一项定义为方差\n$$\n\\begin {aligned}\nvariance=& \\int\\int_D\\{y(x;D)-E_D[y(x;D)]\\}^2p(x)dDdx \\\\\n=&\\int E_D\\{y(x;D)-E_D[y(x;D)]\\}^2p(x)dx\n\\end {aligned} \\tag 3\n$$\n第二项(交叉项)值为0\n$$\n\\begin {aligned}\n& \\int\\int_D2\\{y(x;D)-E_D[y(x;D)]\\}\\{E_D[y(x;D)]-h(x)\\}p(x)dDdx\\\\\n&= \\int2\\{E_D[y(x;D)]-h(x)\\}p(x) \\int_D\\{y(x;D)-E_D[y(x;D)]\\} dD dx \\\\\n&= \\int2\\{E_D[y(x;D)]-h(x)\\}p(x) \\{\\int_Dy(x;D)dD-E_D[y(x;D)]\\} dx \\\\\n&= \\int2\\{E_D[y(x;D)]-h(x)\\}p(x) \\{E_D[y(x;D)]-E_D[y(x;D)]\\} dx \\\\\n&=0\n\\end {aligned}\n$$\n第三项定义为偏差\n$$\n\\begin {aligned}\nbias^2 =& \\int\\int_D\\{E_D[y(x;D)]-h(x)\\}^2 p(x)dDdx \\\\\n=& \\int\\{E_D[y(x;D)]-h(x)\\}^2 p(x)dx \\\\\n\\end {aligned} \\tag 4\n$$\n综上，泛化误差可以分解为如下形式：\n$$\n\\begin {aligned}\nE_D[L] =& \\int E_D\\{y(x;D)-E_D[y(x;D)]\\}^2p(x)dx \\\\\n&+  \\int\\{E_D[y(x;D)]-h(x)\\}^2 p(x)dx \\\\\n&+ \\int\\int [t-h(x)]^2p(t,x) dxdt \\\\\n=& variance + bias^2 + noise\n\\end {aligned}\n$$\n\n## 分析\n\n$$\n\\begin {aligned}\nvariance =&\\int E_D\\{y(x;D)-E_D[y(x;D)]\\}^2p(x)dx \\\\\nbias^2=& \\int\\{E_D[y(x;D)]-h(x)\\}^2 p(x)dx \\\\\nnoise =&\\int\\int [t-h(x)]^2p(t,x) dxdt \n\\end {aligned}\n$$\n\n对以上三项分析如下：\n\n$bias^2$：度量了学习算法预测值的期望与真实值之间的偏离程度，即学习算法本身的拟合能力；\n\n$variance$：度量了训练数据集的变化对对学习算法性能的影响。\n\n$noise$： 只和抽样值和数据真实值有关，是样本数据所固有的噪声造成的。是任何学习算法能够达到的泛化误差的最小值。\n\n偏差和方差是一对矛盾体，实际应用中是需要从偏差和方差之间找到一个平衡点使得模型的总的泛化误差最小，即，trade-off between bias and variance。在很多时候表现为超参数的取值，比如回归问题中的正则化系数。当正则化系数过小的时候方差较大(样本选取对模型影响较大)，偏差较小；当正则化系数过大时，方差较小，偏差较大。\n\n# 存在不足\n\n偏差方差分解是从频率学派的角度分析模型复杂度的工具，但是其在实际应用中的价值有限。\n\n使用该方法时首先需要获得多个数据集D，对这些数据集求相应统计量的平均值。\n\n如果我们真的有多个数据集D，把这些数据集合并成为一个大的数据集来作为训练集会得到更好的模型。\n\n\n\n下面介绍一种验证模型偏差方差的工具。\n\n## Learning Curves\n\n增加训练数据量是解决模型过拟合的一个有效手段，但是通常情况下获取额外的训练数据是比较困难的。通过绘制**随着训练数据量的增长模型在制训练集和验证集上的accuracy的图**可以判断一个模型\n\n\n\n![](Bias-Variance-Decomposition/learning-curves.png)\n\n如上如所示：\n\n- 右下角：在数据量增长到一定程度以后，模型在训练集和验证集上的准确度都趋近与desired accuracy。\n- 左上角：模型在训练集和验证集上的accuracy都较低，表明模型具有较大的偏差，模型在训练集上欠拟合。\n- 右上角：训练集和验证集accuracy曲线具有较大的间隔，表明模型具有较大的方差，模型在训练集上过拟合。\n\n## 解决过拟合和欠拟合\n\n我认为解决过拟合和欠拟合问题可以从两个方面考虑：模型、数据\n\n- 过拟合\n  1. 模型：减小模型复杂度（换用更简单的模型，增加正则化）\n  2. 数据：增加数据量\n- 欠拟合\n  1. 模型：增加模型复杂度（换用更复杂的模型，减小正则化）\n  2. 数据：增加新的特征\n\n##  实例\n\n```python\nimport numpy as np\nfrom sklearn.datasets import load_iris\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\n\nnp.random.seed(0)\niris = load_iris()\nX, y = iris.data, iris.target\nindices = np.arange(y.shape[0])\nnp.random.shuffle(indices)\nX, y = X[indices], y[indices]\ny = y > 1\n\npipe_lr = Pipeline([('scl', StandardScaler()),\n                    ('clf', LogisticRegression(penalty='l2', random_state=0, C=0.6))])\n\ntrain_sizes, train_scores, test_scores = learning_curve(estimator=pipe_lr,\n                                                        X=X,\n                                                        y=y,\n                                                        train_sizes=np.linspace(0.1, 1.0, 10),\n                                                        cv=10,\n                                                        n_jobs=1)\n\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\n\nplt.plot(train_sizes, train_mean,\n         color='blue', marker='o',\n         markersize=5, label='training accuracy')\n\nplt.fill_between(train_sizes,\n                 train_mean + train_std,\n                 train_mean - train_std,\n                 alpha=0.15, color='blue')\n\nplt.plot(train_sizes, test_mean,\n         color='green', linestyle='--',\n         marker='s', markersize=5,\n         label='validation accuracy')\n\nplt.fill_between(train_sizes,\n                 test_mean + test_std,\n                 test_mean - test_std,\n                 alpha=0.15, color='green')\n\nplt.grid()\nplt.xlabel('Number of training samples')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.ylim([0.8, 1.0])\nplt.tight_layout()\n# plt.savefig('./figures/learning_curve.png', dpi=300)\nplt.show()\n```\n\n![](Bias-Variance-Decomposition/learning-curves-pra.png)\n\n\n\n\n\n# 参考资料\n\nPattern Recognition and Machine Learning\n\n机器学习_周志华\n\n\n\n\n\n\n\n","tags":["Performance Analysis"],"categories":["Concepts"]},{"title":"【转】相似图片搜索的原理","url":"%2Fblog%2Fpicture-similarity-method.html","content":"\n之前工作中需要处理相似图片, 期间尝试过本文中所说的 感知hash, 也尝试过 SIFT, CNN等方法. 先将此文转了备查. \n\n# 颜色分布法\n\n每张图片都可以生成[颜色分布的直方图](http://en.wikipedia.org/wiki/Color_histogram)（color histogram）。如果两张图片的直方图很接近，就可以认为它们很相似。\n\n![color_histogram1](picture-similarity-method/color-histogram1.jpg)\n\n任何一种颜色都是由红绿蓝三原色（RGB）构成的，所以上图共有4张直方图（三原色直方图 + 最后合成的直方图）。\n\n如果每种原色都可以取256个值，那么整个颜色空间共有1600万种颜色（256的三次方）。针对这1600万种颜色比较直方图，计算量实在太大了，因此需要采用简化方法。可以将0～255分成四个区：0～63为第0区，64～127为第1区，128～191为第2区，192～255为第3区。这意味着红绿蓝分别有4个区，总共可以构成64种组合（4的3次方）。\n\n任何一种颜色必然属于这64种组合中的一种，这样就可以统计每一种组合包含的像素数量。\n\n![color_histogram2](picture-similarity-method/color-histogram2.png)\n\n上图是某张图片的颜色分布表，将表中最后一栏提取出来，组成一个64维向量(7414, 230, 0, 0, 8, ..., 109, 0, 0, 3415, 53929)。这个向量就是这张图片的特征值或者叫\"指纹\"。\n\n于是，寻找相似图片就变成了找出与其最相似的向量。这可以用[皮尔逊相关系数](http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient)或者[余弦相似度](http://www.ruanyifeng.com/blog/2013/03/cosine_similarity.html)算出。\n\n# 内容特征法\n\n除了颜色构成，还可以从比较图片内容的相似性入手。\n\n**首先**，将原图转成一张较小的灰度图片，假定为50x50像素。**然后**，确定一个阈值，将灰度图片转成黑白图片。\n\n![Otsu_method1](picture-similarity-method/Otsu-method1.jpg)\n\n![Otsu_method2](picture-similarity-method/Otsu-method2.jpg)\n\n![Otsu_method3](picture-similarity-method/Otsu-method3.png)\n\n\n\n如果两张图片很相似，它们的黑白轮廓应该是相近的。于是，问题就变成了，第一步如何确定一个合理的阈值，正确呈现照片中的轮廓？\n\n显然，前景色与背景色反差越大，轮廓就越明显。这意味着，如果我们找到一个值，可以使得前景色和背景色各自的\"类内差异最小\"（minimizing the intra-class variance），或者\"类间差异最大\"（maximizing the inter-class variance），那么这个值就是理想的阈值。\n\n1979年，日本学者大津展之证明了，\"类内差异最小\"与\"类间差异最大\"是同一件事，即对应同一个阈值。他提出一种简单的算法，可以求出这个阈值，这被称为[\"大津法\"](http://en.wikipedia.org/wiki/Otsu's_method)（Otsu's method）。下面就是他的计算方法。\n\n假定一张图片共有$n$个像素，其中灰度值小于阈值的像素为 $n_1$ 个，大于等于阈值的像素为 $n_2$ 个（$ n_1 + n_2 = n$ ）。$w_1$ 和 $w_2$ 表示这两种像素各自的比重。\n\n>   　　$w_1 = \\frac {n_1}  {n}$\n>\n>   　　$w_2 = \\frac{n_2} {n}$\n\n再假定，所有灰度值小于阈值的像素的平均值和方差分别为 $\\mu_1$ 和 $\\sigma_1$，所有灰度值大于等于阈值的像素的平均值和方差分别为$\\mu_2$ 和 $\\sigma_2$ 。于是，可以得到\n\n>   　　$类内差异 = w_1 \\sigma_1^2 + w_2 \\sigma_2^2$\n>\n>   　　$类间差异 = w_1w_2(\\mu_1-\\mu_2)^2$\n\n可以证明，这两个式子是等价的：得到\"类内差异\"的最小值，等同于得到\"类间差异\"的最大值。不过，从计算难度看，后者的计算要容易一些。\n\n下一步用\"穷举法\"，将阈值从灰度的最低值到最高值，依次取一遍，分别代入上面的算式。使得\"类内差异最小\"或\"类间差异最大\"的那个值，就是最终的阈值。具体的实例和Java算法，请看[这里](http://www.labbookpages.co.uk/software/imgProc/otsuThreshold.html)。\n\n![Otsu_method4](picture-similarity-method/Otsu-method4.png)\n\n\n有了50x50像素的黑白缩略图，就等于有了一个50x50的0-1矩阵。矩阵的每个值对应原图的一个像素，0表示黑色，1表示白色。这个矩阵就是一张图片的特征矩阵。\n\n两个特征矩阵的不同之处越少，就代表两张图片越相似。这可以用\"异或运算\"实现（即两个值之中只有一个为1，则运算结果为1，否则运算结果为0）。**对不同图片的特征矩阵进行\"异或运算\"，结果中的1越少，就是越相似的图片**。\n\n#  感知哈希算法（Perceptual hash algorithm）\n\n它的作用是对每张图片生成一个\"指纹\"（fingerprint）字符串，然后比较不同图片的指纹。结果越接近，就说明图片越相似。\n\n下面是一个最简单的实现：\n\n![Perceptual_hash2](picture-similarity-method/Perceptual-hash2.png)\n\n**第一步，缩小尺寸。**\n\n将图片缩小到8x8的尺寸，总共64个像素。这一步的作用是去除图片的细节，只保留结构、明暗等基本信息，摒弃不同尺寸、比例带来的图片差异。\n\n![Perceptual_hash1](picture-similarity-method/Perceptual-hash1.png)\n\n**第二步，简化色彩。**\n\n将缩小后的图片，转为64级灰度。也就是说，所有像素点总共只有64种颜色。\n\n**第三步，计算平均值。**\n\n计算所有64个像素的灰度平均值。\n\n**第四步，比较像素的灰度。**\n\n将每个像素的灰度，与平均值进行比较。大于或等于平均值，记为1；小于平均值，记为0。\n\n**第五步，计算哈希值。**\n\n将上一步的比较结果，组合在一起，就构成了一个64位的整数，这就是这张图片的指纹。组合的次序并不重要，只要保证所有图片都采用同样次序就行了。\n\n![Perceptual_hash3](picture-similarity-method/Perceptual-hash3.png)= 8f373714acfcf4d0\n\n得到指纹以后，就可以对比不同的图片，看看64位中有多少位是不一样的。在理论上，这等同于计算[\"汉明距离\"](http://zh.wikipedia.org/wiki/%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB)（Hamming distance）。如果不相同的数据位不超过5，就说明两张图片很相似；如果大于10，就说明这是两张不同的图片。\n\n具体的代码实现，可以参见[Wote](http://www.reddit.com/r/programming/comments/hql8b/looks_like_it_for_the_last_few_months_i_have_had/c1xkcdd)用python语言写的[imgHash.py](http://www.ruanyifeng.com/blog/2011/07/imgHash.txt)。代码很短，只有53行。使用的时候，第一个参数是基准图片，第二个参数是用来比较的其他图片所在的目录，返回结果是两张图片之间不相同的数据位数量（汉明距离）。\n\n这种算法的优点是简单快速，不受图片大小缩放的影响，**缺点是图片的内容不能变更**。如果在图片上加几个文字，它就认不出来了。所以，它的最佳用途是根据缩略图，找出原图。\n\n实际应用中，往往采用更强大的[pHash](http://www.phash.org/)算法和[SIFT](http://en.wikipedia.org/wiki/Scale-invariant_feature_transform)算法，它们能够识别图片的变形。只要变形程度不超过25%，它们就能匹配原图。这些算法虽然更复杂，但是原理与上面的简便算法是一样的，就是先将图片转化成Hash字符串，然后再进行比较。\n\n\n\n以上内容转自 [相似图片搜索的原理](http://www.ruanyifeng.com/blog/2013/03/similar_image_search_part_ii.html)\n\n\n","tags":["Image"],"categories":["Application"]},{"title":"动态规划-背包问题","url":"%2Fblog%2FKnapsack-Problem.html","content":"\n# 0-1背包问题\n\n## 问题定义\n\n维基百科定义如下：\n\n> Given a set of items, each with a weight and a value, determine the number of each item to include in a collection so that the total weight is less than or equal to a given limit and the total value is as large as possible. It derives its name from the problem faced by someone who is constrained by a fixed-size knapsack and must fill it with the most valuable items.\n\n\n\n![](Knapsack-Problem/knapsack-problem01.png)\n\n\n\n举例：\n\n如上图所示有 5 个物品，它们有各自的重量和价值，现有给定容量的背包(15kg)，如何让背包里装入的物品具有最大的价值总和。\n\n|        |  1   |  2   |  3   |  4   |  5   |\n| :----: | :--: | :--: | :--: | :--: | :--: |\n| weight |  2   |  1   |  4   |  1   |  12  |\n| value  |  3   |  2   |  10  |  2   |  4   |\n\n## 求解思路\n\n变量定义：`wt[i]`表示每个物品的重量; `val[i]`表示每个物品的价值，`0 <= i <= n`。背包能放入的最大容量为 W (大写)。\n\n1. 确定状态：背包问题中的状态是一张二维表。\n   其中：行号(i)表示物品编号，第0行表示什么物品都不放在包里。列号(w)表示当前包里最大能放的重量。**每个单元格用 `f[i][w]`表示，含义为 当背包容量 w 时，前 i 个物品的最佳组合放入背包的最大价值。**\n|      | 0    | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    | 10   | 11   | 12   | 13   | 14   | 15   |\n| :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: |\n| 0    |0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|\n| 1    | 0 |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |\n| 2    | 0 |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |\n| 3    | 0 |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |\n| 4    | 0 |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |\n| 5    | 0 |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |\n2. 确定递推公式：\n   对于上述背包问题只需要正确填写上述二维表， `f[n][W]` 即是满足要求的解。\n   考察 3 中情形：\n   \n   - i = 0 or w = 0: 分别表示背包中不放入物品和背包容量为0。此时的最大价值 `f[i][w] = 0`；\n   - 第 i 个物品重量过大 (wt[i]> w)， 此时第i个物品放不到包里面,  `f[i][W] = f[i-1][W]`；\n   - 第 i 个物品可以放入包中，分两种情况：a) 第 i 个物品放入包里，包内物品的价值为 `f[i-1][w-wt[i]] + val[i]`。 b) 第i个物品不放入包里， 包内物品的价值为 `f[i-1][w]`。 `f[i][W]`为其最大值：`f[i][W] = max{f[i-1][w-wt[i]] + val[i], f[i-1][w]}`。\n   \n   总价如下：\n   $$\n   f[i][W] = \n   \\left \\{\n   \\begin {align}\n   & 0,& i = 0\\ or\\ w = 0 \\\\\n   & f[i-1][w] ,& wt[i]> w \\\\\n   & \\max \\{f[i-1][w-wt[i]] + val[i], f[i-1][w]\\},& other\n   \\end {align}\n   \\right .\n   $$\n   \n\n## 实现代码及优化\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nint max(int a, int b) { return (a > b) ? a : b; }\n\nint knapSack(int W, int wt[], int val[], int n) {\n    int i, w;\n    int f[n + 1][W + 1];\n\n    for (i = 0; i <= n; i++) {\n        for (w = 0; w <= W; w++) {\n            if (i == 0 || w == 0)\n                f[i][w] = 0;\n            else if (wt[i - 1] <= w)\n                f[i][w] = max(val[i - 1] + f[i - 1][w - wt[i - 1]], f[i - 1][w]);\n            else\n                f[i][w] = f[i - 1][w];\n        }\n    }       \n    return f[n][W];\n}           \n                \nint main() {\n    int val[] = {2, 1, 4, 1, 12};\n    int wt[] = {3, 2, 10, 2, 4};\n    int W = 15;\n    int n = sizeof(val) / sizeof(val[0]);\n    std::cout << knapSack(W, wt, val, n) << endl;\n    return 0;\n}\n// output 16\n```\n\n空间复杂度优化：通过观察上面的递推公式可以发现， 二维表的 第 i 行只与 第 i-1 行有关， 所以在内存中只需要保留上一行的值。\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nint max(int a, int b) { return (a > b) ? a : b; }\n\nint knapSackOp(int W, int wt[], int val[], int n) {\n    int i, w;\n    int f_pre[W + 1]; \n    int f_cur[W + 1]; \n    for (int w = 0; w <= W; w++) {\n        f_pre[w] = 0;\n    }   \n    for (i = 1; i <= n; i++) {\n        for (w = 0; w <= W; w++) {\n            if (w == 0)\n                f_cur[w] = 0;\n            else if (wt[i - 1] <= w)\n                f_cur[w] = max(val[i - 1] + f_pre[w - wt[i - 1]], f_pre[w]);\n            else\n                f_cur[w] = f_pre[w];\n        }   \n        for (w = 0; w <= W; w++) {\n            f_pre[w] = f_cur[w];\n        }   \n    }   \n    return f_cur[W];\n}\n\nint main() {\n    int val[] = {2, 1, 4, 1, 12};\n    int wt[] = {3, 2, 10, 2, 4}; \n    int W = 15; \n    int n = sizeof(val) / sizeof(val[0]);\n    std::cout << knapSackOp(W, wt, val, n) << endl;\n    return 0;\n}\n// output 16\n```\n\n进一步优化\n\n设想这么一种情形，例题中每个物品的价值不变， 每个物品的重量 分别扩大10倍 100倍 1532倍 … 不等(就是分别扩大若干倍)。按照上面的解题思路，二维表的列数就会增加非常多，而空间复杂度也相应增加。针对这种现象我们可以采用压缩的一维表的方式存储：\n\n下图为[知乎: 0-1背包问题的动态规划算法](https://zhuanlan.zhihu.com/p/30959069)对这种方法的分析：右边为5个物品的价值和重量，左图为二维表。\n\n![](Knapsack-Problem/knapsack-problem02.png)\n\n蓝色单元格为每个行中 状态发生变化的单元格，此时 `f[i][w] = val[i - 1] + f[i - 1][w - wt[i - 1]]`，即第i个物品被放入背包。所有绿色单元格的值都等于其前面的蓝色单元格的值。\n\n所以我们只需要保存每一行的蓝色单元格的值即能达到降低空间复杂度的目的。\n\n# 完全背包问题\n\n## 问题定义\n\n在n种物品中选取若干件（同一种物品可多次选取）放在最大承重为W的背包里，每种物品的重量为`wt[i]`，与之相对应的价值为`val[i]`。求解怎么装物品可使背包里物品总价值最大。\n\n完全背包问题与01背包问题的区别在于完全背包每一件物品的数量都有无限个，而01背包每件物品数量只有1个。\n\n# 求解思路\n\n1. 确定状态：使用和01背包一样的状态，`f[i][w]`表示前 i 种物品放入一个容量为 w 的背包的最大价值。 其实还可以使用上图所示的二维表表示。对于每一个单元格，我们用 k 表示容量 w 下可以装第 i 种物品的件数，那么k的范围应该是 `0 <= k <= w/wt[i]`。\n\n2. 状态转移公式：\n   还可以像 0 1 背包问题 将问题分解问三种情形讨论。不同之处在于 当第 i 种物品放入背包时，需要遍历 k 可能的取值。\n   $$\n   f[i][W] = \n   \\left \\{\n   \\begin {align}\n   & 0,& i = 0\\ or\\ w = 0 \\\\\n   & f[i-1][w] ,& wt[i]> w \\\\\n   & \\max_{k \\in [0, \\frac{w}{wt[i]}]} \\{f[i-1][w-k \\times wt[i]] + k \\times val[i], f[i-1][w]\\},& other\n   \\end {align}\n   \\right .\n   $$\n   \n\n另一种思路：我们可以把把完全背包问题转化为01背包问题来解，第i种物品最多选`w/wt[i] `件，于是可以把第 i种物品转化为`w/wt[i]`件物品，然后求解这个01背包问题。同样可以使用 01 背包问题的优化方法进行优化。\n\n## 实现代码及优化\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nint max(int a, int b) { return (a > b) ? a : b; }\n\nint knapSack(int W, int wt[], int val[], int n) {\n    int i, w;\n    int f[n + 1][W + 1];\n\n    for (i = 0; i <= n; i++) {\n        for (w = 0; w <= W; w++) {\n            if (i == 0 || w == 0)\n                f[i][w] = 0;\n            else if (wt[i - 1] <= w) {\n                int max_val = f[i - 1][w];\n                for (int k = 0; k <= (w / wt[i - 1]); k++)\n                    max_val = max(val[i - 1] * k + f[i - 1][w - wt[i - 1] * k], max_val);\n                f[i][w] = max_val;            \n            } else       \n                f[i][w] = f[i - 1][w];\n        }       \n    }   \n    return f[n][W];\n}   \n\nint main() {\n    int val[] = {15, 20, 30};\n    int wt[] = {1, 3, 4};\n    int W = 4; \n    int n = sizeof(val) / sizeof(val[0]);\n    std::cout << knapSack(W, wt, val, n) << endl;\n    return 0; \n}\n// 60\n```\n\n\n\n# 多重背包问题\n\n问题描述：有n种物品和一个容量为W的背包。第 i 种物品的数量为`k[i]`，重量为 `wt[i]`，价值是`val[i]`。这个背包最多能够装多少价值的物品。\n\n其实就是将完全背包问题中 k 的最大值设置为 k[i]。 思路和代码不再赘述。\n\n# 参考资料\n\n[知乎: 0-1背包问题的动态规划算法](https://zhuanlan.zhihu.com/p/30959069)\n\n\n\n","tags":["programming"],"categories":["programming"]},{"title":"动态规划 - LIS and LCS","url":"%2Fblog%2Fdynamic-programming-LIS-LCS.html","content":"\n# 最长上升子序列（LIS）\n\n给定一个长度为n的整数序列A[]，求它的一个子序列(子序列即在原序列任意位置删除0或多个元素后的序列)，满足如下条件：\n\n1. 该序列单调递增；\n2. 在所有满足条件1的序列中长度是最长的。\n\n让我们举个例子：求 2 7 1 5 6 4 3 8 9 的最长上升子序列。我们定义`d[i]`来表示前`i`个数以`A[i]`结尾的最长上升子序列长度。\n\n- d[1]=1 子序列为2；\n- d[2]=d[1]+1=2 子序列为2 7\n- d[3]=1 子序列为1\n- d[4]=d[1]+1=2 子序列为2 5\n- d[5]=d[4]+1=3 子序列为2 5 6\n- d[6]=d[1]+1=2 子序列为2 4\n- d[7]=d[1]+1=2 子序列为2 3\n- d[8]=d[5]+1=4 子序列为2 5 6 8\n- d[9]=d[8]+1=5 子序列为2 5 6 8 9\n\n可以总结出递推公式为：\n$$\nd[i]=\\max\\{d[1],d[2],……,d[i-1]\\}  + 1\n$$\n代码如下：\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nint LIS(int A[], int n) {\n    int* d = new int[n];\n    int len = 1;\n    int i, j;\n    for (i = 0; i < n; i++) {\n        d[i] = 1;\n        for (j = 0; j < i; j++) {\n            if (A[j] <= A[i] && (d[j] + 1) >= d[i]) d[i] = d[j] + 1;\n        }   \n        if (d[i] > len) len = d[i];\n    }   \n    delete[] d;\n    return len;\n}\n\nint main() {\n    int A[9] = {2,7,1,5,6,4,3,8,9};\n    cout << LIS(A, 9) << endl;\n    return 0;\n}\n```\n\n\n\n# 最长公共子序列(LCS)问题\n\n在两个字符串中，有些字符会一样，可以形成的**子序列**也有可能相等，因此，长度最长的相等子序列便是两者间的最长公共字序列，其长度可以使用动态规划来求。\n\n以s1={1,3,4,5,6,7,7,8},s2={3,5,7,4,8,6,7,8,2}为例。\n\n借用《算法导论》中的推导图：\n\n创建 DP数组C[][];\n\n![](dynamic-programming-LIS-LCS/lcs01.jpg)\n\n图中的空白格子需要填上相应的数字（这个数字就是 c[i, j] 的定义，记录的LCS的长度值）。填的规则依据递归公式，简单来说：如果横竖 (i, j)对应的两个元素相等，该格子的值 = c[i-1,j-1] + 1。如果不等，取c[i-1,j] 和 c[i,j-1]的最大值。首先初始化该表：\n\n![](dynamic-programming-LIS-LCS/lcs02.jpg)\n\n然后，一行一行地从上往下填：\n\n![](dynamic-programming-LIS-LCS/lcs03.jpg)\n\nS1的元素3 与 S2的元素3 相等，所以 c[2,1] = c[1,0] + 1。继续填充：\n\n![](dynamic-programming-LIS-LCS/lcs04.jpg)\n\nS1的元素3 与 S2的元素5 不等，c[2,2] =max(c[1,2],c[2,1])，图中c[1,2] 和 c[2,1] 背景色为浅黄色。\n\n继续填充：\n\n![](dynamic-programming-LIS-LCS/lcs05.jpg)\n\n![](dynamic-programming-LIS-LCS/lcs06.jpg)\n\n![](dynamic-programming-LIS-LCS/lcs07.jpg)\n\n![](dynamic-programming-LIS-LCS/lcs08.jpg)\n\n中间几行填写规则不变，直接跳到最后一行：\n\n![](dynamic-programming-LIS-LCS/lcs09.jpg)\n\n至此，该表填完。根据性质，c[8,9] = S1 和 S2 的 LCS的长度，即为5。\n\n得到公式\n\n$$\nc[i,j]=\n\\left \\{\n\\begin {align}\n&0; & i=0 \\ or \\ j = 0 \\\\\n&c[i-1, j -1] + 1; & i, j \\gt 0\\ and\\ x_i == y_j \\\\\n&max\\{C[i, j-1], C[i-1, j]\\}; & i,j \\gt0,x_i \\ne y_i\n\\end {align}\n\\right .\n$$\n\n代码\n\n```cpp\n#include <iostream>\n#include<string>\nusing namespace std;\n\nint lcs(string str1, string str2) {\n    int len1 = str1.length();\n    int len2 = str2.length();\n    int c[1000][1000]; // 此处假设字符串的最大长度为1000\n    std::cout<< len1 << len2<<  endl;\n    for (int i = 0; i <= len1; i++) {\n        for( int j = 0; j <= len2; j++) {\n            std::cout<< i << j << endl; \n            if(i == 0 || j == 0) {\n                c[i][j] = 0;\n                std::cout<< i << j << endl;\n            } else if (str1[i-1] == str2[j-1]) {\n                c[i][j] = c[i-1][j-1] + 1;\n            } else {\n                c[i][j] = max(c[i - 1][j], c[i][j - 1]);\n            }   \n        }   \n    }   \n    int result = c[len1][len2];\n    return result;\n}   \n\nint main() {\n    string str1 = \"13456778\";\n    string str2 = \"357486782\";\n    cout << lcs(str1, str2) << endl;\n    return 0;\n}\n// 5\n```\n\n\n\n# 参考资料\n\n[动态规划：最长上升子序列（LIS）](https://www.cnblogs.com/GodA/p/5180560.html)\n\n[LCS（最长公共子序列）](<https://blog.csdn.net/someone_and_anyone/article/details/81044153>)","tags":["programming"],"categories":["programming"]},{"title":"动态规划(dynamic programming)","url":"%2Fblog%2Fdynamic-programming.html","content":"\n\n\n最近看了一些动态规划方面的东西，在此作一些笔记。\n\n# 引例\n\n【例1】动态规划算法的核心是记住已经求过的解，记住这些解的方式有两种：自顶向下的**备忘录法**和**自底向上**。 \n为了说明动态规划的这两种方法，先举一个最简单的例子：求斐波拉契数列**Fibonacci** 。\n$$\nFibonacci(n) = \n\\left \\{ \n\\begin {align}\n& 1, n=0 \\\\\n& 1, n=1 \\\\\n& Fibonacci(n-1) + Fibonacci(n-2)\n\\end {align}\n\\right.\n$$\n\n通过递归方法很容易实现，代码如下：\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nint fib_recursive(int n) { \n  if (n <= 0) return 0;\n  if (n == 1) return 1;\n  return fib_recursive(n - 1) + fib_recursive(n - 2);\n}\n\nint main() { \n  cout << fib_recursive(6) << endl;\n  return 0;\n}\n// output 8\n```\n\n用下图表示上面的递归计算，每个节点代表依次计算。\n\n![](dynamic-programming/fib-6.png)\n\n可以发现 `fib(3)` 和`fib(4)` 被分别重复计算了 3 次和 2次。也就是说有很多子节点被重复执行了，存在多余的计算。所以说这个问题还能有更优的求解方法。动态规划就是其优化方法，线面分别使用**自顶向下的备忘录法**和**自底向上**的两个方法求解。\n\n备忘录法：\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nint fib_memo(int n, int* Memo) { \n    if (Memo[n] != -1) return Memo[n];\n    if (n == 0)\n        Memo[n] = 0;\n    else if (n == 1)\n        Memo[n] = 1;\n    else\n        Memo[n] = fib_memo(n - 1, Memo) + fib_memo(n - 2, Memo);\n    return Memo[n]; \n}   \n\nint fib_memo_main(int n) { \n    int* Memo = new int[n + 1];\n    for (int i = 0; i <= n; i++) Memo[i] = -1;\n    int res = fib_memo(n, Memo);\n    delete Memo;\n    return res;\n} \n\nint main() {\n    cout << fib_memo_main(6) << endl;\n    return 0;\n}  \n// output 8\n```\n\n备忘录法也是比较好理解的，创建了一个n+1大小的数组来保存求出的斐波拉契数列中的每一个值，在递归的时候如果发现前面fib(n)的值计算出来了就不再计算，如果未计算出来，则计算出来后保存在Memo数组中，下次在调用fib(n)的时候就不会重新递归了。比如上面的递归树中在计算fib(6)的时候先计算fib(5)，调用fib(5)算出了fib(4)后，fib(6)再调用fib(4)就不会在递归fib(4)的子树了，因为fib(4)的值已经保存在Memo[4]中。\n\n自底向上：\n\n备忘录法还是利用了递归，上面算法不管怎样，计算fib(6)的时候最后还是要计算出fib(1)，fib(2)，fib(3)……,那么何不先计算出fib(1)，fib(2)，fib(3)……,呢？这也就是动态规划的核心，先计算子问题，再由子问题计算父问题。\n\n```cpp\n# 方法 1\n#include <iostream>\nusing namespace std;\n\nint fib_up1(int n) {\n    int* Memo = new int[n + 1];\n    Memo[0] = 0;\n    Memo[1] = 1;\n    for (int i = 2; i <= n; i++) { \n        Memo[i] = Memo[i - 1] + Memo[i - 2];\n    } \n    int result = Memo[n];\n    delete[] Memo;\n    return result;\n}\n\nint main() { \n    cout << fib_up1(6) << endl;\n    return 0;\n} \n// output 8\n```\n\n自底向上方法也是利用数组保存了先计算的值，为后面的调用服务。观察参与循环的只有 `i, i-1,  i-2`三项，因此该方法的空间可以进一步的压缩如下。\n\n```cpp\n# 方法 2\n#include <iostream>\nusing namespace std;\n\nint fib_up2(int n) {\n  if (n == 0) return 0; \n  if (n == 1) return 1;\n  int Memo_i_2 = 0;\n  int Memo_i_1 = 1;\n  int Memo_i = 1; \n  for (int i = 2; i <= n; i++) {\n    Memo_i = Memo_i_2 + Memo_i_1;\n    Memo_i_2 = Memo_i_1;\n    Memo_i_1 = Memo_i;\n  }\n  return Memo_i;\n} \n\nint main() {\n  cout << fib_up2(6) << endl;\n  return 0;\n}\n// output 8\n```\n\n一般来说由于备忘录方式的动态规划方法使用了递归，递归的时候会产生额外的开销，使用自底向上的动态规划方法要比备忘录方法好。 \n\n# 适用的情况\n\n能采用动态规划求解的问题的一般要具有2个性质：\n\n- 最优子结构：如果问题的最优解所包含的子问题的解也是最优的，就称该问题具有最优子结构，即满足最优化原理。因此，某个问题是否适合应用动态规划算法，它是否具有最优子结构性质是一个很好的线索。使用动态规划算法时，用子问题的最优解来构造原问题的最优解。\n\n- 具有重叠子问题：即子问题之间是不独立的，一个子问题在下一阶段决策中可能被多次使用到。（该性质并不是动态规划适用的必要条件，但是如果没有这条性质，动态规划算法同其他算法相比就不具备优势）。在斐波拉契数列中，可以看到大量的重叠子问题，比如说在求fib(6)的时候，fib(2)被调用了5次。如果递归算法反复求解相同的子问题，就称为具有重叠子问题（overlapping subproblems）性质。在动态规划算法中使用数组来保存子问题的解，这样子问题多次求解的时候可以直接查表不用调用函数递归。\n\n- 无后效性：如果给定某一阶段的状态，则在这一阶段以后过程的发展不受这阶段以前各段状态的影响。要求出fib(6)，只需要知道fib(5),fib(4)的值，而fib(5),fib(4)是如何算出来的，对fib(6)的求解释没有影响的。**“未来与过去无关”，**这就是**无后效性**。\n\n\n# 核心思想\n\n**钞票问题**\n\n【例2】先来看看生活中经常遇到的事。假设您是个土豪，身上带了足够的1、5、10、20、50、100元面值的钞票。现在您的目标是凑出某个金额w，**需要用到尽量少的钞票。**\n\n依据生活经验，我们显然可以采取这样的策略：能用100的就尽量用100的，否则尽量用50的……依次类推。在这种策略下，666=6×100+1×50+1×10+1×5+1×1，共使用了10张钞票。\n\n这种策略称为“**贪心**”：假设我们面对的局面是“需要凑出w”，**贪心策略会尽快让w变得更小**。能让w少100就尽量让它少100，这样我们接下来面对的局面就是凑出w-100。长期的生活经验表明，贪心策略是正确的。\n\n但是，如果我们换一组钞票的面值，贪心策略就也许不成立了。如果一个奇葩国家的钞票面额分别是1、5、11，那么我们在凑出15的时候，贪心策略会出错：\n\n- 15=1×11+4×1    （贪心策略使用了5张钞票）\n- 15=3×5               （正确的策略，只用3张钞票）\n\n我们用f(n)来表示“凑出n所需的最少钞票数量”\n\n$f(n)$ 只与 $f(n-1),f(n-5),f(n-11)$相关；更确切地说：\n\n$$\nf(n)=\\min\\{f(n-1),f(n-5),f(n-11)\\}+1\n$$\n\n我们要求出f(n)，只需要求出几个更小的f值。利用自底向上的动态规划方法其代码如下：\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nint bank_note(int n) {\n    int* memo = new int[n + 1];\n    memo[0] = 0;\n    for (int i = 1; i <= n; i++) {\n        int cost = n + 1;\n        if (i - 1 >= 0) cost = std::min(cost, memo[i - 1] + 1);\n        if (i - 5 >= 0) cost = std::min(cost, memo[i - 5] + 1);\n        if (i - 11 >= 0) cost = std::min(cost, memo[i - 11] + 1);\n        memo[i] = cost;\n    }\n    int result = memo[n];\n    delete[] memo;\n    return result;\n}\n\nint main() {\n    cout << bank_note(15) << endl;\n    return 0;\n}\n```\n\n结合上例我们讨论 动态规划算法的核心思想。动态规划为什么会快？\n\n无论是动态规划还是暴力求解，都是在**可能解空间**内，寻找**最优解**。\n\n钞票问题中，暴力求解是枚举所有的可能解，这是遍历了可能解空间。动态规划是枚举**有希望成为答案的解**。这个空间比暴力的小得多。也就是说：**动态规划自带剪枝**。\n\n动态规划舍弃了一大堆不可能成为最优解的答案。譬如：\n15 = 5+5+5 被考虑了。\n15 = 5+5+1+1+1+1+1 从来没有考虑过，因为这不可能成为最优解。\n\n从而我们可以得到动态规划的核心思想：**尽量缩小可能解空间。**\n\n在暴力算法中，可能解空间往往是指数级的大小；如果我们采用动态规划，那么有可能把解空间的大小降到多项式级。一般来说，解空间越小，寻找解就越快。这样就完成了优化。\n\n# 问题求解步骤\n\n解决动态规划类问题，分为两步：\n\n1.确定状态，\n\n2.根据状态确定状态转移方程\n\n确定状态上可以执行的操作，然后是当前状态和前一个状态或者前多个状态有什么关联，通常当前状态下可执行的操作必定是关联到我们之前的几个状态。\n\n# 动态规划的经典模型及其举例\n\n线性模型: 线性指的是状态的排布是呈线性的。举例：Fibonacci问题； [最长上升子序列(LIS-LCS)](https://weirping.github.io/blog/dynamic-programming-LIS-LCS.html)。\n\n区间模型: \n\n背包模型: [背包问题](https://weirping.github.io/blog/Knapsack-Problem.html)。\n\n# 参考资料\n\n[知乎讨论：什么是动态规划（Dynamic Programming）？动态规划的意义是什么？](https://www.zhihu.com/question/23995189/answer/613096905)\n\n[算法-动态规划 Dynamic Programming--从菜鸟到老鸟](https://blog.csdn.net/u013309870/article/details/75193592)\n\n[动态规划问题集锦与讲解](https://segmentfault.com/a/1190000004498566)\n\n[动态规划：最长上升子序列（LIS）](https://www.cnblogs.com/GodA/p/5180560.html)\n\n[知乎: 0-1背包问题的动态规划算法](https://zhuanlan.zhihu.com/p/30959069)\n\n","tags":["programming"],"categories":["programming"]},{"title":"拉格朗日对偶问题","url":"%2Fblog%2FLagrange-Duality.html","content":"\n拉格朗日对偶(Lagrange Dualtiy)问题在机器学习的很多模型推导中都会用到，如SVM。在日常的文章阅读过程中也多次遇到。\n\n作用：在机器学习中拉格朗日对偶是用在 束最优化问题的求解过程中。\n\n要理解拉格朗日对偶需要弄清楚三个问题：\n\n1. 原始问题\n2. 对偶问题\n3. 原问题与对偶问题的关系\n\n下面逐个讲解着三个问题。\n\n# 原始问题\n\n对偶问题是相对与原始问题而言的。下面这个含有约束的最优化问题就称为 **原始最优化问题 或 原始问题** 。\n$$\n\\left \\{\n\\begin {aligned}\n      & \\min f(x) \\\\\ns.t. & h_i(x) = 0 (i=1,2,\\dots ,m) \\\\\n      & g_j(x) \\le 0 (j=1,2,\\dots ,l) \\\\\n\\end {aligned}\n\\right . \\tag 1\n$$\n对于这个原始问题，我们的求解思路就是构建一个广义拉格朗日函数：\n$$\nL(x, \\lambda, \\upsilon) = f(x) + \\sum_{i=1}^m \\lambda_i h_i(x) +\\sum_{j=1}^l  \\upsilon_j g_j(x)\n$$\n其中：$\\upsilon_j \\ge 0$。\n\n通过求解$L(x, \\lambda, \\upsilon)$函数的最小值来得到$f(x)$的最小值。\n\n将$x$看作常数$\\lambda_i, \\upsilon_j$看作变量，求$L(x, \\lambda, \\upsilon)$的最大值：\n$$\n\\begin {aligned}\n\\theta_P(x) & = \\max_{\\lambda_i,\\upsilon_j \\ge 0} L(x, \\lambda, \\upsilon) \\\\\n                     &= \\max_{\\lambda_i,\\upsilon_j \\ge 0} \\{ f(x) + \\sum_{i=1}^m \\lambda_i h_i(x) +\\sum_{j=1}^l  \\upsilon_j g_j(x) \\}\n\\end {aligned}\n$$\n当$x$ 满足约束条件时，$\\sum_{i=1}^m \\lambda_i h_i(x) = 0, \\sum_{j=1}^l  \\upsilon_j g_j(x) \\le 0$ ,所以 $\\theta_(xP) = f(x)$。\n\n当$x$ 不满足约束条件时， $\\theta_P(x) = + \\infty$。\n\n即：\n$$\n\\theta_P(x) =\n\\left \\{\n\\begin {aligned}\n&f(x),        &x满足约束条件 \\\\\n&+\\infty,  &x不满足约束条件\n\\end {aligned}\n\\right .\n$$\n所以：\n$$\n \\min \\theta_P(x) = \\min_x \\max_{\\lambda_i,\\upsilon_j \\ge 0} L(x, \\lambda, \\upsilon) \\tag 2\n$$\n称为**广义拉格朗日函数的极小极大问题**。\n\n当$x$ 满足约束条件时：\n$$\n\\min f(x) = \\min \\theta_P(x)\n$$\n由于以上等价关系，式(2)与式原始优化问题(1)是等价的，所以在有些文章中讨论对偶问题时常用$\\min \\theta_P(x)$表示**原始最优化问题**。\n\n原始问题的值用p表示（通常时 p星, hexo需要转义，我就用p了）。\n$$\np = \\min \\theta_P(x)\n$$\n\n# 对偶问题\n\n在《凸优化》这本书中，将**对偶函数**定义为如下形式(为了符号统一，我修改了部分符号)：\n$$\n\\theta_D(\\lambda, \\upsilon) = \\min_x L(x, \\lambda, \\upsilon)\n$$\n即，对偶问题首先将$\\lambda, \\upsilon$看作常数，将$x$ 看作变量，求$L(x, \\lambda, \\upsilon)$关于$x$的极小值。\n\n然后求$\\theta_D(\\lambda, \\upsilon)$的极大值：\n$$\n\\max_{\\lambda_i,\\upsilon_j \\ge 0} \\theta_D(\\lambda, \\upsilon) = \\max_{\\lambda_i,\\upsilon_j \\ge 0} \\min_x L(x, \\lambda, \\upsilon) \\tag 3\n$$\n这就是**广义拉格朗日函数的极大极小问题**。与之等价的约束最优化问题如下：\n$$\n\\left \\{\n\\begin {aligned}\n      & \\max_{\\lambda_i,\\upsilon_j} \\theta_D(\\lambda, \\upsilon) = \\max_{\\lambda_i,\\upsilon_j \\ge 0} \\min_x L(x, \\lambda, \\upsilon) \\\\\ns.t. & \\upsilon_j \\ge 0,  (i=1,2,\\dots ,l) \\\\\n\\end {aligned}\n\\right . \\tag 4\n$$\n称为原始问题的**对偶问题**。\n\n对偶问题的值为:\n$$\nd = \\max_{\\lambda_i,\\upsilon_j \\ge 0} \\theta_D(\\lambda, \\upsilon)\n$$\n\nnote: 对于原始问题(1)来说变量是$x$ , 对于对偶问题(4)来说变量是$\\lambda, \\upsilon$。所以原始问题的最优解记为$\\hat x$，对偶问题的最优解记为$\\hat \\lambda, \\hat \\upsilon$。\n\n# 原问题与对偶问题的关系\n\n在实际应用中对偶问题是怎么使用的呢？\n\n当原始问题和对偶问题都有最优值时：\n$$\n\\begin {aligned}\n& \\left \\{\n\\begin {aligned}\n\\theta_D(\\lambda, \\upsilon) = \\min_x L(x, \\lambda, \\upsilon)\\\\ \n\\\\\n\\theta_P(x) = \\max_{\\lambda_i,\\upsilon_j \\ge 0} L(x, \\lambda, \\upsilon) \\\\\n\\end {aligned}\n\\right . \\\\\n\\\\\n& \\Rightarrow  \n\\theta_D(\\lambda, \\upsilon) = \\min_x L(x, \\lambda, \\upsilon) \n\\le L(x, \\lambda, \\upsilon) \\le \n\\max_{\\lambda_i,\\upsilon_j \\ge 0} L(x, \\lambda, \\upsilon) = \\theta_P(x)\\\\\n\\\\\n& \\Rightarrow\nd = \\max_{\\lambda_i,\\upsilon_j \\ge 0} \\theta_D(\\lambda, \\upsilon)  \\le  \\min_x \\theta_P(x) = p\n\\end {aligned}\n$$\n\n可以看出：**在某种情况下原始问题的最优值$p$ 与对偶问题的最优值$d$相等。**那么什么情况下原问题和对偶问题的最优值相等呢？\n\n下面直接给出《统计学习方法》中的几个定理和推论。\n\n>考虑原始问题(1)和对偶问题(4)。假设$f(x)$和$g_j(x)$是凸函数，$h_i(x)$是仿射函数；并且假设不等式约束$g_j(x)$时严格可行的，即存在$x$，对于所有的$i$有$g_j(x) < 0$，则存在$\\hat x, \\hat \\lambda, \\hat \\upsilon$，使$\\hat x$是原问题的解，$\\hat x, \\hat \\lambda, \\hat \\upsilon$是对偶问题的解，并且$p = d = L(\\hat x, \\hat \\lambda, \\hat \\upsilon)$\n\n\n\n> 对于原始问题(1)和对偶问题(4)。假设$f(x)$和$g_j(x)$是凸函数，$h_i(x)$是仿射函数；并且假设不等式约束$g_j(x)$时严格可行的。则$\\hat x, \\hat \\lambda, \\hat \\upsilon$分别是原始问题和对偶问题的解的充分必要条件是$\\hat x, \\hat \\lambda, \\hat \\upsilon$满足下面的Karush -Kuhn -Tucker(KKT)条件：\n> $$\n> \\left \\{\n> \\begin {aligned}\n>  \\nabla_x f(\\hat x) + \\sum_i^m \\lambda_i \\nabla_x h_i(\\hat x) + \\sum_j^l \\upsilon_j  \\nabla_x g_j(\\hat x) &= 0 \\\\\n>                                                                                                                                                                   h_i(\\hat x) &= 0 (i=1,2,\\dots ,m) \\\\\n>                                                                                                                                                                   g_j(\\hat x) &\\le 0, (j = 1,2 \\dots l) \\\\\n>                                                                                                                                                \\upsilon_j g_j(\\hat x) &= 0, (j = 1,2 \\dots l) \\\\\n>                                                                                                                                                                  \\upsilon_j & \\ge 0, (j = 1,2 \\dots l) \\\\\n>  \\end {aligned}\n> \\right .\n> $$\n>\n\n也就是说在满足上面的(KKT)条件的情况下，对偶问题的最优值和原始问题的最优值相等。\n\n# 总结\n\n在求解约束的最优化问题时，如果原始问题求解困难，而对偶问题求解相对容易，那么可以在满足KKT条件的情况下，通过求解对偶问题来得到原始问题的最优值和最优解。\n\n\n# 参考资料\n\n凸优化(Boyd)\n\n统计学习方法\n\n","tags":["Optimization"],"categories":["Mathematics"]},{"title":"Matrix and Vector Products in Numpy","url":"%2Fblog%2FMatrix-and-Vector-Products-in-Numpy.html","content":"\n最近复习了numpy中的数组和广播机制并总结成两篇文章分别为【broadcasting in numpy】和【ndarray in Numpy】。本文总结Numpy提供的几个用于矩阵和向量乘法的线性代数函数。\n\n[`inner(a, b)`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.inner.html#numpy.inner)\n\n**a 和 b的最后一个维度的内积。结果的维度为`a.shape[:-1] + b.shape[:-1]`**\n\n一维数组的内积\n\n```python\n>>> a = np.array([1,2,3])\n>>> b = np.array([0,1,0])\n>>> np.inner(a, b)\n2\n```\n\n多维数组与一维数组的内积\n\n```python\n>>> a = np.arange(24).reshape((2,3,4))\n>>> b = np.arange(4)\n>>> np.inner(a, b)\narray([[ 14,  38,  62],\n       [ 86, 110, 134]])\n```\n\n数组与标量\n\n```python\n>>> np.inner(np.eye(2), 7)\narray([[ 7.,  0.],\n       [ 0.,  7.]])\n```\n\n[`matmul(a, b[, out])`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html#numpy.matmul)\n\nMatrix product of two arrays.\n\nThe behavior depends on the arguments in the following way.\n\n- 如果都是二维数组时 they are multiplied like conventional matrices.\n- 如果a是一维数组, it is promoted to a matrix by prepending a 1 to its dimensions. After matrix multiplication the prepended 1 is removed.\n- 如果b是一维数组, it is promoted to a matrix by appending a 1 to its dimensions. After matrix multiplication the appended 1 is removed.\n- ~~If either argument is N-D, N > 2, it is treated as a stack of matrices residing in the last two indexes and broadcast accordingly.~~\n- a 和 b都不能是标量(scalar)\n\n两个二维数组\n\n```python\n>>> a = [[1, 0], [0, 1]]\n>>> b = [[4, 1], [2, 2]]\n>>> np.matmul(a, b)\narray([[4, 1],\n       [2, 2]])\n\n\n```\n\n二维数组与一维数组\n\n```python\n>>> a = [[1, 0], [0, 1]]\n>>> b = [1, 2]\n>>> np.matmul(a, b)\narray([1, 2])\n>>> np.matmul(b, a)\narray([1, 2])\n```\n\n[`dot(a, b[, out])`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html#numpy.dot)\n\n该函数可以是inner， matmul， multiply三个函数的结合体。\n\n- 如果a和b有一个是一维数组时，等价于`inner(a, b)`。\n\n- 如果a和b都是二维数组时，等价于`matmul(a, b)`。\n- 如果a和b有一个是标量时，等价于`multiply(a, b)`。\n- ~~If *a* is an N-D array and *b* is an M-D array (where `M>=2`), it is a sum product over the last axis of *a* and the second-to-last axis of *b*~~\n\n```python\n>>> x = np.arange(12).reshape((3,4))\n>>> a = np.arange(4)\n>>> b = np.arange(12, 24).reshape((3,4))\n>>> c = 10\n>>> np.dot(x, a)\narray([14, 38, 62])\n>>> np.inner(x, a)\narray([14, 38, 62])\n>>> \n>>> np.dot(x, b.T)\narray([[ 86, 110, 134],\n       [302, 390, 478],\n       [518, 670, 822]])\n>>> np.matmul(x, b.T)\narray([[ 86, 110, 134],\n       [302, 390, 478],\n       [518, 670, 822]])\n>>> \n>>> np.dot(x, c)\narray([[  0,  10,  20,  30],\n       [ 40,  50,  60,  70],\n       [ 80,  90, 100, 110]])\n>>> np.multiply(x, c)\narray([[  0,  10,  20,  30],\n       [ 40,  50,  60,  70],\n       [ 80,  90, 100, 110]])\n```\n\n[`vdot(a, b)`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.vdot.html#numpy.vdot)\n\n计算两个一维向量的 内积 。 如果参数传的是多维数组，则将其 `flatten` 后计算内积\n\n```python\n>>> x = np.arange(1, 7).reshape(2, 3)\n>>> y = np.arange(2, 8).reshape(2, 3)\n>>> np.vdot(x, y) == np.vdot(x.flatten(), y.flatten())\nTrue\n```\n\n[`outer(a, b[, out])`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.outer.html#numpy.outer)\n\n一维数组与一维数组的外积\n\n```python\n>>> m = np.arange(1, 4)\n>>> n = np.arange(3, 6)\n>>> np.outer(m, n)\narray([[ 3,  4,  5],\n       [ 6,  8, 10],\n       [ 9, 12, 15]])\n```\n\n\n\n参考资料\n\nhttps://docs.scipy.org/doc/numpy/reference/routines.linalg.html","tags":["Python"],"categories":["Python"]},{"title":"broadcasting in numpy","url":"%2Fblog%2Fbroadcasting-in-numpy.html","content":"\n广播（broadcasting）是numpy数组的重要概念，对于它的理解有利于更深入的理解ndarray数组的计算逻辑。Numpy中有一种重要的函数叫做 `universal function (ufunc)`  ，一个 `ufunc` 以两个 `ndarray` 作为输入并返回一个`ndarray` ，`ufunc` 按照element-by-element方式操作参数中的两个 `ndarray` ，并返回结果。对于一个`ufun` `np.add` 有如下例子:\n\n```python\n>>> import numpy as np\n>>> arr1 = np.arange(24).reshape(2,3,4)\n>>> arr2 = np.arange(24).reshape(2,3,4)\n>>> np.add(arr1, arr2)\narray([[[ 0,  2,  4,  6],\n        [ 8, 10, 12, 14],\n        [16, 18, 20, 22]],\n\n       [[24, 26, 28, 30],\n        [32, 34, 36, 38],\n        [40, 42, 44, 46]]])\n```\n\n`np.add` 将 arr1 和 arr2中相同位置的元素相加得到一个`ndarray` 类型的而结果。\n\n那么问题来了，如果做为输入参数的两个 ndarray 的 具有不同的shape怎么办呢？广播就是用来解决这个问题的。\n\n# 问题分析\n\n首先我们通过下面的例子来分析一下两个 ndarray 有哪些中不同shape的参数？\n\n假设一个参数固定为 `arr.shape`：(5, 6)\n\n另外一个参数为\n\n- `a.shape` is (5,1)  \n- `b.shape` is (1,6) \n- `c.shape` is (6,) \n- `d.shape` is ()  ：一个标量(scalar)\n- `e.shape` is (5,) \n- f 另外还有一种情况：两个数组分别为 m.shape(5, 1), n.shape(1,6)， 求m 和n 的ufunc结果。\n- `g.shape` is (4, 3)\n- `h.shape` is (4, 6)\n\n理论上，广播可以解决以上每种情况，但是，我们常见的是 a、b、c、d 四种，e、f 偶尔会遇到，g、h基本遇不到。\n\n# 广播的机制\n\n下面为[Broadcasting](https://docs.scipy.org/doc/numpy/reference/ufuncs.html#broadcasting)对广播机制的描述：\n\n> 1. All input arrays with `ndim`smaller than the input array of largest `ndim`, have 1’s **prepended** to their shapes. （如果不人为指定，默认是在shape的最前面增加若干个 1，使得两个array的 ndim属性相等）\n> 2. The size in each dimension of the output shape is the maximum of all the input sizes in that dimension.\n> 3. An input can be used in the calculation if its size in a particular dimension either matches the output size in that dimension, or has value exactly 1.\n> 4. If an input has a dimension size of 1 in its shape, the first data entry in that dimension will be used for all calculations along that dimension. In other words, the stepping machinery of the `ufunc` will simply not step along that dimension (the stride will be 0 for that dimension).\n\n按照上述机制，可以将`a-e`5种情况对应的广播机制处理流程整理成如下图所示的过程：其中`shape_arr` 是一个和arr的shape相同的数组。该流程中变化的是他们的shape\n\n![](broadcasting-in-numpy/a2e.png)\n\n问题 f 中 m 和 n 的shape变化流程是这样的:\n\n![](broadcasting-in-numpy/mn.png)\n\n**需要强调的是：广播机制是我们理解Numpy的一种逻辑模型，在实际的数据计算阶段是不会沿着轴长度为1的方向将数组复制若干份的。**\n\n# 举例\n\n下面以 `ufunc` 函数 `np.add` 为例介绍以上每种情况数据处理流程。\n\n数据准备：\n\n```python\n>>> arr\narray([[ 1.,  1.,  1.,  1.,  1.,  1.],\n       [ 1.,  1.,  1.,  1.,  1.,  1.],\n       [ 1.,  1.,  1.,  1.,  1.,  1.],\n       [ 1.,  1.,  1.,  1.,  1.,  1.],\n       [ 1.,  1.,  1.,  1.,  1.,  1.]])\n```\n\n**情况a & 情况b**\n\n```python\n>>> a = np.arange(5).reshape(5, 1)\n>>> a\narray([[0],\n       [1],\n       [2],\n       [3],\n       [4]])\n>>> np.add(arr, a)\narray([[ 1.,  1.,  1.,  1.,  1.,  1.],\n       [ 2.,  2.,  2.,  2.,  2.,  2.],\n       [ 3.,  3.,  3.,  3.,  3.,  3.],\n       [ 4.,  4.,  4.,  4.,  4.,  4.],\n       [ 5.,  5.,  5.,  5.,  5.,  5.]])\n\n>>> b = np.arange(6).reshape(1, 6)\n>>> b\narray([[0, 1, 2, 3, 4, 5]])\n>>> np.add(arr, b)\narray([[ 1.,  2.,  3.,  4.,  5.,  6.],\n       [ 1.,  2.,  3.,  4.,  5.,  6.],\n       [ 1.,  2.,  3.,  4.,  5.,  6.],\n       [ 1.,  2.,  3.,  4.,  5.,  6.],\n       [ 1.,  2.,  3.,  4.,  5.,  6.]])\n```\n\n`np.add(arr, a)` 的计算过程可以理解为如下过程：\n\n1. 将a的第一列数据沿着轴1复制，得到如下数组:（其实只有这一步能算的是广播）\n\n   ```\n   array([[0, 0, 0, 0, 0, 0],\n          [1, 1, 1, 1, 1, 1],\n          [2, 2, 2, 2, 2, 2],\n          [3, 3, 3, 3, 3, 3],\n          [4, 4, 4, 4, 4, 4]])       \n   ```\n\n2. 将该数组与arr相加\n\n`np.add(arr, b)` 的计算过程可以理解为如下过程：\n\n1. 将a的第一列数据沿着轴1复制，得到如下数组:（其实只有这一步能算的是广播）\n\n   ```python\n   array([[0, 1, 2, 3, 4, 5],\n          [0, 1, 2, 3, 4, 5],\n          [0, 1, 2, 3, 4, 5],\n          [0, 1, 2, 3, 4, 5],\n          [0, 1, 2, 3, 4, 5],\n          [0, 1, 2, 3, 4, 5]])  \n   ```\n\n2. 将该数组与arr相加\n\n**情况c**\n\n```python\n>>> c = np.arange(6).reshape(6)\n>>> c\narray([0, 1, 2, 3, 4, 5])\n>>> np.add(arr, c)\narray([[ 1.,  2.,  3.,  4.,  5.,  6.],\n       [ 1.,  2.,  3.,  4.,  5.,  6.],\n       [ 1.,  2.,  3.,  4.,  5.,  6.],\n       [ 1.,  2.,  3.,  4.,  5.,  6.],\n       [ 1.,  2.,  3.,  4.,  5.,  6.]])\n```\n\n该过程可以理解为如下过程：\n\n1. 先将c转换成情况b，c.shape is (6,) ，在shape的最前面添加个 '1' 使得 c.shape is (1, 6)。即使 ` c.ndim == arr.ndim`\n2. 按照情况b进行计算\n\n**情况d**\n\n```python\n>>> d = 5\n>>> d\n5\n>>> np.add(arr, d)\narray([[ 6.,  6.,  6.,  6.,  6.,  6.],\n       [ 6.,  6.,  6.,  6.,  6.,  6.],\n       [ 6.,  6.,  6.,  6.,  6.,  6.],\n       [ 6.,  6.,  6.,  6.,  6.,  6.],\n       [ 6.,  6.,  6.,  6.,  6.,  6.]])\n```\n\n该过程可以理解为如下过程：\n\n1. d.shape is (,) ，在shape的最前面添加两个 '1' 使得 d.shape is (1, 1)。即使 ` c.ndim == arr.ndim`\n\n2. 在轴1，和轴0上分别复制，得到：\n\n   ```python\n   array([[5, 5, 5, 5, 5, 5],\n          [5, 5, 5, 5, 5, 5],\n          [5, 5, 5, 5, 5, 5],\n          [5, 5, 5, 5, 5, 5],\n          [5, 5, 5, 5, 5, 5]])\n   ```\n\n3. 将该数组与arr相加\n\n**情况e**\n\n```python\n>>> e = np.arange(5).reshape(5)\n>>> e\narray([0, 1, 2, 3, 4])\n>>> np.add(arr, e)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nValueError: operands could not be broadcast together with shapes (5,6) (5,)\n```\n\n如上所示，直接操作arr和e是错误的。由于广播机制默认是在e.shape的最前面加一个‘1’，这样 arr.shape is (5, 6)，e.shape is (1, 5)，但是 最后一个轴的值不想等，所以不能计算。\n\n如果实际情况允许的话，我们可以e当做一个列向量，即，shape(5, 1)。可以通过如下两种方法实现：通过 reshape函数 或者 np.newaxis \n\n*推荐使用np.newaxis*\n\n```python\n>>> e_reshape = e.reshape(5, 1)\n>>> e_reshape\narray([[0],\n       [1],\n       [2],\n       [3],\n       [4]])\n>>> np.add(arr, e_reshape)\narray([[ 1.,  1.,  1.,  1.,  1.,  1.],\n       [ 2.,  2.,  2.,  2.,  2.,  2.],\n       [ 3.,  3.,  3.,  3.,  3.,  3.],\n       [ 4.,  4.,  4.,  4.,  4.,  4.],\n       [ 5.,  5.,  5.,  5.,  5.,  5.]])       \n       \n>>> e_newaxis = e[:, np.newaxis]\n>>> e_newaxis\narray([[0],\n       [1],\n       [2],\n       [3],\n       [4]])\n>>> np.add(arr, e_newaxis)\narray([[ 1.,  1.,  1.,  1.,  1.,  1.],\n       [ 2.,  2.,  2.,  2.,  2.,  2.],\n       [ 3.,  3.,  3.,  3.,  3.,  3.],\n       [ 4.,  4.,  4.,  4.,  4.,  4.],\n       [ 5.,  5.,  5.,  5.,  5.,  5.]])\n```\n\n**情况f**\n\n```python\n>>> m = np.arange(5).reshape(5, 1)\n>>> m\narray([[0],\n       [1],\n       [2],\n       [3],\n       [4]])\n>>> n = np.arange(6).reshape(1, 6)\n>>> n\narray([[0, 1, 2, 3, 4, 5]])\n>>> np.add(m, n)\narray([[0, 1, 2, 3, 4, 5],\n       [1, 2, 3, 4, 5, 6],\n       [2, 3, 4, 5, 6, 7],\n       [3, 4, 5, 6, 7, 8],\n       [4, 5, 6, 7, 8, 9]])\n```\n\nm和n的ndim是相等的，但是m.shape is (5, 1)， n.shape is (1, 6)。\n\n1. 对于轴1 来说，需要沿着轴1 将m复制6次得到：\n\n```python\narray([[0, 0, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1, 1],\n       [2, 2, 2, 2, 2, 2],\n       [3, 3, 3, 3, 3, 3],\n       [4, 4, 4, 4, 4, 4]])\n```\n\n2. 对于轴0来说，需要将n沿着轴0复制5次得到：\n\n```python\narray([[0, 1, 2, 3, 4, 5],\n       [0, 1, 2, 3, 4, 5],\n       [0, 1, 2, 3, 4, 5],\n       [0, 1, 2, 3, 4, 5],\n       [0, 1, 2, 3, 4, 5]])\n```\n\n3. 然后将以上两个数组相加。\n\n# 总结\n\n广播就是用于操作 ndim相同的两个数组的。\n\n这两个数组的shape值只能是两种情况(即，对应的轴长度)：\n\n1. 对应位置的值相等，\n2. 对应位置的值不相等，但其中一个必须是 1。\n\n对于ndim不同的两个数组需要在 某个数组的shape中合适的位置补 1，使得 ndim想等:\n\n1. 默认是在shape的最前面补充若干个 1，\n2. 也可以通过reshape函数或者np.newaxis 人为指定需要补 1 的轴。\n\n\n《利用Python进行数据分析》中用一句话定义了广播的原则\n\n>如果两个数据的后缘维度(trailing dimension, 即从末尾开始算起的维度)的轴长度相符或者一方的长度是1，则认为他们是广播兼容的。广播会在确实和(或)长度为1的维度上进行。\n\n**再次强调一下：广播机制是我们理解Numpy的一种逻辑模型，在实际的数据计算阶段是不会沿着轴长度为1的方向将数组复制若干份的。**\n\n# 参考资料\n\n[Broadcasting](https://docs.scipy.org/doc/numpy/reference/ufuncs.html#broadcasting)\n\n[用Python做科学计算](http://old.sebug.net/paper/books/scipydoc/)\n\n利用python进行数据分析","tags":["Python"],"categories":["Python"]},{"title":"ndarray in Numpy","url":"%2Fblog%2Fndarray-in-numpy.html","content":"\nndarray 数组是我们用python进行科学计算时常用的数据类型，对它的深入了解是非常必要的。本文回顾之前学习的有关adarray的知识。\n\n# 内存结构\n\nndarray 的内存结构如下图所示：\n\n![](ndarray-in-numpy/numpy_memory_struct.png)\n\n- data：指向数组中元素的二进制数据块。\n- dtype:定义了数组中存放的对象的数据类型，通过它可以知道如何将元素的二进制数据转换为可用的值。如上图每32位表示一个有用数据\n- dim count: 表示数组维数，上图为2维数组 (对应ndarray的属性`ndim`)\n- dimmension: 数组的形状，3×3给出数组的(对应ndarray的属性`shape`)\n- strides: 保存的是当每个轴的下标增加1时，数据存储区中的指针所增加的字节数。例如图中的strides为12,4，即第0轴的下标增加1时，数据的地址增加12个字节：即a[1,0]的地址比a[0,0]的地址要高12个字节，正好是3个单精度浮点数的总字节数；第1轴下标增加1时，数据的地址增加4个字节，正好是单精度浮点数的字节数。\n\n## dtype\n\ndtype（数据类型）是一个特殊的对象，它含有ndarray将一块内存解释为特定数据类型所需的信息。\n\n可以通过ndarray的astype方法显式地转换其dtype。\n\n```python\n>>> import numpy as np\n>>> arr = np.array([1, 2, 3], dtype=np.int32)\n>>> arr\narray([1, 2, 3], dtype=int32)\n>>> arr.dtype\ndtype('int32')\n>>> float_arr = arr.astype(np.float128)\n>>> float_arr.dtype\ndtype('float128')\n```\n\nnumpy 有多种预定义的dtype（用的比较多的还是`np.float64`），需要的时候可以自行查找\n\n还可以自定义数组的dtype。\n\n## strides再说明\n\n有时ndarray中的数据并不一定都是连续储存的，通过下标范围得到新的数组是原始数组的视图(类似于引用)，即它和原始视图共享数据存储区域， 对于新数组来说，其中的数据不一定是连续存储的。如下所示：\n\n```python\n>>> import numpy as np\n>>> a = np.array([[0,1,2],[3,4,5],[6,7,8]], dtype=np.float32)\n>>> a\narray([[ 0.,  1.,  2.],\n       [ 3.,  4.,  5.],\n       [ 6.,  7.,  8.]], dtype=float32)\n>>> a.strides\n(12, 4)\n>>> b = a[::2,::2]\n>>> b\narray([[ 0.,  2.],\n       [ 6.,  8.]], dtype=float32)\n>>> b.strides\n(24, 8)\n```\n\n由于数组b和数组a共享数据存储区，而b中的第0轴和第1轴都是数组a中隔一个元素取一个，因此数组b的strides变成了24,8，正好都是数组a的两倍。\n\n元素在数据存储区中的排列格式有两种：C语言格式和Fortan语言格式。在C语言中，多维数组的第0轴是最上位的，即第0轴的下标增加1时，元素的地址增加的字节数最多；而Fortan语言的多维数组的第0轴是最下位的，即第0轴的下标增加1时，地址只增加一个元素的字节数。在NumPy中，元素在内存中的排列缺省是以C语言格式存储的，如果你希望改为Fortan格式的话，只需要给数组传递order=\"F\"参数：\n\n```python\n>>> c = np.array([[0,1,2],[3,4,5],[6,7,8]], dtype=np.float32, order=\"C\")\n>>> c.strides\n(12, 4)\n>>> f = np.array([[0,1,2],[3,4,5],[6,7,8]], dtype=np.float32, order=\"F\")\n>>> f.strides\n(4, 12)\n```\n\n# ndarray的创建\n\n创建ndarray对象的常用函数如下所示：\n\n```python\n np.array\n np.asarray\n np.arange  # 通过开始值、终值和步长 创建一维数组\n np.linspace  # 通过开始值、终值和元素个数创建一维数组\n np.logspace  # 产生等比数列\n np.ones\n np.ones_like\n np.zeros\n np.zeros_like\n np.empty\n np.empty_like\n np.eye\n np.identity\n np.fromfunction  # 根据下标生成数组\n```\n\n示例代码如下：\n\n```python\n>>> np.arange(0,1,0.1)\narray([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9])\n>>> np.linspace(0, 1, 12)\narray([ 0.        ,  0.09090909,  0.18181818,  0.27272727,  0.36363636,\n        0.45454545,  0.54545455,  0.63636364,  0.72727273,  0.81818182,\n        0.90909091,  1.        ])\n>>> np.logspace(0, 2, 20)\narray([   1.        ,    1.27427499,    1.62377674,    2.06913808,\n          2.6366509 ,    3.35981829,    4.2813324 ,    5.45559478,\n          6.95192796,    8.8586679 ,   11.28837892,   14.38449888,\n         18.32980711,   23.35721469,   29.76351442,   37.92690191,\n         48.32930239,   61.58482111,   78.47599704,  100.        ])\n\n>>> def func(i):\n...     return i%4+1\n... \n>>> np.fromfunction(func, (10,))\narray([ 1.,  2.,  3.,  4.,  1.,  2.,  3.,  4.,  1.,  2.])\n\n>>> def func2(i, j):\n...     return (i+1) * (j+1)\n... \n>>> np.fromfunction(func2, (4, 4))\narray([[  1.,   2.,   3.,   4.],\n       [  2.,   4.,   6.,   8.],\n       [  3.,   6.,   9.,  12.],\n       [  4.,   8.,  12.,  16.]])\n```\n\n\n\n# ndarray元素的索引\n\nndarray提供了三种索引方法。\n\n## 切片索引\n\n通过下标范围获取的新的数组是原始数组的一个视图。**它与原始数组共享同一块数据空间**，所以对 索引数组的修改 就是对原始数组的修改。\n\n如果你想要得到的是ndarray切片的一份副本而非视图，就需要显式地进行复制操作，例如arr[5:8].copy()。\n\n```python\n>>> a = np.arange(10)\n>>> a[5]    # 用整数作为下标可以获取数组中的某个元素\n5\n>>> a[3:5]  # 用范围作为下标获取数组的一个切片，包括a[3]不包括a[5]\narray([3, 4])\n>>> a[:5]   # 省略开始下标，表示从a[0]开始\narray([0, 1, 2, 3, 4])\n>>> a[:-1]  # 下标可以使用负数，表示从数组后往前数\narray([0, 1, 2, 3, 4, 5, 6, 7, 8])\n>>> a[2:4] = 100,101    # 下标还可以用来修改元素的值\n>>> a\narray([  0,   1, 100, 101,   4,   5,   6,   7,   8,   9])\n>>> a[1:-1:2]   # 范围中的第三个参数表示步长，2表示隔一个元素取一个元素\narray([  1, 101,   5,   7])\n>>> a[::-1] # 省略范围的开始下标和结束下标，步长为-1，整个数组头尾颠倒\narray([  9,   8,   7,   6,   5,   4, 101, 100,   1,   0])\n>>> a[5:1:-2] # 步长为负数时，开始下标必须大于结束下标\narray([  5, 101])\n```\n\n## 花式索引(整数序列)\n\n当使用整数序列对数组元素进行存取时，将使用整数序列中的每个元素作为下标，整数序列可以是列表或者数组。\n\n**使用整数序列作为下标获得的数组不和原始数组共享数据空间。**\n\n```python\n>>> x = np.arange(10,1,-1)\n>>> x\narray([10,  9,  8,  7,  6,  5,  4,  3,  2])\n>>> x[[3, 3, 1, 8]] # 获取x中的下标为3, 3, 1, 8的4个元素，组成一个新的数组\narray([7, 7, 9, 2])\n>>> b = x[np.array([3,3,-3,8])]  #下标可以是负数\n>>> b[2] = 100\n>>> b\narray([  7,   7, 100,   2])\n>>> x   # 由于b和x不共享数据空间，因此x中的值并没有改变\narray([10,  9,  8,  7,  6,  5,  4,  3,  2])\n>>> x[[3,5,1]] = -1, -2, -3 # 整数序列下标也可以用来修改元素的值\n>>> x\narray([10, -3,  8, -1,  6, -2,  4,  3,  2])\n```\n\n## 布尔索引(布尔数组 & 布尔列表)\n\n当使用布尔数组b作为下标存取数组x中的元素时，将收集数组x中所有在数组b中对应下标为True的元素。\n\n**使用布尔数组作为下标获得的数组和原始数组共享数据空间，注意这种方式只对应于布尔数组**\n\n**不能使用布尔列表， 否则会把True当作1, False当作0，按照整数序列方式获取原始中的元素，不共享内存**\n\n```python\n>>> x = np.arange(5,0,-1)\n>>> x\narray([5, 4, 3, 2, 1])\n>>> x[np.array([True, False, True, False, False])] # 布尔数组中下标为0，2的元素为True，因此获取x中下标为0,2的元素\narray([5, 3])\n>>> x[[True, False, True, False, False]] # 如果是布尔列表，则把True当作1, False当作0，按照整数序列方式获取x中的元素\narray([5, 3])\n>>> x[np.array([True, False, True, True])] # 布尔数组的长度不够时，不够的部分都当作False\n__main__:1: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 0; dimension is 5 but corresponding boolean dimension is 4\narray([5, 3, 2])\n>>> x[np.array([True, False, True, True])] = -1, -2, -3  # 布尔数组下标也可以用来修改元素\n>>> x\narray([-1,  4, -2, -3,  1])\n```\n\n布尔数组 索引可以使用逻辑运算， 分别为 `|, &, ~ ` (或 与 非)。*不能使用 and or not*\n\n```python\n>>> names = np.array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe']) # 七个人 ，有重复\n>>> data = np.random.randn(7, 4) # 7个人的成绩，每行一个人\n>>> data[~(names == 'Bob')]   #  查看除了 Bob 之外 其他六个人的成绩 ， 等价于 data[(names != 'Bob')]\narray([[ 0.07820045, -1.71734855, -0.34533472,  0.13199966],\n       [ 1.44077541,  0.599357  ,  0.02741339, -0.27952545],\n       [ 0.40324184, -1.14696069, -2.63616404, -0.89460574],\n       [-1.07763886,  1.38956886, -0.51076578,  0.22787857],\n       [-0.56223972, -0.4285839 ,  1.00189764, -1.27962868]])\n>>> data[names == 'Bob']  # 查看 Bob 的成绩\narray([[-0.20510993,  1.16346024,  1.0559742 , -0.17387184],\n       [ 0.08864056,  0.49012893, -0.27613655, -0.89549472]])\n>>> mask = (names == 'Bob') | (names == 'Will')\n>>> data[mask]   # 查看 Bob 和 Will 的成绩\narray([[-0.20510993,  1.16346024,  1.0559742 , -0.17387184],\n       [ 1.44077541,  0.599357  ,  0.02741339, -0.27952545],\n       [ 0.08864056,  0.49012893, -0.27613655, -0.89549472],\n       [ 0.40324184, -1.14696069, -2.63616404, -0.89460574]])\n```\n\n\n\n# 参考资料\n\n[用Python做科学计算](http://old.sebug.net/paper/books/scipydoc/)\n\n利用python进行数据分析","tags":["Python"],"categories":["Python"]},{"title":"假设检验","url":"%2Fblog%2Fhypothesis-testing.html","content":"\n看文章是每次遇到假设检验方面的内容老是犯迷糊，导致每次都需要重新翻书本。所有我决定干脆把假设检验想管的内容做一次系统性的整理。\n\n# 引例\n\n某车间用一台包装机包装葡萄糖.袋装糖的净重是一个随机变量,它服从正态分布当机器正常时,其均值为0.5kg,标准差为0.015kg,某日开工后为检验包装机是否正常,随机地抽取它所包装的糖9袋称得净重为(kg)\n$$\n0.497, 0.506, 0.518, 0.524, 0.498, 0.511, 0.520, 0.515, 0.512\n$$\n问机器是否正常?\n\n以$\\mu$, $\\sigma$分别表示这一天袋装糖的净重总体$X$的均值和标准差. $\\sigma=0.015$. 于是$X \\sim N(\\mu,0.0152)$,这里未知问题是根据样本值来判断$\\mu = 0.5$还是$\\mu \\neq 0.5$.为此我们提出两个相互对立的假设.\n$$\nH_0: \\mu = 0.5 \\\\\nH_1: \\mu \\neq 0.5\n$$\n由于要检验的假设涉及未知的总体$X$的均值$\\mu$, 使用$\\mu$的无偏统计量 $\\bar x$ 替代。如果假设$H_0$为真, 则观察值与$\\mu_0=0.5$的偏差$|\\bar x - \\mu_0|$ 一般不应太大. 若 $|\\bar x - \\mu_0|$ 过大,我们就怀疑假设$H_0$的正确性而拒绝$H_0$ .\n\n当$H_0$为真时$\\frac{\\bar X - \\mu_0}{\\sigma / \\sqrt n} \\sim N(0, 1)$ .而衡量 $|\\bar x - \\mu_0|$ 的大小可归结为衡量 $\\frac{ | \\bar x - \\mu_0 | }{\\sigma / \\sqrt n}$ 的大小. 基于上面的想法,我们可适当选定一正数 $k$ . 使当观察值满足 $\\frac{ | \\bar x - \\mu_0 | }{\\sigma / \\sqrt n} \\ge k$  时就拒绝假设$H_0$, 反之,就接受假设$H_0$ 。$\\frac{ | \\bar x - \\mu_0 | }{\\sigma / \\sqrt n}$ 即为 **检验统计量**。\n\n当检验统计量取某个区域$C$中的值时, 我们拒绝原假设 $H_0$, 则称区域$C$为**拒绝域**， 反之则为**接受域**。 拒绝域的边界点称为**临界点**。此处的$k$ 即是临界点。\n\n# 假设检验\n\n##  两类错误\n\n由于检验法则是根据样本作出的, 总有可能作出错误的决策。 在假设 $H_0$ 实际上为真时,我们可能犯拒绝 $H_0$ 的错误,称这类“弃真”的错误为第I类错误. 又当 $H_0$ 实际上不真时, 我们也有可能接受 $H_0$ 称这类“取伪”的错误为第Ⅱ类错。\n\n一般来说,当样本容量固定时,若减少犯一类错误的概率, 则犯另一类错误的概率往往增大. 若要使犯两类错误的概率都减小,除非增加样本容量. \n\n在给定样本容量的情况下, 我们总是控制犯第I类错误的概率, 使它不大于 $\\alpha$,  $\\alpha$的大小视具体情况而定,通常取0.1, 0.05, 0.01, 0.005等值.  $\\alpha$ 即为 **显著性水平**。\n\n这种只对犯第I类错误的概率加以控制,而不考虑犯第Ⅱ类错误的概率的检验, 称**显著性检验** 。\n\n## 引例求解\n\n此例中 犯第一类错误的概率为 $P(\\text{当}H_0 \\text{为真时拒绝}H_0)$  , 使得犯这一类错误的概率不超过 显著性水平 $\\alpha$ 。\n$$\nP(\\text{当}H_0 \\text{为真时拒绝}H_0) = P_{\\mu \\in H_0}(\\frac{ | \\bar x - \\mu_0 | }{\\sigma / \\sqrt n} \\ge k ) \\le \\alpha\n$$\n其中:  $P_{\\mu \\in H_0}(.)$ 表示 $\\mu$ 取 $H_0$ 规定的值时的事件， 即$H_0$ 为真时。此时, $z = \\frac{\\bar X - \\mu_0}{\\sigma / \\sqrt n} \\sim N(0, 1)$ . 由标准正太分布的分位点得 \n$$\nk = z_{\\alpha/2}\n$$\n分位点与显著行水平的关系如下：\n\n![](hypothesis-testing/normal-dist.png)\n\n因而,若$Z$的观察值满足 $|z| = \\frac{|\\bar X - \\mu_0|}{\\sigma / \\sqrt n} \\ge k = z_{\\alpha/2}$ 则拒绝$H_0$。而若 $|z| = \\frac{|\\bar X - \\mu_0|}{\\sigma / \\sqrt n} \\lt k = z_{\\alpha/2}$ , 则接受$H_0$ .\n本例中取$\\alpha=0.05$,则有$k=z_{0.05/2} =1.96$, 又知$n=9$, $\\sigma = 0.015$, 由样本算得$\\bar x=0.511$,即有\n$$\n\\frac{|\\bar X - \\mu_0|}{\\sigma / \\sqrt n} = 2.2 \\gt 1.96\n$$\n\n于是拒绝$H_0$, 认为这天包装机工作不正常.\n\nnote：通常软件(如spss)中会直接给出 p 值，即 犯第一类错误的概率， 我们可以直接和设定的显著性水平进行比较。\n\n# 单边检验\n\n像引例中的备择假设$H_1$,表示$\\mu$可能大于$\\mu_0$,也可能小于$\\mu_0$,称为**双边备择假设**, 而称形如引例重的假设检验为**双边假设检验**。\n有时,我们只关心总体均值是增大，还是减小。\n\n形如：\n\n$$\nH_0: \\mu \\le \\mu_0 \\\\\nH_1: \\mu \\gt \\mu_0\n$$\n\n的假设检验成为右边检验（备选假设落于右边）。\n\n形如：\n\n$$\nH_0: \\mu \\ge \\mu_0 \\\\\nH_1: \\mu \\lt \\mu_0\n$$\n\n的假设检验成为左边检验（备选假设落于左边）。\n\n右边检验和左边检验成为双边检验。\n\n### 单边检验的求解\n\n设总体$X \\sim N(\\mu, \\sigma^2)$, $\\mu$未知、$\\sigma$已知,$X_1,X_2, \\dots ,X_n$,是来自$X$的样本. 给定显著性水平$a$. 求检验问题\n$$\nH_0: \\mu \\le \\mu_0 \\\\\nH_1: \\mu \\gt \\mu_0\n$$\n的拒绝域。\n\n因$H_0$中的全部$\\mu$都比H1中的μ要小,当$H_1$为真时,观察值$\\bar x$往往偏大. 因此, 拒绝域的形式为\n$$\nx≥k(k是某一正常数)\n$$\n下面来确定常数k:\n\n$$\n\\begin {align}\nP(\\text{当}H_0 \\text{为真时拒绝}H_0) &= P_{\\mu \\in H_0}(\\bar X \\ge k) \\\\\n&= P_{\\mu \\le \\mu_0}(\\frac{ \\bar X - \\mu_0}{\\sigma / \\sqrt n} \\ge \\frac{k - \\mu_0}{\\sigma / \\sqrt n} ) \\\\\n&\\le  P_{\\mu \\le \\mu_0}(\\frac{ \\bar X - \\mu}{\\sigma / \\sqrt n} \\ge \\frac{k - \\mu_0}{\\sigma / \\sqrt n} ) \\\\\n\\end {align}\n$$\n\n上式不等号成立是由于$\\mu \\le \\mu_0, \\frac{ \\bar X - \\mu}{\\sigma / \\sqrt n} \\ge \\frac{ \\bar X - \\mu_0}{\\sigma / \\sqrt n}$\n\n要控制$P(\\text{当}H_0 \\text{为真时拒绝}H_0)$,只需令\n$$\nP_{\\mu \\le \\mu_0}(\\frac{ \\bar X - \\mu}{\\sigma / \\sqrt n} \\ge \\frac{k - \\mu_0}{\\sigma / \\sqrt n} ) =a\n$$\n\n\n\n\n由于 $\\frac{\\bar X - \\mu}{\\sigma / \\sqrt n} \\sim N(0, 1)$, 由上式得 $\\frac{k - \\mu_0}{\\sigma / \\sqrt n} = z_a$ , 如下图所示.\n\n![](hypothesis-testing/right-test.jpg)\n\n所以 $k = \\mu_0 + \\frac \\sigma {\\sqrt n} z_a$, 即，右边检验问题的拒绝域为：\n$$\n\\bar x \\ge \\mu_0 + \\frac \\sigma {\\sqrt n} z_a \\\\\nz = \\frac{\\bar x - \\mu}{\\sigma / \\sqrt n} \\ge z_a\n$$\n\n类似的， 左边检验\n$$\nH_0: \\mu \\ge \\mu_0 \\\\\nH_1: \\mu \\lt \\mu_0\n$$\n\n的拒绝域\n\n$$\nz = \\frac{\\bar x - \\mu}{\\sigma / \\sqrt n} \\le -z_a\n$$\n\n\n\n# 常用的假设检验\n\n\n\n## 单个总体$N(\\mu,\\sigma^2)$均值$\\mu$的检验\n\n### $\\sigma$ 已知 (z检验)\n\n假设检验问题：$X \\sim N(\\mu, \\sigma^2)$, $\\mu$未知, $\\sigma$ 已知 ,求检验问题$H_0: \\mu = \\mu_0; H_1 \\neq \\mu_0$ 的拒绝域。\n\n统计量： $Z=\\frac{\\bar X - \\mu_0}{\\sigma / \\sqrt n} \\sim N(0, 1)$\n\n拒绝域：  $\\|z\\| = \\frac{\\|\\bar X - \\mu_0\\|}{\\sigma / \\sqrt n} \\ge z_{\\alpha/2}$\n\n### $\\sigma$ 未知 (t检验)\n\n假设检验问题： $X \\sim N(\\mu, \\sigma^2)$, $\\mu$,$\\sigma$未知  ,求检验问题$H_0: \\mu = \\mu_0; H_1 \\neq \\mu_0$ 的拒绝域。\n\n统计量：   $t=\\frac{\\bar X - \\mu_0}{S / \\sqrt n} \\sim t(n-1)$\n\n拒绝域：$\\|t\\|=\\|\\frac{\\bar X - \\mu_0}{S / \\sqrt n}\\| \\ge t_{a/2}(n-1)$\n\nnote: \n\n1. $n-1$ 为自由度；\n2. t检验中实际上是用样本方差 $S^2$ 替代未知的 总体方差 $\\sigma^2$. 替代以后的统计量恰好是 t统计量\n\n## 两个正太总体均值差的检验 (t 检验)\n\n假设检验问题： $X \\sim N(\\mu_1, \\sigma^2); Y \\sim N(\\mu_2, \\sigma^2)$ $X$ 和 $Y$ 的样本均值分别为$\\bar X$， $\\bar Y$, 方差为 $S_1^2$, $\\S_2^2$. 样本量为： $n_1$, $n_2$.求检验问题 $H_0: \\mu_1 - \\mu_2 = \\delta, H_1: \\mu_1 - \\mu_2 \\neq \\delta$\n\n统计量： $t=\\frac{(\\bar X - \\bar Y) - \\delta}{S_w / \\sqrt (\\frac 1n_1+ \\frac 1n_2)} \\sim t(n_1 +n_2 -2)$  其中 $S_w^2 = \\frac{(n_1-1)S_1^2 + (n_2-1)S_2^2}{n_1 +n_2 -2}$\n\n拒绝域：$|t|=\\frac{|(\\bar X - \\bar Y) - \\delta|}{S_w / \\sqrt (\\frac 1n_1+ \\frac 1n_2)} \\ge t_{a/2}(n_1 +n_2 -2)$\n\n## 其他检验\n\n成对样本的检验 (t检验)\n\n正态总体方差的检验： 单个总体（$\\chi^2$ 检验）；两个总体（F检验）\n\n# 总结\n\n- 两类错误：一般来说我们总是控制犯第一类错误的概率。\n- 显著性水平 $\\alpha$ ：本质是我们人为可以接受的犯第一类错误的概率。\n- 置信度 ： $(1-\\alpha)$\n- 显著性检验：只对犯第一类错误的概率加以控制，而不考虑犯第二类错误的概率的检验。\n- 双边检验、单边检验（左边检验，右边检验）及其求解。\n- 统计量： z 统计量，t 统计量，$\\chi^2$统计量， F统计量\n\n\n# 参考资料\n\n《概率论与数理统计》-第四版-浙大版 第八章","tags":["Statistics"],"categories":["Mathematics"]},{"title":"Hexo配置","url":"%2Fblog%2Fhexo-config.html","content":"\n作为一个技术人员，平时肯定需要学习一些东西，多年以来我习惯将学的的东西记录在文件中保存。时间长了以后就出问题了：\n\n1. 文件查找困难。当我想回头看之前记录的东西时，由于文件较多，查找困难，最终还是去网上找。\n2. 无法添加tag\n\n后来尝试使用博客园，发现博客的发布和管理相当不方便。\n\n最后决定使用Hexo在github上写。由于我需要编写Latex公式，Hexo的配置还是消耗了一些时间的，为了防止以后搭建博客时的重复劳动，遂成此文。\n\n本文记录个人的Hexo的配置过程(在windows上)，希望最终形成一个脚本，能够自动完成个人博客的配置工作。\n\n# 前期准备\n\n1. 安装[Git Bash](https://git-scm.com/downloads)\n   配置git：在新机器上生成一个ssh秘钥和公钥\n\n   ```shell\n   ssh-keygen -t rsa -C \"weirping@work-VM\"  ## -t 加密算法， -C comment 用于连接github\n   git config --global user.name 'weirping'  ## \n   git config --global user.email \"zhangweiping1988@gmail.com\"  ## \n   ```\n\n2. 安装[NodeJs](https://nodejs.org/en/) ，安装是勾选 `Add to PATH`选项\n\n3. 使用淘宝 NPM 镜像\n\n   ```\n   npm --registry https://registry.npm.taobao.org info underscore \n   ```\n# blog初始化与配置\n\n```shell\nnpm install hexo -g  # 安装hexo模块\n\nhexo init blog  # 初始化一个博客目录\n\ncd blog\n\nnpm install  #这样会在blog文件夹中生成整个博客程序\n```\n\n修改站点信息\n```yaml\n# Site\ntitle: Weiping's notes\nsubtitle:\ndescription:\nkeywords: NLP, ML\nauthor: Weiping\nlanguage: zh-Hans\ntimezone:\n```\n\n修改url ：去掉url中年月日的显示\n\n```yaml\npermalink: blog/:title.html  # :year/:month/:day/:title/\n```\n\n`_post` 目录下的文件夹：默认情况下，`_post` 目录下的文件夹是不会发布的。当我编写一个markdown文件的时候，如 a.md 。我会在同级目录下建一个 **文件夹a**，将markdown文件所需要的图片放到**文件夹a**中，在md文件中只需要使用  `![](a/p.png)`就能引用这个图片。\n\n当我编写好一个md文件后，只需要将**a.md**和**文件夹a** 同时拷贝到`_post` 中，发布即可。为了做到这一点，需要：\n\n```yaml\npost_asset_folder: true  # false\n```\n\n# NexT主题安装与配置\n\n## 安装\n\n```shell\ngit clone https://github.com/theme-next/hexo-theme-next themes/next  # install\n```\n\n启用NexT主题：打开 站点的配置文件`_config.yml`， 找到 `theme` 字段，并将其值更改为 `next`\n\n```yaml\ntheme: next\n```\n\n## NexT配置\n\n### 选择 Scheme\n\n```yaml\n# ---------------------------------------------------------------\n# Scheme Settings\n# ---------------------------------------------------------------\n# Schemes\n#scheme: Muse\nscheme: Mist\n#scheme: Pisces\n#scheme: Gemini\n```\n\n### 设置头像\n\n新建文件夹`source/avatar` 在其中放入头像文件 `avatar.jpg`\n\n修改主题配置文件 `_config.yml`\n\n```\navatar: /avatar/avatar.jpg\n```\n\n### 设置sidebar\n\n```yaml\nsidebar:\n  display: post\n```\n\n设置我的github 和email\n\n```yaml\nsocial:\n  GitHub: https://github.com/weirping || github\n  E-Mail: mailto:zhangweiping1988@gmail.com || envelope\n```\n\n### 页脚 (footer)\n\n```yaml\nfooter:\n  since: 2017\n  icon:\n    name: user\n    animated: false\n    color: \"#808080\"\n  copyright:\n  powered:\n    enable: false\n    version: false\n  theme:\n    enable: false\n    version: false\n```\n\n### 显示blog修改时间\n\n```yaml\npost_meta:\n  updated_at: true\n```\n\n### 摘要\n\nhome页面自动提取各blog的摘要\n\n```yaml\nauto_excerpt:\n  enable: true\n  length: 150\n```\n\n### 设置 菜单\n\n```shell\nhexo new page tags  # 新建tags页面\nhexo new page categories  # 新建categories页面\n```\n\n在`source\\tags\\index.md` 中添加如下内容\n\n```\n---\ntitle: 标签\ndate: 2014-12-22 12:39:04\ntype: \"tags\"\n---\n```\n\n在`source\\categories\\index.md` 中添加如下内容\n\n```\n---\ntitle: 分类\ndate: 2014-12-22 12:39:04\ntype: \"categories\"\n---\n```\n\n修改主题配置文件 `_config.yml`\n\n```yaml\nmenu:\n  home: / || home\n  #about: /about/ || user\n  tags: /tags/ || tags\n  categories: /categories/ || th\n  archives: /archives/ || archive\n  #schedule: /schedule/ || calendar\n  #sitemap: /sitemap.xml || sitemap\n  #commonweal: /404/ || heartbeat\n```\n\n### Latex公式支持\n\n修改主题配置文件 `_config.yml`\n\n```yaml\nmath:\n  enable: true  \n  per_page: false\n```\n\nMathjax和Markdown一起工作有个坑。\n下划线`_` 在Markdown里面是标记斜体字，而下划线`_`在Latex语法中是表示下标。\n`\\\\` 在 Markdown中会被转义为`\\` ，而在Latex中`\\\\` 表示多行公式的换行符。\n\nMarkdown优先于Mathjax，所以下划线会渲染成斜体字，导致一些MathJax公式不能正常显示。为了解决这个问题需要修改Hexo的渲染引擎 `marked` 的转义配置。位于: `node_modules\\marked\\lib\\marked.js` 中替换`escape` 和`em` \n\n```javascript\nvar inline = {\n  // escape: /^\\\\([\\\\`*{}\\[\\]()#+\\-.!_>])/,\n  escape: /^\\\\([`*\\[\\]()# +\\-.!_>])/,  \n  // em: /^_([^\\s_](?:[^_]|__)+?[^\\s_])_\\b|^\\*((?:\\*\\*|[^*])+?)\\*(?!\\*)/,\n  em: /^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/,\n```\n\n### 禁用公式自动编号\n\nNext 集成的Mathjax 默认是开启自动编号功能的. 这个自动编号存在两个问题: 当一个公式书写多行以后, 每一行都会有一个编号, 显的非常凌乱; 和markdown中的公式编号冲突, 当用markdown编写的公式自带编号时, 会和Mathjax自动添加的编号同时出现, 显得更加凌乱.\n\n所以需要禁用自动编号功能:\n\n修改文件: themes/next/layout/_third-party/math/mathjax.swig\n\n```html\n<script type=\"text/x-mathjax-config\">\n    MathJax.Hub.Config({\n      tex2jax: { \n        inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"]  ],\n        processEscapes: true,\n        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']\n      },\n      TeX: {equationNumbers: { autoNumber: \"AMS\" }}\n    });\n</script>\n\n<script type=\"text/x-mathjax-config\">\n    MathJax.Hub.Queue(function() { \n      var all = MathJax.Hub.getAllJax(), i;\n        for (i=0; i < all.length; i += 1) { \n          all[i].SourceElement().parentNode.className += ' has-jax';\n        } \n    });\n</script>\n<script type=\"text/javascript\" src=\"{{ theme.math.mathjax.cdn }}\"></script>\n```\n\n删除其中的第8行 `TeX: {equationNumbers: { autoNumber: \"AMS\" }}`, 保存即可.\n\n```html\n<script type=\"text/x-mathjax-config\">\n    MathJax.Hub.Config({\n      tex2jax: { \n        inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"]  ],\n        processEscapes: true,\n        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']\n      },\n    });\n</script>\n\n<script type=\"text/x-mathjax-config\">\n    MathJax.Hub.Queue(function() { \n      var all = MathJax.Hub.getAllJax(), i;\n        for (i=0; i < all.length; i += 1) { \n          all[i].SourceElement().parentNode.className += ' has-jax';\n        } \n    });\n</script>\n<script type=\"text/javascript\" src=\"{{ theme.math.mathjax.cdn }}\"></script>\n```\n\n# 发布到github\n\n在 github 上创建 blog repo\n\n![](hexo-config/create-blog-repo.png)\n\n配置blog\n\n```yaml\ndeploy:\n  type: git\n  repository: git@github.com:Weirping/weirping.github.io.git\n  branch: master\n```\n\n# 部署脚本\n\n根据以上内容我编写了一个自动化部署Hexo Blog 脚本，地址为：\n\n```\nhttps://github.com/Weirping/hexo-install\n```\n\n\n\n","tags":["Hexo"],"categories":["Hexo"]},{"title":"PRank算法","url":"%2Fblog%2FPRank.html","content":"\nLTR模型可以分为 point-wise、pair-wise、list-wise三类，Prank算法属于point-wise模型。\n\nPointwise可以用于推荐系统中也可以用于IR中。\n\n以Pointwise在IR中的应用为例，它处理对象是doc-query pair，将doc-query的match信息转化为特征向量后，机器学习系统根据训练得出的模型对doc-query pair进行打分，打分的顺序即为搜索排序的结果。计算打分的公式如下：\n\n$$\n\\mathrm{score} =  \\mathbf w \\cdot \\mathbf x\n$$\n\n其中$\\mathbf w$为特征各维度的权重，$\\mathbf x$为doc-query match信息转化为的特征向量。\n\n在Ranking问题中我们使用的训练样本的label值不是分数，而是一个具有强弱分级的label，如`Perfect > Excellent > Good > Fair > Bad` 这样具有强弱关系的五级label。为了将score映射到分级label，需要设置5个阈值来区分score的label。如果score落在某两个相邻阈值之间，则划分为相应的label，常见算法包括：PRank、McRank。如下图所示为PRank算法示意图：\n\n![](PRank/score-rank.png)\n\n# 算法思想\n\n数据：$X_{T \\times n}$ ， $y， y \\in  {1, 2, 3, \\dots, k}$， 即训练样本量为$T$， 特征维度为n，$y$共有k个等级的取值。\n\nPRank的目标是训练一个ranking rule H : $R^n \\rightarrow y$ ，即，将样本特征投影到$k$个等级上。$H$ 定义如下：\n$$\nH(\\mathbf x)=\\min_{r \\in {1, 2, 3, \\dots, k}}\\{r: \\mathbf w \\cdot \\mathbf x - b_r < 0 \\}\n$$\n其中：$\\mathbf w$ 和 $b_r, r \\in {1, 2, 3, \\dots, k}$ 是模型参数。 $ \\mathbf w \\cdot \\mathbf x$ 就是上文中所说的score，$k$ 个 $b_r$ 就是上文所说的阈值，$b_1 \\le \\dots \\le  b_{k-1} \\le  b_k = \\infty$ 。如上文所述如果一个样本满足$b_{r-1} \\lt \\mathbf w \\cdot \\mathbf x \\le b_r$ ，则该样本的预测rank值为$r$，即，$\\hat y = H(\\mathbf x) = r$。\n\n# 模型参数估计\n\nPRank模型存在两组参数$\\mathbf w$ 和 $b_r, r \\in {1, 2, 3, \\dots, k}$ ，只要能将这两组参数确定下来，就大功告成。下面讲解参数的确定过程。PRank更新参数的方法类似于随机梯度下降法，即，每当预测错误一个样本后，就更新参数。\n\n对于一个样本$(\\mathbf x, y)$ 和模型参数$\\mathbf w$ 和 $b_r, r \\in \\{1, 2, 3, \\dots, k\\}$ 。如果模型能够正确预测，则 :\n$$\n\\begin {align}\n& \\mathbf w \\cdot \\mathbf x \\gt b_r ,  r \\le y-1 \\\\\n& \\mathbf w \\cdot \\mathbf x \\lt b_r ,  r \\ge y\n\\end {align}\n$$\n\n如上所述，$y$的取值是从集合$\\{1, 2, 3, \\dots, k\\}$ 中选取。模型引入辅助变量$s$(原文中依然使用$y$，我认为可能产生符号混淆，所以改用$s$) ， \n\n$s$是一个向量，长度为$k-1$ ， $s$ 与 $y$ 是一一对应的(类似于多分类问题中，使用onehot编码将label向量化)。对于样本 $(\\mathbf x, y)$来说，s的各维度值定义如下：\n$$\n\\begin {align}\n& s_r = +1 , r \\le y-1 \\\\\n& s_r = -1,  r \\ge y , r \\lt k\n\\end {align}\n$$\n例如当 $k=5$时，$y$的取值与$s$的关系如下：\n\n$$\n\\begin {align}\n& y=1 \\Leftrightarrow s=[-1,  -1, -1, -1] \\\\\n& y=2 \\Leftrightarrow s=[ +1, -1, -1, -1] \\\\\n& y=3 \\Leftrightarrow s=[ +1,+1, -1, -1] \\\\\n& y=4 \\Leftrightarrow s=[ +1,+1,+1, -1] \\\\\n& y=5 \\Leftrightarrow s=[ +1,+1,+1,+1]\n\\end {align}\n$$\n\n对于样本$(\\mathbf x, y)$来说， 对于所有的$r \\in \\{1, \\dots , k-1\\}$ ：\n\n1. 如果模型预测结果是正确的，则$s_r\\cdot (\\mathbf w \\cdot \\mathbf x - b_r ) \\gt 0$，此时参数不需要更新\n2. 如果模型预测结果是错误的，则**存在**$s_r\\cdot (\\mathbf w \\cdot \\mathbf x - b_r ) \\le 0$，此时需要更新参数\n\n对于特定的$r$，如果$s_r\\cdot (\\mathbf w \\cdot \\mathbf x - b_r ) \\le 0$， 则说明score值$\\mathbf w \\cdot \\mathbf x$ 落在了阈值$b_r$的**错误的一侧**，为了改正这个错误的预测，只需要将$\\mathbf w \\cdot \\mathbf x$和$b_r$**相对**移动就能完成对于参数$\\mathbf w$ 和 $b_r$ 的更新。更新公式如下：\n\n对于$s_r\\cdot (\\mathbf w \\cdot \\mathbf x - b_r ) \\le 0$：\n$$\n\\begin {align}\n& b_r = b_r - s_r \\\\\n& \\mathbf w = \\mathbf w + s_r \\cdot \\mathbf x\n\\end {align}\n$$\n当$y=4$ ，预测值落在了Rank 3 范围内时：$s_ 3= +1$ ，此时需要将$b_3$向左移动， $\\mathbf w \\cdot \\mathbf x$向右移动。\n$$\n\\begin {align}\n& b_3 = b3 - s_3  = b3 - (+1) \\\\\n& \\mathbf w = \\mathbf w + (+1) \\cdot \\mathbf x  \\Leftrightarrow \\mathbf w \\cdot \\mathbf x = \\mathbf w \\cdot \\mathbf x + (+1) \\mathbf x^2\n\\end {align}\n$$\n\n\n![](PRank/wrong-left.png)\n\n当$y=2$ ，预测值落在了Rank 3 范围内时：$s_ 2= -1$ ，此时需要将$b_2$向右移动， $\\mathbf w \\cdot \\mathbf x$向左移动。\n$$\n\\begin {align}\n& b_2 = b2 - s_2  = b3 - (-1) \\\\\n& \\mathbf w = \\mathbf w + (-1) \\cdot \\mathbf x  \\Leftrightarrow \\mathbf w \\cdot \\mathbf x = \\mathbf w \\cdot \\mathbf x + (-1) \\mathbf x^2\n\\end {align}\n$$\n![](PRank/wrong-right.png)\n\n如果有存在多个$r$ 使得$s_r\\cdot (\\mathbf w \\cdot \\mathbf x - b_r ) \\le 0$时，更新过程如下图所示：\n\n![](PRank/update-rule.png)\n\n# 实现流程\n\nPRank算法比较简单，基本流程如下所示：\n\n![](PRank/prank-algorithm.png)\n\n# 实现代码\n\n以下为PRank算法的Python实现代码\n\nnote：由于实际环境中我们使用的rate是从0开始的，如5级使用的是$\\{0, 1, 2, 3 ,4\\}$ 来做标记，所以下面的代码和上文中的论述有一点出入。\n\n```python\nimport numpy as np\n\ndef prank(X, y, rate_levels, epochs=10, delta=0.01):\n    '''\n    epochs: int, 收敛之前 遍历样本次数\n    rate_lavels: int, y中rate的级别数量，如y用 0,1,2,3 标记，则rate_lavels = 4\n    X: 训练样本feature集合\n    y: 训练样本的rate集合，需要从 0开始。如果未5级标注，需要为 0, 1, 2, 3, 4\n    delta: float, 终止迭代条件\n    '''\n    N = len(X)  # 样本量\n    D = len(X[0])  # 样本维度\n    theta = np.zeros(D)\n    b = np.zeros(rate_levels - 1)\n    s = np.zeros((N, rate_levels - 1))  # 辅助变量，类似于y的one-hot表示\n    for i in range(0, rate_levels - 1):  # 初始化b\n        b[i] = i\n    for n in range(0, N):  # 初始化 s\n        for l in range(0, rate_levels - 1):\n            if (y[n] <= l):\n                s[n][l] = -1\n            else:\n                s[n][l] = 1\n    last_err_ratio = 1.0 + delta\n    for it in range(0, epochs):\n        err_cnt = 0\n        for n in range(0, N):\n            E = np.zeros(rate_levels - 1) - 1  # 用于记录该样本\n            for l in range(0, rate_levels - 1):\n                if (s[n][l] * (np.dot(theta, X[n]) - b[l])) <= 0:\n                    E[l] = l\n            if(len(E[E >= 0]) > 0):\n                err_cnt += 1\n                sumval = 0  # 预测rate和真正rate 的间距，真正label是3，预测label是1，则sumval=3-1=2\n                for l in range(0, rate_levels - 1):  # 统计 sumval\n                    if(E[l] >= 0):\n                        sumval += s[n][int(E[l])]\n                for d in range(0, D):  # 更新theta\n                    theta[d] += sumval * X[n][d]\n                for l in range(0, rate_levels - 1):  # 更新b\n                    if(E[l] >= 0):\n                        b[int(E[l])] -= s[n][int(E[l])]\n        cur_err_ratio = err_cnt * 1.0 / N\n        print(err_cnt, N, cur_err_ratio)\n        if abs(last_err_ratio - cur_err_ratio) < delta:\n            break\n        last_err_ratio = cur_err_ratio\n    return theta, b\n```\n\nsklearn estimator版\n\n```python\nimport numpy as np\n\nfrom sklearn.base import TransformerMixin\nfrom sklearn.base import BaseEstimator\n\nclass PRank(BaseEstimator, TransformerMixin):\n\n    def __init__(self, rate_levels, epochs, delta):\n        self._rate_levels =  rate_levels\n        self._epochs = epochs\n        self._delta = delta\n\n    def _prank(self, X, y, rate_levels, epochs=10, delta=0.01):\n        '''\n        epochs: int, 收敛之前 遍历样本次数\n        rate_lavels: int, y中rate级别的数量，如y用 0,1,2,3 标记，则rate_lavels = 4\n        X: array 训练样本feature集合\n        y: list 训练样本的rate集合，需要从 0开始。如为5级标注，需要为 0, 1, 2, 3, 4\n        delta: float, 终止迭代条件\n        '''\n        N = len(X)  # 样本量\n        D = len(X[0])  # 样本维度\n        theta = np.zeros(D)\n        b = np.zeros(rate_levels - 1)\n        s = np.zeros((N, rate_levels - 1))  # 辅助变量，类似于y的one-hot表示\n        for i in range(0, rate_levels - 1):  # 初始化b\n            b[i] = i\n        for n in range(0, N):  # 初始化 s\n            for l in range(0, rate_levels - 1):\n                if (y[n] <= l):\n                    s[n][l] = -1\n                else:\n                    s[n][l] = 1\n        last_err_ratio = 1.0 + delta\n        for it in range(0, epochs):\n            err_cnt = 0\n            for n in range(0, N):\n                E = np.zeros(rate_levels - 1) - 1  # 用于记录该样本\n                for l in range(0, rate_levels - 1):\n                    if (s[n][l] * (np.dot(theta, X[n]) - b[l])) <= 0:\n                        E[l] = l\n                if(len(E[E >= 0]) > 0):\n                    err_cnt += 1\n                    sumval = 0  # 预测rate和真正rate 的间距，真正label是3，预测label是1，则sumval=3-2=1\n                    for l in range(0, rate_levels - 1):  # 统计 sumval\n                        if(E[l] >= 0):\n                            sumval += s[n][int(E[l])]\n                    for d in range(0, D):  # 更新theta\n                        theta[d] += sumval * X[n][d]\n                    for l in range(0, rate_levels - 1):  # 更新b\n                        if(E[l] >= 0):\n                            b[int(E[l])] -= s[n][int(E[l])]\n            cur_err_ratio = err_cnt * 1.0 / N\n            # print(err_cnt, N, cur_err_ratio)\n            if abs(last_err_ratio - cur_err_ratio) < delta:\n                break\n            last_err_ratio = cur_err_ratio\n        return theta, b\n\n    def fit(self, X, y):\n        self.theta_, self.b_ = self._prank(X, y, self._rate_levels, self._epochs, self._delta)\n        return self\n\n    def predict(self, X):\n        def get_rank(row):\n            rank = len(row)\n            for ind in range(len(row)):\n                if row[ind] < 0:\n                    rank = ind\n                    break\n            return rank\n        scores = np.dot(X_test_scale, pranker.theta_)[:, np.newaxis] - pranker.b_ \n        pred = np.apply_along_axis(get_rank, 1, scores)\n        return pred\n    \n    def score():\n        pass\n```\n\n\n\n# 参考资料\n\n[Pranking with Ranking](http://papers.nips.cc/paper/2023-pranking-with-ranking.pdf)","tags":["LTR"],"categories":["Model"]},{"title":"multiprocessing - Python中的并发处理","url":"%2Fblog%2Fmultiprocessing-in-Python.html","content":"\n之前写过java，C++ 等程序，接触到python后如果想写一些需要大量计算的程序，首先想到的可能会是一个多线程程序。但是……\n\n# threading模块和multiprocessing模块\n\n在python中threading模块用于处理多线程问题，但是由于Python的GIL（全局解释锁），导致python中的多线程不能利用多核CPU。通过实际coding可以发现，python中使用threading实现的多线程计算程序实际上**最多只能使用一个CPU核心** ，所以对于需要大量计算的应用来说，threading模块实际起不到什么作用。\n\n计算机程序可以分为 **计算密集型** 和 **IO密集型** 两种：\n通过以上分析可以发现，threading模块由于不能充分利用多核CPU，所以对于计算密集型的程序是没有意义的。\n但是对于IO密集型程序，threading模块却能够利用CPU的性能。如果程序中需要进行大量的网络传输或者文件读写等IO操作时，由于计算机IO的速度远没有CPU处理数据的速度快，所以必然会出现CPU等待IO完成的现象，如果在一段代码处在等待IO时执行其他待执行的代码，必然能够加快程序的执行速度并充分利用CPU。\n\n所有threading模块对于IO密集型程序有优化作用，对于计算密集型的程序基本没有什么作用。\n\n对于 **计算密集型**的程序，python使用的是multiprocessing，即多进程。下文整理python的多进程使用方法。首先认识进程对象Process。然后进程安全机制。进程池pool的使用。\n\n# Process\n\n## 初始化\n\n```python\nclass multiprocessing.Process(group=None  # 为了和Threading保持统一，此处无用\n                              ,target=None  # 目标函数\n                              ,name=None  # 该进程的名字\n                              ,args=()  # 目标函数的位置参数&元组参数\n                              ,kwargs={})  # 目标函数的字典参数\n```\n\n## 关键函数：\n\n\n> start()  # 开始执行\n> is_alive()  #\n> join([timeout])   # \n> terminate()  # 终止\n> exitcode  # 属性，表明该进程退出的状态, 状态值的含义 https://docs.python.org/2/library/signal.html\n\n## 实例：\n\n```python\nfrom multiprocessing import Process\nimport time\nimport os\n\ndef info(title):\n    process_info = u'title:' + title\n    process_info += u'|module name:' + __name__\n    if hasattr(os, u'getppid'):  # only available on Unix\n        process_info += u'|parent process:' + unicode(os.getppid())\n    process_info += u'|process id:' + unicode(os.getpid())\n    print process_info\n\ndef f(name):\n    info(u'function f')\n    time.sleep(0.5)\n    print u'hello', name\n\ninfo(u'main line')\np1 = Process(target=f, args=(u'bob',))\np1.start()\nprint u'p1 is_alive:', p1.is_alive()\np1.join()\nprint u'p1 is_alive:', p1.is_alive()\n\np2 = Process(target=f, args=(u'tom',))\np2.start()\nprint u'p2 started, p2 is_alive:', p2.is_alive()\np2.terminate()\ntime.sleep(0.1)  # 需要一段时间才能停止p2\nprint u'p2 terminated, p2 is_alive:', p2.is_alive()\nprint p2.exitcode \n================================outpupt===================================================\ntitle:main line|module name:__main__|parent process:2794|process id:2824\ntitle:function f|module name:__main__|parent process:2824|process id:3761\np1 is_alive: True\nhello bob\np1 is_alive: False\np2 started, p2 is_alive: True\np2 terminated, p2 is_alive: False\n-15\n```\n\n\n\n# 进程之间传输数据\n\n（Exchanging objects between processes）\n\n有两种进程之间通信的方式Pipes和Queues。\n\n- `Pipe()` 两个进程之间的通信\n- `queue`多生产者和多消费者之间通信。包括`Queue`, `multiprocessing.queues.SimpleQueue` 和`JoinableQueue` 三种\n\n*注意：Pipe()， 和 queue 只能用于Process之间的通信。不用用于Pool管理的进程之间的通信*\n\n## Pipe\n\n![](multiprocessing-in-Python/pipe.png)\n\n定义：\n\n```python\nPipe(duplex=True)  # 通过查看源码可以发现，Pipe实际上是一个函数\n```\n\n传输的数据对象可以使用`pickle`进行序列化时\n\n- `send(obj)` 将obj使用pickle序列化后送入pipe通道\n- `recv()`   接受`send(obj)`发送的pickle序列化数据，并解析成原始的obj对象。**如果pipe中没有数据时，该函数会阻塞其所在进程，直到接收到新的数据.**\n\n如果传输的对象不能使用`pickle`序列化，可以使用如下方法以byte进行传输：\n\n- `send_bytes(buffer[, offset[, size]])`\n\n- `recv_bytes([maxlength])`\n\n- `recv_bytes_into(buffer[, offset])`\n\n\n```python\nfrom multiprocessing import Process, Pipe\nimport time\nimport os\n\ndef client(conn):\n    i = 0\n    while i < 20:\n        print 'client', 'send',i\n        conn.send(i)\n        time.sleep(0.1)\n        i += 1\n        r = conn.recv()\n        print 'client', 'recv',r\n    conn.send(None)\n    conn.close()\n    \ndef calc(conn):\n    i = 0\n    while True:\n        r = conn.recv()\n        if r == None:\n            break        \n        print 'calc', 'recv', r\n        time.sleep(0.5)\n        conn.send(str(r) +  '*' + str(r) + '=' + str(r*r))\n    conn.close()\n\n# duplex=True 双向通信 ,\n# duplex=False 单向传输，conn1 接收端，conn2 发送端\nconn1, conn2 = Pipe(duplex=True)  \nsend_pro = Process(target=client, args=(conn2,))\nrecv_pro = Process(target=calc, args=(conn1,))\nsend_pro.start()\nrecv_pro.start()\nsend_pro.join()\nrecv_pro.join()\n```\n\n##  Queues\n\n用于进程间通信的还有队列，多进程的队列对象实际上是对`Pipe`的封装。存在如下三个队列类。\n\n```\nmultiprocessing.Queue  # 对Pipe的封装\nmultiprocessing.JoinableQueue  # 继承自Queue，增加了join() 和 task_done() 方法\nmultiprocessing.SimpleQueue  # 对Pipe的封装, 相对于Queue来说 更简单\n```\n\n### Queue\n\n使用`Queue`将数据从生产者传输到消费之的流程如下。\n\n![](multiprocessing-in-Python/queue.png)\n\n如上所述，`Queue` 实际上是对`Pipe`的封装，但是当生产者将数据放入`Queue`时，不是直接放入`Pipe`中，`Queue`使用了一个缓冲区`Buffer` 。`put`函数先将数据放入`Buffer`中，再由一个专门的`feed`线程将其放入`Pipe`当中。消费之则是直接从`Pipe`中`get`对象。\n\n定义：\n\n```\nQueue([maxsize])  # 队列同时能容纳的对象的数量\n```\n\n关键函数：\n\n- 使用标准库中的 `Queue.Empty` 和 `Queue.Full`exceptions 来判断队列是否已经满了，用在put函数中。也可以使用如下两个函数，但是不可靠。`empty()` 、`full()`\n\n\n\n- `put(obj[, block[, timeout]])`\n  将`obj`添加到`Queue`中。如果队列已满，则阻塞该进程`timeout`长时间，如果`timeout`时间以后队列还是满的，则产生异常`Queue.Full` 。`block` 默认 `True` ，`timeout` 默认无穷大(`None`)。`block` 为 `False`时，如果队列是满的直接产生异常`Queue.Full` 。\n\n\n- `put_nowait(obj) `\n\n  等价于 `put(obj, block=False)`.\n\n\n- `get([block[, timeout]])`\n  从队列中取出一个对象。如果队列是空的则阻塞该进程`timeout`长时间。如果`timeout`时间以后队列还是空的，则产生异常`Queue.Empty` 。`block` 默认 `True` ，`timeout` 默认无穷大(`None`)。`block` 为 `False`时，如果队列是空的直接产生异常`Queue.Empty` 。\n\n\n- `get_nowait()`\n\n  等价于 `get(block=False)`.\n\n由于队列中`feed`线程的存在，`Queue`使用如下三个函数来对其进程处理。（标准库中的队列没有如下三个方法）\n\n- `close()`\n  该进程不在向队列中写入数据，并调用`join_thread()`，将buffer中的数据写入`Pipe`\n  *注意：只能在生产者端使用。如果在消费者端使用，则消费之不能从队列中get数据。但是生产者仍然可以写入数据。*\n\n\n- `join_thread()`\n\n  join `feed`线程，等待buffer中的数据写入Pipe\n\n\n- `cancel_join_thread()`\n\n  假设消费者不在消费数据，则由于`join_thread()`可能带来一些死锁问题，即，Buffer的数据无法写入Pipe中。这时可以使用 `cancel_join_thread()` 来终止feed线程。注意：**此时buffer中的数据将会丢失**。\n\n\n实例：\n\n```python\nimport time\nfrom multiprocessing import Process, Queue, current_process\nfrom Queue import Empty\ndef produce(q):\n    for i in xrange(0, 20):\n        print \"process name: \" + current_process().name + ', put:' + str(i)\n        q.put(i)\n        time.sleep(0.1)\n    q.close()\n\n\ndef consum(q):\n    try_times = 0\n    while True:\n        try:\n            r = q.get(True, 1)\n            print \"process name: \" + current_process().name + ', get:' + str(r)\n        except Empty:\n            continue\n\n\nif __name__ == '__main__':\n    q = Queue(5)\n    producers = [Process(target=produce, name='p' + str(i), args=(q,)) for i in xrange(0, 3)]\n    consumers = [Process(target=consum, name='c' + str(i), args=(q,)) for i in xrange(0, 2)]\n    for c in consumers:\n        c.start()\n    for p in producers:\n        p.start()\n        p.join()\n    # 不要直接这样做，此时还不确定消费之是否已经处理完成数据。还是推荐使用JoinableQueue\n    for c in consumers:  \n        c.terminate()\n```\n\n### JoinableQueue\n\n`multiprocessing.Queue`是模仿标准库中的队列写的，但是没有`task_done()` 和 `join()` 方法。JoinableQueue继承了`multiprocessing.Queue`并实现了`task_done()` 和 `join()` 方法。\n\n`task_done()`\n由队列的消费者调用。消费则调用get()得到一个队列中的数据(任务)，处理完成这个数据以后，调用`task_done()`告诉队列该任务已经处理完毕。队列中的每一个对象都对应一个`task_done()`。\n\n`join()`\n\n阻塞调用进程，直到队列中的所有数据(任务)被消费掉。当有数据被加入队列，未完成的任务数就会增加。当消费者调用task_done()，意味着有消费者取得任务并完成任务，未完成的任务数就会减少。当未完成的任务数降到0，join()解除阻塞。\n\n实例\n\n```python\nimport time\nfrom multiprocessing import Process, JoinableQueue, current_process\nfrom Queue import Empty\n\ndef produce(q):\n    for i in xrange(0, 20):\n        print \"process name: \" + current_process().name + ', put:' + str(i)\n        q.put(i)\n        time.sleep(0.1)\n    q.close()\n\ndef consum(q):\n    try_times = 0\n    while True:\n        try:\n            r = q.get(True, 1)\n            print \"process name: \" + current_process().name + ', get:' + str(r)\n            q.task_done()  # 数据r已经处理完毕\n        except Empty:\n            continue\n\nif __name__ == '__main__':\n    q = JoinableQueue(5)\n    producers = [Process(target=produce, name='p' + str(i), args=(q,)) for i in xrange(0, 3)]\n    consumers = [Process(target=consum, name='c' + str(i), args=(q,)) for i in xrange(0, 2)]\n    for c in consumers:\n        c.start()\n    for p in producers:\n        p.start()\n        p.join()\n    q.join()\n    print 'all task finished'\n    for c in consumers:\n        c.terminate()\n```\n\n# Synchronization机制\n\n(多进程同步操作共享资源)\n\n`Lock()`\n在多进程python程序中只有一个进程执行，并阻塞其他进程。\n\n应用场景：当多个进程需要操作共享资源的时候，使用Lock来避免操作的冲突。\n\n如下面例子，10个进程同步写入文件。当一个进程进程开始写入时（即`lock.acquire()`执行后），阻塞其他进程的操作。直到该进程执行`lock.release()` 后，其他进程才能进行写入。\n\n```python\nimport multiprocessing\nimport sys\n\ndef worker_with(lock, f, i):\n    with lock:\n        fs = open(f, \"a+\")\n        fs.write('Lock acquired via with ' + str(i) + '\\n')\n        fs.close()\n\ndef worker_no_with(lock, f, i):\n    lock.acquire()\n    try:\n        fs = open(f, \"a+\")\n        fs.write('Lock acquired via with ' + str(i) + '\\n')\n        fs.close()\n    finally:\n        lock.release()\n\nif __name__ == \"__main__\":\n    f = \"file.txt\"\n    lock = multiprocessing.Lock()\n    # writers = [multiprocessing.Process(target=worker_with, args=(lock, f, i)) for i in xrange(0, 10)]\n    # for w in writers:\n        # w.start()\n        # w.join()\n    writers = [multiprocessing.Process(target=worker_no_with, args=(lock, f, i)) for i in xrange(0, 10)]\n    for w in writers:\n        w.start()\n        w.join()\n```\n\n# 进程间共享数据\n\n## 共享内存\n\n![](multiprocessing-in-Python/share-data.png)\n\n应用场景举例：比如我想使用一个多进程程序统计一个文件夹下所有文件的行数（每个进程一次统计一篇文章的行数）。如上图所示，多个进程同时读写同一个资源。\n\nPython多进程机制使用的是从内存中申请一块内存，让所有的进程能够同时读写这块内容。 `multiprocessing`提供了`multiprocessing.Value`  和`multiprocessing.Array` 来作为共享内存。\n\n`multiprocessing.Value`  和`multiprocessing.Array` 是进程安全的，所以不用使用`lock`。\n\n实例：\n\n```python\nfrom multiprocessing import Process, Value, Array\n\ndef f(n, a):\n    n.value += 1\n    print 'arr pre', arr[:]\n    for i in range(len(a)):\n        a[i] = -a[i]\n    print 'arr post', arr[:]\n\nif __name__ == '__main__':\n    num = Value('d', 0.0)\n    arr = Array('i', range(10))\n    ps = [Process(target=f, args=(num, arr)) for i in xrange(0, 10)]\n    for p in ps:\n        p.start()\n        p.join()\n    print num.value\n    print arr[:]\n```\n\n注意：上面Value和Array的定义方式。Value 和 Array 都需要设置其中存放值的类型，d 是 double 类型，i 是 int 类型，具体的对应关系在Python 标准库的 sharedctypes 模块中查看。如有需要请参考https://docs.python.org/2/library/multiprocessing.html#module-multiprocessing.sharedctypes。\n\n## 共享进程\n\n使用一个进程来管理需要在多进程中共享的数据。其他进程可以对其管理的数据进行操作。如下图所示：\n\n![](multiprocessing-in-Python/share-process)\n\n为了理解multiprocessing使用一个进程来共享数据的机制，我们需要理解如下四者的关系：\n\n> class multiprocessing.managers.BaseManager([address[, authkey]])\n>\n> Proxy \n>\n> class multiprocessing.managers.SyncManager  ：是一个已经注册了常用共享对象的 BaseManager， 是BaseManager的子类\n>\n> multiprocessing.Manager() ：是一个能够返回 已经start的 `SyncManager` 对象的函数\n\n\n\nBaseManager是用来管理共享对象的进程，通过对外开放代理 Proxy 使得其他进程在进程安全的情况下操作共享对象。\n\n`BaseManager` 关键函数:\n\n```\nclass multiprocessing.managers.BaseManager([address[, authkey]])  # address BaseManager进程运行的host的ip:port ; authkey: 密码\n```\n用于初始化 BaseManager 对象。\n该方法需要在两个地方使用：\n1. Manager的初始化，初始化之后使用 `start()` 启动 manager\n2. 当有以个进程需要方位manager管理的对象时，需要使用该函数初始化 Manager，其 address 和 authkey 需要和被访问的 manager相同。初始化后使用 `connect()` 连接\n\n```\nstart([initializer[, initargs]])\n```\nStart a subprocess to start the manager. If initializer is not None then the subprocess will call initializer(*initargs) when it starts.\n\n```\nget_server()\n```\n返回 manager 对象，manager 对象可以使用 serve_forever() 启动manager\n\n```\nconnect()\n```\n连接 manager\n\n```\nshutdown()\n```\nStop the process used by the manager. This is only available if start() has been used to start the server process.\n\n\n```\nregister(typeid[, callable[, proxytype[, exposed[, method_to_typeid[, create_method]]]]])\n```\n用于注册代理 。注册一个获取manager所管理对象的proxy。具体使用方法见例子\n\ntypeid：用户获取被管理对象的proxy\n\ncallable是一个能够返回需要管理对象的函数\n\n\n\n实例：使用一个master进程分发任务，slave进程用于处理任务并将任务返回。master和slave使用manager通信\n\n```python\nimport random, time\nfrom Queue import Queue\nfrom multiprocessing.managers import BaseManager\n\nclass Master:\n    def __init__(self):\n        # 派发出去的作业队列\n        self.dispatched_job_queue = Queue()\n        # 完成的作业队列\n        self.finished_job_queue = Queue()\n\n    def get_dispatched_job_queue(self):\n        return self.dispatched_job_queue\n\n    def get_finished_job_queue(self):\n        return self.finished_job_queue\n\n    def start(self, tasks):\n        # 把派发作业队列和完成作业队列注册到网络上\n        BaseManager.register('get_dispatched_job_queue', callable=self.get_dispatched_job_queue)\n        BaseManager.register('get_finished_job_queue', callable=self.get_finished_job_queue)\n\n        # 监听端口和启动服务\n        manager = BaseManager(address=('localhost', 58881), authkey='jobs')\n        manager.start()\n        print('manager started...')\n\n        # 使用上面注册的方法获取队列\n        dispatched_jobs = manager.get_dispatched_job_queue()  # 实际上是一个 proxy\n        print(type(dispatched_jobs))\n        finished_jobs = manager.get_finished_job_queue()\n        \n        for t in TASKS:\n            print(t)\n            dispatched_jobs.put(t)\n\n        while not dispatched_jobs.empty():\n            res = finished_jobs.get()\n            print(res)\n        dispatched_jobs.put('EXIT')\n        time.sleep(1)\n        manager.shutdown()\n        \ndef mul(a, b):\n    time.sleep(0.5*random.random())\n    return a * b\n\ndef plus(a, b):\n    time.sleep(0.5*random.random())\n    return a + b\n\nTASKS = [(mul, (i, 7)) for i in range(10)] + \\\n        [(plus, (i, 8)) for i in range(10)]\n\nif __name__ == \"__main__\":\n    master = Master()\n    master.start(TASKS)\n```\n\n\n\n```python\nimport time, random\nfrom Queue import Queue\nfrom multiprocessing.managers import BaseManager\n\nclass Slave:\n\n    def __init__(self):\n        # 派发出去的作业队列\n        self.dispatched_job_queue = Queue()\n        # 完成的作业队列\n        self.finished_job_queue = Queue()\n\n    def start(self):\n        # 把派发作业队列和完成作业队列注册到网络上\n        BaseManager.register('get_dispatched_job_queue')\n        BaseManager.register('get_finished_job_queue')\n\n        # 连接master\n        server = 'localhost'\n        print('Connect to server %s...' % server)\n        manager = BaseManager(address=(server, 58881), authkey='jobs')\n        manager.connect()\n\n        # 使用上面注册的方法获取队列\n        dispatched_jobs = manager.get_dispatched_job_queue()\n        finished_jobs = manager.get_finished_job_queue()\n\n        # 运行作业并返回结果\n        while True:\n            func_args = dispatched_jobs.get()\n            if func_args == 'EXIT':\n                break\n            func = func_args[0]\n            args = func_args[1]            \n            res = func(*args)\n            print(args, res)\n            finished_jobs.put(res)\n\n# 用于slave和master有时候是在不同 host (或进程)中完成的，所有mul 和plus需要在master和slave间共享\n# 实际应用中可以让master和slave共享 mul和plus 所在的模块的方法解决\ndef mul(a, b):\n    time.sleep(0.5*random.random())\n    return a * b\n\ndef plus(a, b):\n    time.sleep(0.5*random.random())\n    return a + b\n            \nif __name__ == \"__main__\":\n    slave = Slave()\n    slave.start()\n```\n\n\n\n# 进程池Pool\n\n## Pool\n\n定义：\n\n```python\nclass multiprocessing.Pool([processes[, initializer[, initargs[, maxtasksperchild]]]])\nprocesses:  # 同时运行的进程(worker)数量  \ninitializer:  # 每个worker初始化函数\ninitargs:  # initializer的参数\nmaxtasksperchild:  # 每个worker执行这么多task后退出。因为在Pool结束前，所有的worker都是live状态，占用资源，限制该值后，让worker退出，从而释放一定的资源，我自己测试后发现在我的机器上没有什么作用\n```\n\n关键函数：\n\n`apply_async(func[, args[, kwds[, callback]]])`\ncallback: 回调函数，当task执行结束以后，处理返回值。\n用于传递不定参数，它是 *非阻塞*的且支持结果返回后进行回调。\n\n`map(func, iterable[, chunksize])`\n是内置函数map的多进程版本，在所有的task执行完成之前会**阻塞**主进程\n\n`map_async(func, iterable[, chunksize[, callback]])`\n是map的变体，它是 *非阻塞*的。但是如果传入了callback，当子进程结果ready以后，callback会执行并阻塞主进程(func是在子进程中异步执行的)。callback是在主进程中执行的。\n\n`imap(func, iterable[, chunksize])`\nitertools.imap()的多进程版本。返回IMapIterator迭代器对象\n\n`imap_unordered(func, iterable[, chunksize])`\n和imap功能相同，但是其结果是无序的。返回IMapUnorderedIterator 迭代器对象\n\n`close()`\n执行该函数后，pool中不能再加入新的task\n\n`terminate()`\n直接终止进程池中的所有task，如果有未执行结束的task，其结果将会丢失。\n\n`join()`\n等待所有task结束，阻塞主进程。执行`join()`之前必须先执行`close()`否则会出错。\n\n## AsyncResult& MapResult\n\n```\nclass multiprocessing.pool.AsyncResult\n```\n\n`Pool.apply_async()` 返回结果保存在AsyncResult对象中，AsyncResult接收异步结果。\n\n`get([timeout])`\n获取进程执行的结果，如果结果没有available，则阻塞主线程并直到 result is available或者timeout。\n\n`wait([timeout])`\n等待进程返回结果。等待时阻塞主线程，直到 result is available或者timeout。\n\n`ready()`\n返回boolean值，表示进程是否已经返回结果\n\n`successful()`\n和read()作用相同，但是如果未ready则会产生异常\n\n\n```\nclass MapResult(ApplyResult)\n```\n\n `Pool.map_async()`返回结果保存在MapResult对象中，MapResult继承自ApplyResult对外提供get、wait、ready和successful四个方法。MapResult接收异步结果。\n\n其中`get()` 获取的是多个进程结果组成的list的对象。\n\n## IMapIterator&IMapUnorderedIterator \n\nimap,imap_unordered返回的结果对象\n\n`next([timeout])`\n\n用于迭代获取下一个result\n\n## 实例：\n\n### close() 、 terminate()、 join()的使用\n\n```python\nimport multiprocessing\nimport time\nimport random\nimport sys\n\ndef pow3(x):\n    time.sleep(0.01)\n    return x**3\nif __name__ == \"__main__\":\n  # Create pool\n  PROCESSES = 4\n  print 'Creating pool with %d processes\\n' % PROCESSES\n  pool = multiprocessing.Pool(PROCESSES)\n\n  print 'Testing close():'\n  results = [pool.apply_async(pow3, (i,)) for i in range(100)]\n  pool.close()\n  pool.join()\n  for r in results:\n      # print r.get()\n      assert r.get() is None\n  for worker in pool._pool:  # pool._pool 是进程Process的对象集合  # type(worker) == <class 'multiprocessing.process.Process'>\n      assert not worker.is_alive()\n  print '\\tclose() succeeded\\n'\n\n  print 'Testing terminate():'\n  pool = multiprocessing.Pool(2)\n  DELTA = 0.1\n  ignore = pool.apply(pow3, [2])\n  results = [pool.apply_async(time.sleep, [DELTA]) for i in range(100)]\n  pool.terminate()\n  pool.join()\n  for worker in pool._pool:\n      assert not worker.is_alive()\n  print '\\tterminate() succeeded\\n'\n```\n\n### apply_async、 map、 imap、 imap_unordered\n\n```python\nimport multiprocessing\nimport time\nimport random\nimport sys\n\n# Functions used by test code\ndef calculate(func, args):\n    result = func(*args)\n    return '%s says that %s%s = %s' % (\n        multiprocessing.current_process().name,\n        func.__name__, args, result\n        )\n\ndef calculatestar(args):\n    return calculate(*args)\n\ndef mul(a, b):\n    time.sleep(0.5*random.random())\n    return a * b\n\ndef plus(a, b):\n    time.sleep(0.5*random.random())\n    return a + b\n\nif __name__ == \"__main__\":\n    print 'cpu_count() = %d\\n' % multiprocessing.cpu_count()\n    # Create pool\n    PROCESSES = 4\n    pool = multiprocessing.Pool(PROCESSES)\n\n    # Tasks\n    TASKS = [(mul, (i, 7)) for i in range(10)] + \\\n            [(plus, (i, 8)) for i in range(10)]\n\n    results = [pool.apply_async(calculate, t) for t in TASKS]\n    print 'Ordered results using pool.apply_async():'\n    print type(results)\n    for r in results:\n        print type(r), '\\t', r.get()  # 每个结果都是 ApplyResult 对象\n    print\n    imap_it = pool.imap(calculatestar, TASKS)\n    print 'Ordered results using pool.imap():'\n    print type(imap_it)# IMapIterator 迭代器对象\n    for x in imap_it:\n        print '\\t', x\n    print\n    imap_unordered_it = pool.imap_unordered(calculatestar, TASKS)\n    print 'Unordered results using pool.imap_unordered():'\n    print type(imap_unordered_it) # IMapUnorderedIterator 迭代器对象\n    for x in imap_unordered_it:\n        print '\\t', x\n    print\n    print 'Ordered results using pool.map() --- will block till complete:'\n    map_it = pool.map(calculatestar, TASKS) \n    print type(map_it)  # 由于Map是阻塞的，所有返回结果的 list\n    for x in map_it:\n        print '\\t', x\n    print\n```\n\n### imap、 imap_unordered结果迭代器\n\n```python\nimport multiprocessing\nimport time\nimport random\nimport sys\n\n# Functions used by test code\ndef calculate(func, args):\n    result = func(*args)\n    return '%s says that %s%s = %s' % (\n        multiprocessing.current_process().name,\n        func.__name__, args, result\n        )\n\ndef calculatestar(args):\n    return calculate(*args)\n\ndef mul(a, b):\n    time.sleep(0.5*random.random())\n    return a * b\n\ndef plus(a, b):\n    time.sleep(0.5*random.random())\n    return a + b\n\nif __name__ == \"__main__\":\n    PROCESSES = 4\n    print 'Creating pool with %d processes\\n' % PROCESSES\n    pool = multiprocessing.Pool(PROCESSES)\n\n    # Tasks\n    TASKS = [(mul, (i, 7)) for i in range(10)] + \\\n            [(plus, (i, 8)) for i in range(10)]\n\n    print 'Testing IMapIterator.next() with timeout:',\n    it = pool.imap(calculatestar, TASKS)\n    while 1:\n        sys.stdout.flush()\n        try:\n            sys.stdout.write('\\n\\t%s' % it.next(0.01))\n        except StopIteration:\n            break\n        except multiprocessing.TimeoutError:\n            sys.stdout.write('.')\n\n    print 'Testing IMapUnorderedIterator.next() with timeout:',\n    it = pool.imap_unordered(calculatestar, TASKS)\n    while 1:\n        sys.stdout.flush()\n        try:\n            sys.stdout.write('\\n\\t%s' % it.next(0.01))\n        except StopIteration:\n            break\n        except multiprocessing.TimeoutError:\n            sys.stdout.write('.')\n```\n\n### 回调函数的使用\n\n```python\nimport multiprocessing\nimport time\nimport random\nimport sys\n\n# Functions used by test code\ndef mul(a, b):\n    time.sleep(0.5*random.random())\n    return a * b\n\ndef pow3(x):\n    return x**3\n\nif __name__ == \"__main__\":\n    # Create pool\n    PROCESSES = 4\n    print 'Creating pool with %d processes\\n' % PROCESSES\n    pool = multiprocessing.Pool(PROCESSES)\n    print 'pool = %s' % pool\n\n    # Testing callback\n    A = []\n    B = [56, 0, 1, 8, 27, 64, 125, 216, 343, 512, 729]\n\n    # wait\n    r = pool.apply_async(mul, (7, 8), callback=A.append) # \n    r.wait() # 使用wait等待子进程的结果ready。\n    print 'try1:', A\n    r = pool.map_async(pow3, range(10), callback=A.extend)\n    r.wait()\n    print 'map_async result', r.get()\n    print 'try2:', A\n\n    print 'no wait ========='\n    A = []\n\n    ## no wait\n    r = pool.apply_async(mul, (7, 8), callback=A.append) # \n    print 'try1:', A\n    r = pool.map_async(pow3, range(10), callback=A.extend)\n    print 'try2:', A\n    for i in xrange(5):\n        print A\n        time.sleep(1)\n```\n\n# 杂项\n\n- `multiprocessing.active_children()`\n\n  Return list of all live children of the current process.Calling this has the side effect of “joining” any processes which have already finished.\n\n\n- `multiprocessing.cpu_count()`\n\n  Return the number of CPUs in the system. May raise `NotImplementedError`.\n\n\n- `multiprocessing.current_process()`\n  Return the `Process` object corresponding to the current process.\n\n\n\n# 参考资料\n\n[multiprocessing— Process-based “threading” interface](https://docs.python.org/2/library/multiprocessing.html)\n\n使用进程共享实现机器之间通信\n\nhttps://www.cnblogs.com/sherlockhomles/p/8421075.html","tags":["Python"],"categories":["Python"]},{"title":"Performance based Confusion Matrix","url":"%2Fblog%2FPerformance-based-Confusion-Matrix.html","content":"\nROC（Receiver Operating Characteristic）曲线和AUC常被用来评价一个二值分类器（binary classifier）的优劣，对两者的简单介绍见[这里](http://bubblexc.com/y2011/148/)。这篇博文简单介绍ROC和AUC的特点，以及更为深入地，讨论如何作出ROC曲线图以及计算AUC。\n\n# ROC曲线\n\n需要提前说明的是，我们这里只讨论二值分类器。对于分类器，或者说分类算法，评价指标主要有precision，recall，F-score，以及我们今天要讨论的ROC和AUC。下图是一个ROC曲线的示例。\n\n![ROC曲线示例](Performance-based-Confusion-Matrix/Roccurves.png)\n\n正如我们在这个ROC曲线的示例图中看到的那样，ROC曲线的横坐标为false positive rate（FPR），纵坐标为true positive rate（TPR）。下图中详细说明了FPR和TPR是如何定义的。\n\n![FPR和TPR定义](Performance-based-Confusion-Matrix/fpr-and-tpr.png)\n\nROC曲线图中的四个点和一条线：\n\n- (0,1)，即FPR=0, TPR=1，这意味着FN（false negative）=0，并且FP（false positive）=0。Wow，这是一个完美的分类器，它将所有的样本都正确分类。\n- (1,0)，即FPR=1，TPR=0，类似地分析可以发现这是一个最糟糕的分类器，因为它成功避开了所有的正确答案。\n- (0,0)，即FPR=TPR=0，即FP（false positive）=TP（true positive）=0，可以发现该分类器预测所有的样本都为负样本（negative）。\n- (1,1），分类器实际上预测所有的样本都为正样本。\n\n经过以上的分析，我们可以断言，ROC曲线越接近左上角，该分类器的性能越好。\n\n- ROC曲线中虚线y=x上的点,这条对角线上的点其实表示的是一个采用随机猜测策略的分类器的结果，例如(0.5,0.5)，表示该分类器随机对于一半的样本猜测其为正样本，另外一半的样本为负样本。\n\n\n# 如何画ROC曲线\n\n对于一个特定的分类器和测试数据集，显然只能得到一个分类结果，即一组FPR和TPR结果，而要得到一个曲线，我们实际上需要一系列FPR和TPR的值，这又是如何得到的呢？我们先来看一下[Wikipedia](http://en.wikipedia.org/wiki/Receiver_operating_characteristic)上对ROC曲线的定义：\n\n> In signal detection theory, a receiver operating characteristic (ROC), or simply ROC curve, is a graphical plot which illustrates the performance of a binary classifier system as its discrimination threshold is varied.\n\n问题在于“as its discrimination threashold is varied”。如何理解这里的“discrimination threashold”呢？我们忽略了分类器的一个重要功能“概率输出”，即表示分类器认为某个样本具有多大的概率属于正样本（或负样本）。通过更深入地了解各个分类器的内部机理，我们总能想办法得到一种概率输出。通常来说，是将一个实数范围通过某个变换映射到(0,1)区间。\n\n假如我们已经得到了所有样本的概率输出（属于正样本的概率），现在的问题是如何改变“discrimination threashold”？我们根据每个测试样本属于正样本的概率值从大到小排序。下图是一个示例，图中共有20个测试样本，“Class”一栏表示每个测试样本真正的标签（p表示正样本，n表示负样本），“Score”表示每个测试样本属于正样本的概率。\n\n![按照概率排序](Performance-based-Confusion-Matrix/score-ranking.png)\n\n接下来，我们从高到低，依次将“Score”值作为阈值threshold，当测试样本属于正样本的概率大于或等于这个threshold时，我们认为它为正样本，否则为负样本。举例来说，对于图中的第4个样本，其“Score”值为0.6，那么样本1，2，3，4都被认为是正样本，因为它们的“Score”值都大于等于0.6，而其他样本则都认为是负样本。每次选取一个不同的threshold，我们就可以得到一组FPR和TPR，即ROC曲线上的一点。这样一来，我们一共得到了20组FPR和TPR的值，将它们画在ROC曲线的结果如下图：\n\n![ROC曲线举例](Performance-based-Confusion-Matrix/roc-example.png)\n\n当我们将threshold设置为1和0时，分别可以得到ROC曲线上的(0,0)和(1,1)两个点。将这些(FPR,TPR)对连接起来，就得到了ROC曲线。当threshold取值越多，ROC曲线越平滑。\n\n其实，我们并不一定要得到每个测试样本是正样本的概率值，只要得到这个分类器对该测试样本的“评分值”即可（评分值并不一定在(0,1)区间）。评分越高，表示分类器越肯定地认为这个测试样本是正样本，而且同时使用各个评分值作为threshold。我认为将评分值转化为概率更易于理解一些。\n\n# AUC值的计算\n\nAUC（Area Under Curve）被定义为ROC曲线下的面积，显然这个面积的数值不会大于1。又由于ROC曲线一般都处于y=x这条直线的上方，所以AUC的取值范围在0.5和1之间。使用AUC值作为评价标准是因为很多时候ROC曲线并不能清晰的说明哪个分类器的效果更好，而作为一个数值，对应AUC更大的分类器效果更好。\n\n在了解了ROC曲线的构造过程后，编写代码实现并不是一件困难的事情。相比自己编写代码，有时候阅读其他人的代码收获更多，当然过程也更痛苦些。在此推荐[scikit-learn](http://scikit-learn.org/stable/)中关于[计算AUC的代码](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/metrics/metrics.py#L479)。\n\n# AUC意味着什么\n\n那么AUC值的含义是什么呢？根据(Fawcett, 2006)，AUC的值的含义是： > The AUC value is equivalent to the probability that a randomly chosen positive example is ranked higher than a randomly chosen negative example.\n\n这句话有些绕，我尝试解释一下：首先AUC值是一个概率值，当你随机挑选一个正样本以及一个负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率就是AUC值。当然，AUC值越大，当前的分类算法越有可能将正样本排在负样本前面，即能够更好的分类。\n\n# 为什么使用ROC曲线\n\n既然已经这么多评价标准，为什么还要使用ROC和AUC呢？因为ROC曲线有个很好的特性： **当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变**。在实际的数据集中经常会出现类不平衡（class imbalance）现象，即负样本比正样本多很多（或者相反），而且测试数据中的正负样本的分布也可能随着时间变化。下图是ROC曲线和Precision-Recall曲线的对比：\n\n![ROC曲线 vs. Precision-Recall曲线](Performance-based-Confusion-Matrix/roc-and-precall.png)\n\n在上图中，(a)和(c)为ROC曲线，(b)和(d)为Precision-Recall曲线。(a)和(b)展示的是分类器在原始测试集（正负样本分布平衡）的结果，(c)和(d)是将测试集中负样本的数量增加到原来的10倍后，分类器的结果。可以明显的看出，ROC曲线基本保持原貌，而Precision-Recall曲线则变化较大。\n\n","tags":["Performance Analysis"],"categories":["Concepts"]},{"title":"【转】git图解","url":"%2Fblog%2Fgit-illustration.html","content":"\n 本文内容[来源](http://marklodato.github.io/visual-git-guide/index-zh-cn.html?no-svg) ，为查找方便和防止丢失，特此备份。\n\n\n\ngit分为 工作目录、暂存目录(也叫做索引)和仓库 三个部分，git命令就是围绕着三个部分进行的。\n\n## 基本用法\n\n  ![](git-illustration/basic-usage.svg.png)\n\n上面的四条命令在工作目录、暂存目录(也叫做索引)和仓库之间复制文件。\n\n*   `git add files` 把当前文件放入暂存区域。\n*   `git commit` 给暂存区域生成快照并提交。\n*   `git reset -- files` 用来将暂存区的文件恢复到最后一次commit时的状态。或者撤销未提交的 `git add` 操作。\n*   `git checkout -- files` 把文件从暂存区域复制到工作目录，用来丢弃本地修改。\n\n你可以用 `git reset -p`, `git checkout -p`, or   `git add -p`进入交互模式。\n\n也可以跳过暂存区域直接从仓库取出文件或者直接提交代码。\n\n  ![](git-illustration/basic-usage-2.svg.png)\n\n*   `git commit -a ` 相当于运行 `git add` 把所有当前目录下的文件加入暂存区域再运行 `git commit` 。\n*   `git commit files` 进行一次包含最后一次提交加上工作目录中文件快照的提交。并且文件被添加到暂存区域。\n*   `git checkout HEAD -- files` 将工作目录和暂存区都同步到仓库最后一次被提交的状态。\n\n## 约定\n\n后文中以下面的形式使用图片。\n\n  ![](git-illustration/conventions.svg.png)\n\n绿色的5位字符表示提交的ID，分别指向父节点。分支用橘色显示，分别指向特定的提交。当前分支由附在其上的`HEAD`标识。\n这张图片里显示最后5次提交，`ed489`是最新提交。 `master`分支指向此次提交，另一个`maint`分支指向祖父提交节点。\n\n## 命令详解\n\n### Diff\n\n有许多种方法查看两次提交之间的变动。下面是一些示例。\n\n```\ngit diff \ngit diff --cached\ngit diff HEAD\ngit diff maint\ngit diff b325c da985\n```\n\n  ![](git-illustration/diff.svg.png)\n\n### Commit\n\n提交时，git用暂存区域的文件创建一个新的提交，并把此时的节点设为父节点。然后把当前分支指向新的提交节点。下图中，当前分支是`master`。\n在运行命令之前，`master`指向`ed489`，提交后，`master`指向新的节点`f0cec`并以`ed489`作为父节点。\n\n  ![](git-illustration/commit-master.svg.png)\n\n即便当前分支是某次提交的祖父节点，git会同样操作。下图中，在`master`分支的祖父节点`maint`分支进行一次提交，生成了`1800b`。\n这样，`maint`分支就不再是`master`分支的祖父节点。此时，[合并](http://marklodato.github.io/visual-git-guide/index-zh-cn.html?no-svg#merge) (或者 [衍合](http://marklodato.github.io/visual-git-guide/index-zh-cn.html?no-svg#rebase)) 是必须的。\n\n  ![](git-illustration/commit-maint.svg.png)\n\n如果想更改一次提交，使用  `git commit --amend`。git会使用与当前提交相同的父节点进行一次新提交，旧的提交会被取消。\n\n  ![](git-illustration/commit-amend.svg.png)\n\n另一个例子是[分离HEAD提交](http://marklodato.github.io/visual-git-guide/index-zh-cn.html?no-svg#detached),后文讲。\n\n### Checkout\n\ncheckout命令用于从历史提交（或者暂存区域）中拷贝文件到工作目录，也可用于切换分支。\n\n当给定某个文件名（或者打开-p选项，或者文件名和-p选项同时打开）时，git会从指定的提交中拷贝文件到暂存区域和工作目录。比如，`git checkout HEAD~ foo.c`会将提交节点`HEAD~`(即当前提交节点的父节点)中的`foo.c`复制到工作目录并且加到暂存区域中。（如果命令中没有指定提交节点，则会从暂存区域中拷贝内容。）注意当前分支不会发生变化。\n\n  ![](git-illustration/checkout-files.svg.png)\n\n当不指定文件名，而是给出一个（本地）分支时，那么`HEAD`标识会移动到那个分支（也就是说，我们“切换”到那个分支了），然后暂存区域和工作目录中的内容会和`HEAD`对应的提交节点一致。新提交节点（下图中的`a47c3`）中的所有文件都会被复制（到暂存区域和工作目录中）；只存在于老的提交节点（`ed489`）中的文件会被删除；**不属于上述两者的文件会被忽略，不受影响。**\n\n  ![](git-illustration/checkout-branch.svg.png)\n\n如果既没有指定文件名，也没有指定分支名，而是一个标签、远程分支、SHA-1值或者是像_master~3_类似的东西，就得到一个匿名分支，称作`detached HEAD`（被分离的`HEAD`标识）。这样可以很方便地在历史版本之间互相切换。比如说你想要编译1.6.6.1版本的git，你可以运行`git checkout v1.6.6.1`（这是一个标签，而非分支名），编译，安装，然后切换回另一个分支，比如说`git checkout master`。然而，当提交操作涉及到“分离的HEAD”时，其行为会略有不同，详情见在[下面](http://marklodato.github.io/visual-git-guide/index-zh-cn.html?no-svg#detached)。\n\n  ![](git-illustration/checkout-detached.svg.png)\n\n### HEAD标识处于分离状态时的提交操作\n\n当`HEAD`处于分离状态（不依附于任一分支）时，提交操作可以正常进行，但是不会更新任何已命名的分支。(你可以认为这是在更新一个匿名分支。)\n\n  ![](git-illustration/commit-detached.svg.png)\n\n一旦此后你切换到别的分支，比如说`master`，那么这个提交节点（可能）再也不会被引用到，然后就会被丢弃掉了。注意这个命令之后就不会有东西引用`2eecb`。\n\n  ![](git-illustration/checkout-after-detached.svg.png)\n\n但是，如果你想保存这个状态，可以用命令`git checkout -b name`来创建一个新的分支。\n\n  ![](git-illustration/checkout-b-detached.svg.png)\n\n### Reset\n\nreset命令把当前分支指向另一个位置，并且有选择的变动工作目录和索引。也用来在从历史仓库中复制文件到索引，而不动工作目录。\n\n如果不给选项，那么当前分支指向到那个提交。如果用`--hard`选项，那么工作目录也更新，如果用`--soft`选项，那么都不变。\n\n  ![](git-illustration/reset-commit.svg.png)\n\n如果没有给出提交点的版本号，那么默认用`HEAD`。这样，分支指向不变，但是索引会回滚到最后一次提交，如果用`--hard`选项，工作目录也同样。\n\n  ![](git-illustration/reset.svg.png)\n\n如果给了文件名(或者 `-p`选项), 那么工作效果和带文件名的[checkout](http://marklodato.github.io/visual-git-guide/index-zh-cn.html?no-svg#checkout)差不多，除了索引被更新。\n\n  ![](git-illustration/reset-files.svg.png)\n\n### Merge\n\nmerge 命令把不同分支合并起来。合并前，索引必须和当前提交相同。如果另一个分支是当前提交的祖父节点，那么合并命令将什么也不做。\n  另一种情况是如果当前提交是另一个分支的祖父节点，就导致_fast-forward_合并。指向只是简单的移动，并生成一个新的提交。\n\n  ![](git-illustration/merge-ff.svg.png)\n\n否则就是一次真正的合并。默认把当前提交(`ed489` 如下所示)和另一个提交(`33104`)以及他们的共同祖父节点(`b325c`)进行一次[三方合并](http://en.wikipedia.org/wiki/Three-way_merge)。结果是先保存当前目录和索引，然后和父节点`33104`一起做一次新提交。\n\n  ![](git-illustration/merge.svg.png)\n\n### Cherry Pick\n\ncherry-pick命令\"复制\"一个提交节点并在当前分支做一次完全一样的新提交。\n\n  ![](git-illustration/cherry-pick.svg.png)\n\n### Rebase\n\n衍合是合并命令的另一种选择。合并把两个父分支合并进行一次提交，提交历史不是线性的。衍合在当前分支上重演另一个分支的历史，提交历史是线性的。\n  本质上，这是线性化的自动的 [cherry-pick](http://marklodato.github.io/visual-git-guide/index-zh-cn.html?no-svg#cherry-pick)\n\n  ![](git-illustration/rebase.svg.png)\n\n上面的命令都在`topic`分支中进行，而不是`master`分支，在`master`分支上重演，并且把分支指向新的节点。注意旧提交没有被引用，将被回收。\n\n要限制回滚范围，使用`--onto`选项。下面的命令在`master`分支上重演当前分支从`169a6`以来的最近几个提交，即`2c33a`。\n\n  ![](git-illustration/rebase-onto.svg.png)\n\n同样有`git rebase --interactive`让你更方便的完成一些复杂操作，比如丢弃、重排、修改、合并提交。没有图片体现这些，细节看这里:[git-rebase(1)](http://www.kernel.org/pub/software/scm/git/docs/git-rebase.html#_interactive_mode)\n\n\n\n\n原文链接：http://marklodato.github.io/visual-git-guide/index-zh-cn.html?no-svg","tags":["git"],"categories":["git"]},{"title":"DSSM相关论文阅读","url":"%2Fblog%2FDSSM.html","content":"\nDSSM是在2013年提出的，应用场景是IR中的Rank问题，即，给定一个query后，计算doc(url)与这个query的语义相关性。\n\n# DSSM\n\n## 模型结构\n\n先上DSSM的模型结构图\n\n![DSSM](DSSM/DSSM-model.png)\n\n可以将模型分为两步理解：\n\n1. 第一步是feature representation过程，使用DNN神经网络将文本的高维稀疏向量 投影到文本的低维语义特征向量。DNN网络接收query或者doc的term vector(如one-hot编码)，为了使one-hot编码这种高维特征能够在模型中计算，文章使用了一个小技巧(Word Hashing)将高维稀疏特征表示为低维稀疏特征 得到 $l_1$层。从$l_1$到$y$是标准的三层DNN神经网络。$y$是一个具有128维的特征的向量，它是原始的query或者doc的低维语义向量表示。\n   将query或者doc的原始Term Vector表示为$x$ ，$y$作为DNN网络的输出，$l_i$作为DNN网络的隐藏层节点值，$W_i$是DNN网络的第$i$层的权重矩阵，DNN网络的层数记为$N$。那么从$x$到$y$的前馈计算过程如下：\n\n   $$\n   \\begin {aligned}\n   l_1 &= W_1x \\\\\n   \\\\\n   l_i &=f(W_i l_{i-1}+b_i) , i =2,\\dots,N-1 \\\\\n   \\\\\n   y &=f(W_N l_{N-1}+b_N) \\\\\n   \\end {aligned}\n   $$\n\n   其中$f$为神经网络中隐藏层和输出层的激活函数，论文中使用的是$\\tanh$:\n   $$\n   f(x) = \\frac {1-e^{-2x}}{1+e^{-2x}}\n   $$\n\n2. 第二步是语义相关性的计算过程，使用第一步得到的query和doc的语义向量表示$y$计算query和doc的相关系数。论文中使用的是余弦相似度：\n   $$\n   R(Q,D)=\\cos(y_Q,y_D) = \\frac{y_Q^{\\mathrm{T}}y_D}{\\Arrowvert y_Q\\Arrowvert \\Arrowvert y_D\\Arrowvert} \n   $$\n   其中 $y_Q$ 和 $y_D$ 分别表示query和doc的语义向量表示(第一步的输出)。当给定一个query和候选doc后，就可以按照上面的方法计算其相关性得分，并按照相关性大小排序(个人感觉生产环境下不会这样干，因为生产环境中面临的情况更加多样。将DSSM的相关性得分作为最终ltr模型的输入特征还是更加可行的)。\n\n\n## 损失函数\n\n上面介绍的是DSSM模型的前馈网络结构。DSSM做为一种监督学习方法，还需要有一个损失函数作为训练的目标。\n\nDSSM模型的输入是一个query列表和每个query对应的用户点击的doc序列。论文奖给定一个query $Q$ ,用户点击一个特定doc $D$ 的概率定义为：\n$$\np(D|Q) = \\frac{\\exp(\\gamma R(Q,D))}{\\sum_{D^{'} \\in \\boldsymbol {D} } \\exp(\\gamma R(Q,D^{'} ))}\n$$\n\n其中$\\gamma$是一个softmax函数的平滑系数，是一个经验参数。\n\n注意: 分母中有一个粗体的$\\boldsymbol{D}$ 表示与$Q$对应的的所有doc的集合, 该集合包含如下内容：\n\n1. 在训练样本中与 $Q$ 相关的所有doc的集合(正例)，下文中用$D^+$表示与 $Q$ 相关的doc\n2. 在训练样本中，相对于每个 $Q$ ,还随机从数据库中选择了4个负例(与 $Q$ 不相关的doc)，下文中用 $D^-$表示 。\n\n集合 $\\boldsymbol{D}$包含与$Q$对应的所有$D^+$ 和$D^-$ ，即：\n\n$$\nD^+ \\in \\boldsymbol{D} \\\\\nD^- \\in \\boldsymbol{D}\n$$\n\n模型的目标函数就是给定$Q$时所有正例的最大似然。损失函数取其负对数：\n$$\n\\begin {aligned}\nL(\\Lambda) &= - \\log \\prod_{(Q,D^+)} p(D^+ | Q) \\\\\n                     &= - \\sum_{(Q,D^+)} log p(D^+ | Q)\n\\end {aligned}\n$$\n\n## Word Hashing\n\n由于DSSM的输入数据是 one-hot 编码，如果直接将其放入圣经网络中计算将会带来两个问题:\n\n1.  vocabulary太大，输入层的稀疏向量将会具有非常高的维度。\n2.  会出现 oov (out of vocabulary)的问题\n\nWord Hashing的设计就是为了解决以上问题的。他是基于字母级别的n-gram设计的。如单词 good：\n\n1. 在单词两端加入临界符号   #good# 。\n2. 按照n-gram将其分割为多个部分，如trigrams  将得到[#go, goo, ood, od#]四个部分。\n3. 单词good 将用[#go, goo, ood, od#] 的向量表示。\n\n这种方式可以非常有效的解决 vocabulary 太大的问题，因此英文单词才26个，3个字母的组合都是有限的)。另外也不会出现 oov 问题， 举个例子：discriminative，discriminate，discrimination 三个单词的意思很像，他们的Word Hashing中也有大部分是相同的。\n\n这样两个不同的单词也有可能具有相同的tri-grams，针对这个问题paper里面做了统计，这个冲突的概率非常的低，500K个word可以降到30k维，冲突的概率为0.0044%。\n\nWord Hashing在英文场景下很有效，但是中文场景估计就没有这样的效果了吧。\n\n\n\n# CLSM\n\nCSSM的一个重要不足是它将整个query/doc作为一个bag处理，没有考虑到term的上下文信息，文本的上下文信息丢失。如. “我爱你”和“你爱我”将会映射到同一个y(特征向量)。\n\nCLSM(Convolutional latent semantic model)于2014年提出，又称CDSSM。它是解决了CSSM的文本上下文丢失问题。在模型结构上，它将DSSM的DNN换成了CNN，这也是其名称中Convolutional 的由来。\n\n## 模型结构\n\n![](DSSM/CLSM-model.png)\n\n入上图所示，对于一个query/doc的语义向量$y$ 的训练过程可以分为如下5个步骤：\n\n(0)  预处理阶段：将句子的开头和结尾加上pading符， 上图中的`<s>`\n\n(1)  a word-n-gram layer obtained by running a contextual sliding  window  over  the  input  word  sequence  (i.e.,  a query  or  a document),\n按照固定大小(上图中是3)的滑动窗口从输入句子中提取word-n-gram层\n\n(2)  $l_t$ :a  letter-trigram  layer  that  transforms  each  word-tri-gram  into  a  letter-trigram  representation  vector,  \n将word-n-gram层的每个word用3-gram的word hashing表示(每个word可以表示为30K维的向量)，word-n-gram层($n=3$)中的每个bag可以表示成$30K \\times 3 = 90K$维度的向量\n\n(3)  $h_t$ :a convolutional layer that extracts contextual features for each word with  its neighboring words  defined by  a window\n以固定大小的窗口对letter-trigram  layer每个bag的90K维度的向量做卷积，每个bag映射到300维的向量上得到convolutional layer。卷几层的激活函数使用$tanh$\n$$\ntanh(x) = \\frac {1-e^{-2x}}{1+e^{-2x}}\n$$\n到此时为止word-n-gram layer、letter-trigram  layer和convolutional layer三层，每一层包含bag的数量是和句子的长度有关的，句子越长bag数量越多\n\n(4)  $v$ :a max-pooling layer that discovers and combines salient word-n-gram  features  to  form  a  fixed-length  sentence-level feature vector, \n$$\nv(i) = \\max_{t=1,\\dots,T} \\{h_t(i)\\} , i=1,\\dots,K\n$$\n其中$v(i)$为$v$的第$i$个维度，$T$为卷几层包含的向量的个数，K为卷积层每个向量的维度(都是一样的)，K也是$v$的维度\n\n(5)  a semantic layer that extracts  a  high-level semantic  feature  vector  for  the  input  word  sequence\n最后通过一个非线性映射得到语义向量$y$ ：\n$$\ny=\\tanh(W_s \\cdot v)\n$$\n\n## 损失函数\n\n与DSSM相同\n\n\n\n---\n\n分割线，coding工作繁忙，先写这些，回头在补！\n\n# DSSM-LSTM \n\n如上文所述，DSSM不能够很好的捕捉上下文信息，所有使用LSTM替换DSSM的DNN使其能够捕捉到文本的上下文信息。\n\n\n\n\n\n# MV-DSSM\n\n该模型主要是用于推荐系统。\n\n\n\n\n# 参考资料\n\nDSSM: [Learning Deep Structured Semantic Models for Web Search using Clickthrough Data](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/cikm2013_DSSM_fullversion.pdf)\n\nCLSM: [A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/cikm2014_cdssm_final.pdf)\n\nDSSM-LSTM:[Semantic Modelling with Long-Short-Term Memory for Information Retrieval](https://arxiv.org/pdf/1412.6629.pdf)\n\nMV-DSSM:[A Multi-View Deep Learning Approach for Cross Domain User Modeling in Recommendation Systems](http://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/frp1159-songA.pdf)","tags":["LTR"],"categories":["Neural Networks"]},{"title":"关于python中的MRO问题","url":"%2Fblog%2FMRO-in-python.html","content":"\n今天突然看到一篇文章[Python: super 没那么简单](https://mozillazg.com/2016/12/python-super-is-not-as-simple-as-you-thought.html) ，受其启发，然后查阅了一些其他文章，整理如下。\n\n# 问题的产生\n\npython是一个可以多重继承的编程语言，本文以如下多重继承的事例提出问题。\n\n```python\nclass A(object):\n    def __init__(self):\n        self.n = 2\n\n    def add(self, m):\n        print('self is {0} @A.add'.format(self))\n        self.n += m\n\n\nclass B(A):\n    def __init__(self):\n        self.n = 3\n\n    def add(self, m):\n        print('self is {0} @B.add'.format(self))\n        super(B, self).add(m)\n        self.n += 3\n\n        \nclass C(A):\n    def __init__(self):\n        self.n = 4\n\n    def add(self, m):\n        print('self is {0} @C.add'.format(self))\n        super(C, self).add(m)\n        self.n += 4\n\n\nclass D(B, C):\n    def __init__(self):\n        self.n = 5\n\n    def add(self, m):\n        print('self is {0} @D.add'.format(self))\n        super(D, self).add(m)\n        self.n += 5\n\n\nd = D()\nd.add(2)\nprint(d.n)\n```\n\n结果如下：\n\n```shell\nself is <__main__.D object at 0x10ce10e48> @D.add\nself is <__main__.D object at 0x10ce10e48> @B.add\nself is <__main__.D object at 0x10ce10e48> @C.add\nself is <__main__.D object at 0x10ce10e48> @A.add\n19\n```\n\n从子类D开始，调用顺为什么会是D->B->C->A？\n\n在B中执行了`super(C, self).add(m)`，B的父类是A，为什么却先执行了C中的add方法？\n\n带着这两个问题，我们进入正题。\n\n# MRO\n\n在正式解决这两个问题之前，先介绍一个基础知识。由于python的这种多重继承机制，多继承的语言往往会遇到以下两类二义性的问题：\n\n1. 有两个基类A和B，A和B都定义了方法f()，C继承A和B，那么调用C的f()方法时会出现不确定。\n2. 有一个基类A，定义了方法f()，B类和C类继承了A类（的f()方法），D类继承了B和C类，那么出现一个问题，D不知道应该继承B的f()方法还是C的f()方法。\n\n为了解决这种二义性问题，python使用MRO(Method Resolution Order)来处理。\n\n**MRO是一个搜索列表，如果一个类C中的方法foo()是从他的祖先类中继承来的，当我们要调用C的这个继承来方法foo()的时候，python需要按照一定的顺序遍历其祖先类来找到这个方法的具体实现。 MRO就是这么一个查找顺序的列表。按照这个顺序逐一查看各祖先类，找到的 第一个实现了的foo() 将作为C的foo()方法。**\n\n在python历史上，MRO使用过DFS(Depth-First-Search)、BFS(Breadth-First-Search)和C3算法实现。从python2.3开始都是使用C3实现的MRO。在python2.x中可以通过`D__mro__` 来拿到D的MRO列表 `(__main__.D, __main__.B, __main__.C, __main__.A, object)` 。\n\nC3算法是一种使用图论的拓扑排序方法。如下图所示，如果有如下的类继承关系，我们使用拓扑排序算法来得到类A的MRO列表。\n\n![](MRO-in-python/C3.png)\n\n1. 找入度为0的点，只有一个A，把A拿出来，加入列表；                                               -------> [A]\n2. 把A相关的边剪掉，再找下一个入度为0的点，有两个点(B, C)，取最左原则，拿B；-------> [A, B]\n3. 剪掉与B相关的边，这时候入度为0的点有E和C，取最左；                                          -------> [A, B, E]\n4. 剪掉与E相关的边，这时只有C点入度为0，取C；                                                          -------> [A, B, E, C]\n5. 剪掉与C相关的边，得到两个入度为0的点（D, F），取最左D；                                  -------> [A, B, E, C, D] \n6. 然后剪D相关的边，那么下一个入度为0的就是F，然后是object。那么最后的排序就为[A, B, E, C, D, F, object] 。\n\n# super()的作用\n\n当我们调用 `super()` 的时候，实际上是实例化了一个 `super` 类。\n\n在大多数情况下， `super` 包含了两个非常重要的信息: 一个 MRO列表以及 MRO 中的一个类。\n\n如：在上面的例子中self 指的是对象d(D的实例)，实例`super(B, self)` 可以通过`type(self).__mro__`得到MRO列表`(D, B, C, A, object)`，B指示了当前的类B在MRO列表中的位置。\n\n当在类B中调用`super(B, self).add(m)`时，Python个解释器将会按照MRO列表中从B开始向后查找含有add方法的类，即按照`C, A, object`的顺序。\n\n通过以上解释也就决了开头提出的两个问题。\n\n# 多重继承二义性举例\n\n除了显示的使用super以外，如果子类D的多个父类都实现了同一个方法add，那么调用子类D的add方法时到底调用了哪一个父类中实现的add方法呢？其实Python也是按照MRO的顺序来确定的。\n\n```python\nclass A(object):\n    def __init__(self):\n        self.n = 2\n\nclass B(A):\n    def __init__(self):\n        self.n = 3        \n        \n    def add(self):\n        print('self is {0} @B.add'.format(self))\n        self.n += 3\n        \nclass C(A):\n    def __init__(self):\n        self.n = 4\n        \n    def add(self):\n        print('self is {0} @C.add'.format(self))\n        self.n += 4\n  \n\nclass D(C, B):\n    def __init__(self):\n        self.n = 5\n        \nclass E(B, C):\n    def __init__(self):\n        self.n = 5\n\nd = D()\nd.add()\nprint d.n   #  9\n\ne = E()\ne.add()\nprint e.n  #  8\n```\n\n重新修改文章开头部分的代码，如上所示，此时，D同时继承了B和C，E同时继承了C和B。\n\n按照MRO列表，d.add()调用的是类C中定义的add方法。  (D, B, C, A, object)\n\ne.add()调用的是类B中定义的add方法。(D, C, B, A, object) \n\n\n\n# 参考资料\n\n[Python: super 没那么简单](https://mozillazg.com/2016/12/python-super-is-not-as-simple-as-you-thought.html) \n\n[你真的理解Python中MRO算法吗？](http://python.jobbole.com/85685/)","tags":["Python"],"categories":["Python"]},{"title":"将一台机器连接到github","url":"%2Fblog%2Fmachine-connect-github.html","content":"\n当我们有一台新的机器以后，希望和个人github建立ssh连接，并且和其中的某一个repo连接到一起。过程虽然简单，但是有时候也会忘掉，毕竟这个动作不是太常用。本文将这个过程记录下来，备查。\n\n1. 在新机器上生成一个ssh秘钥和公钥\n\n   ```shell\n   ssh-keygen -t rsa -C \"weirping@work-VM\"  # -t 加密算法， -C comment\n   ```\n\n2. 将生成的公钥复制到github中，这里有两中方案\n\n   - 全局：该机器可以管理github账户中的所有repo\n     在 https://github.com/settings/profile 中的 “SSH and GPG keys”中添加\n   - 单个repo: 该机器只能管理特定的repo\n     在repo的settings->Deploy keys 中添加\n\n3. 在机器上将github中的代码clone到本地\n\n   ```shell\n   git clone git@github.com:Weirping/configs-bak.git\n   ```\n\n4. 如果本地已经存在一个本地repo，github账户中是一个空repo。怎么将我本地的repo同步到线上呢？\n\n   - 本地建立repo， git init -> git add  [file] -> git commit -m \"\" \n\n   - 将本地仓库和线上仓库关联 \n\n     ```shell\n     git remote add origin git@github.com:Weirping/configs-bak.git\n     ```\n\n   - 数据同步\n\n     ```shell\n     git pull origin master # 这一步很重要，否则可能无法push\n     git push origin master \n     ```\n\n     因为他们（本地的和远程的）是两个不同的项目，pull时可能报如下错误: refusing to merge unrelated histories。\n\n     要把两个不同的项目合并，需要执行如下命令：\n\n     ```shell\n     git pull origin master --allow-unrelated-histories\n     ```\n\n     ​","tags":["git"],"categories":["git"]},{"title":"激活函数-神经网络","url":"%2Fblog%2FActivation_Function.html","content":"\n# 1 激活函数的作用\n\n- 激活函数是用来加入非线性因素的，解决线性模型所不能解决的问题。\n  神经网络之所以区别于线性模型的一点就是应为它有激活函数，如一个三层神经网络模型：\n$$\n  \\begin {aligned}\n  y_K(x, w)& = \\sigma (\\sum_{j=1}^M w_{kj}^{(2)} h(\\sum_{i=1}^D {w_{ji}^{(1)} x_i} + w_{j0}^{(1)}) + w_{k0}^{(2)}) \\\\\n  &= \\sigma (W^{(2)} h(W^{(1)}X))\n  \\end {aligned}\n$$\n  其中$h$和$\\sigma$分别是隐藏层和输出层的激活函数，如果没有这两个激活函数：\n$$\n  \\begin {aligned}\n  y_K(x, w)&= W^{(2)}W^{(1)}X \\\\\n  &=WX\n  \\end {aligned}\n$$\n  这不就是一个线性模型吗。所以相对于线性模型，激活函数使神经网络具有的更强大的表达能力。\n\n- 在一神经网络模型中：Most hidden units are distinguished from each other only by the choice of the form of the activation\n  function\n\n# 2 常见激活函数\n\n\n\n## 2.1 Sigmoid\n\n$$\n\\begin {aligned}\n\\sigma(x)& = \\frac1{1+e^x} \\\\\n\\\\\n\\sigma'(x)& = \\sigma(x) (1-\\sigma(x) )\n\\end {aligned}\n$$\n![](Activation_Function/sigmoid_func.png)\n\nsigmoid 函数将输入的实数压缩到范围[0, 1]之间。\n\n优点：\n\n1. Sigmoid函数将输入映射在(0,1)之间，单调连续，可以用作输出层。\n2. 求导容易。\n\n缺点：\n\n1. **具有饱和性(saturate)对参数$W$的初始值敏感， 反向传播过程易梯度消失**\n   - 反向传播过程：梯度消失\n     sigmoid 函数将输入的实数压缩到范围[0, 1]之间，但是在函数的两端的较大范围中，sigmoid 函数的导数接近0。在backpropagation过程中需要迭代更新参数$w_{ji}$：\n\n     $$\n     w_{ji} = w_{ji} - \\alpha \\frac{\\partial}{\\partial w_{ji}}E\n     $$\n\n     其中：\n     $$\n     \\frac{\\partial E}{\\partial w_{ji}} = \\frac{\\partial E}{\\partial a_j} \\frac{\\partial a_j}{\\partial w_{ji}} = \\delta_j z_i  = h'(a_j) \\sum_{k=1}^K w_{kj} \\delta_k z_i\n     $$\n\n     函数$h'$是激活函数$h$的梯度，如果$h$是sigmoid函数，在函数的两端的较大范围中，$h'$接近0，从而导致$\\frac{\\partial E}{\\partial w_{ji}}=0$ (kill gradients)，进而在迭代过程中$w_{ji}$得不到更新。\n\n   - 饱和性使 模型对参数$W$的初始值敏感\n     sigmoid 函数将输入的实数压缩到范围[0, 1]之间，但是在函数的两端的较大范围中，sigmoid函数的值是0或者1。一个神经元的前向传播为：\n     $$\n     f(a)=f(\\sum_i {w_i \\times x_i })\n     $$\n     在神经网络训练之前需要对参数$W$进行初始化，如果参数$W$被初始化了一个较大的值，则$a$较大，将使该神经元的输出值长时间是0或者1。\n     同时，在反向传播中有与$a$较大，使得$h'(a)=0$，也就产生了梯度消失现象。\n\n2. *Sigmoid outputs are not zero-centered*. This is undesirable since neurons in later layers of processing in a Neural Network (more on this soon) would be receiving data that is not zero-centered. This has implications on the dynamics during gradient descent, because if the data coming into a neuron is always positive (e.g. $x>0$ elementwise in $f=wTx+b$), then the gradient on the weights $w$ will during backpropagation become either all be positive, or all negative (depending on the gradient of the whole expression $f$). This could introduce undesirable zig-zagging dynamics in the gradient updates for the weights. However, notice that once these gradients are added up across a batch of data the final update for the weights can have variable signs, somewhat mitigating this issue. Therefore, this is an inconvenience but it has less severe consequences compared to the saturated activation problem above.\n\n\n## 2.2 Tanh\n\n$$\n\\begin {aligned}\n    \\tanh(x)&=\\frac{\\sinh(x)}{\\cosh(x)}=\\frac{e^x-e^{-x}}{e^x+e^{-x}} \\\\\n    \\tanh(x) &=2\\sigma(2x)-1 \\\\\n    \\tanh'(x)&= 1-\\tanh^2(x) \n    \\end {aligned}\n$$\n\n![](Activation_Function/tanh_func.png)\n\n  tanh将实数值压缩到[-1, 1]之间。和sigmoid一样，tanh具有饱和性对参数$W$的初始值敏感， 反向传播过程易梯度消失的缺点。\n\n  但是tanh是以0位中心，因此，实际应用中，tanh 会比 sigmoid 更好。\n\n## 2.3 ReLU\n\n$$\nf(x)=\\max(0, x)\n$$\n![](Activation_Function/ReLU_func.png)\n\n在设计隐藏层时，ReLU是一个比较好的选择。\n\n优点：\n\n- ReLU 得到的SGD的收敛速度会比 sigmoid/tanh 快很多\n- 相比于 sigmoid/tanh，计算简单。\n\n缺点：\n\n- 训练过程中容易存在神经元死亡现象：在某一轮反向传播过程中如果一个参数$w_{ji}$的梯度$\\frac{\\partial E}{\\partial w_{ji}}$非常大，导致更新后$w_{ji} = w_{ji} - \\alpha \\frac{\\partial}{\\partial w_{ji}}E$ ，$w$具有一个非常大的值(正值或者负值)。则激活因子 $a_j = \\sum_i w_{ji}z_i$ 可能会出负值。此下一轮的正向传播该神经元的输出值是0，反向传播该神经元所有参数$w$的梯度也是0。从而导致该神经元“dead”。\n  实际操作中，如果你的learning rate 很大，那么很有可能你网络中的40%的神经元都”dead”了。 当然，如果你设置了一个合适的较小的learning rate，这个问题发生的情况其实也不会太频繁。\n\n## 2.4 Leaky ReLU\n\n  有一些基于ReLU的泛化的激活函数，这些激活函数的效果大部分和ReLU差不多，有的会在具体的某类任务中表现好于ReLU。这些激活函数都具有如下形式：\n$$\n  f(x)=\\max(0, x) + \\alpha \\min(0, x)\n$$\n\n  当$\\alpha = -1$时，$f(x)=|x|$。称为Absolute value rectification。好像不常用。\n\n  > It is used for object recognition from images, where it makes sense to seek features that are invariant under a polarity reversal of the input illumination.\n\n将$\\alpha$值作为参数 参与神经网络模型的训练时称为parametric ReLU 或者 PReLU\n\n---\n\n当$\\alpha$取一个很小的值时，如$\\alpha = 0.01$，称为leaky ReLU:\n$$\nf(x)=\\max(0, x) +0.01 \\min(0, x)\n$$\n![](Activation_Function/leaky_ReLU_func.png)\n\n\n\n  Leaky ReLU就是用来解决ReLU的\"dead\" units问题的。这里的$\\alpha$是一个很小的常数。这样，即修正了数据分布，又保留了一些负轴的值，使得负轴信息不会全部丢失。\n\n## 2.5 Maxout\n\nmaxout是对ReLU和leaky ReLU的泛化，其公式为：\n$$\nf(x) = \\max(w_1^Tx+b_1,w_2^Tx+b_2)\n$$\nmaxout具有ReLU的所有优点：ReLU 得到的SGD的收敛速度会比 sigmoid/tanh 快很多。相比于 sigmoid/tanh，计算简单。\n\nmaxout不具有ReLU的所缺点（dying ReLU）。\n\n但是它存在两组参数，所以其参数增加为原来的两倍。\n\n\n\n# 3 激活函数的选择\n\n神经网络隐藏层的激活函数的选择是比较困难的，这个需要根绝具体的问题进行实验。\n\n- ReLU通常是一个比较好的选择，使用ReLU时要注意学习率(learning rate)的设置，如果太大容易造成节点死亡（ “dead” units）。所以在使用过程中需要监控 “dead” units在总的节点中所占的比例\n- 如果使用ReLU时“dead” units的比例较高，可以尝试Leaky ReLU 和 Maxout\n- sigmoid or tanh：在ReLU出现之前神经网络主要使用sigmoid和tanh作为激活函数，由于上面说明的原因，现在已经很少用了。\n\n\n\n其他常见激活函数[请参见](https://en.wikipedia.org/wiki/Activation_function)\n\n\n\n# 参考资料\n\nhttp://cs231n.github.io/neural-networks-1/\n\nDeep Leaning\n\nPattern Recognition and Machine Learning\n\n[神经网络之激活函数(Activation Function)](http://blog.csdn.net/memray/article/details/51442059)\n\n[Activation function wikipedia](https://en.wikipedia.org/wiki/Activation_function)","tags":["Activation Function"],"categories":["Neural Networks"]},{"title":"【转】Understanding LSTM Networks","url":"%2Fblog%2FUnderstanding-LSTM-Networks.html","content":"\n本文来自大神Olah的[blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)。 每次需要复习的时候都要重新搜索一番，所以将其原文转载到我自己的笔记中。以便于以后复习。\n\n# Recurrent Neural Networks\n\nHumans don’t start their thinking from scratch every second. As you read this essay, you understand each word based on your understanding of previous words. You don’t throw everything away and start thinking from scratch again. Your thoughts have persistence.\n\nTraditional neural networks can’t do this, and it seems like a major shortcoming. For example, imagine you want to classify what kind of event is happening at every point in a movie. It’s unclear how a traditional neural network could use its reasoning about previous events in the film to inform later ones.\n\nRecurrent neural networks address this issue. They are networks with loops in them, allowing information to persist.\n\n![Recurrent Neural Networks have loops](Understanding-LSTM-Networks/RNN-rolled.png)\n\nIn the above diagram, a chunk of neural network, $A$, looks at some input $x_t$ and outputs a value $h_t$. A loop allows information to be passed from one step of the network to the next.\n\nThese loops make recurrent neural networks seem kind of mysterious. However, if you think a bit more, it turns out that they aren’t all that different than a normal neural network. A recurrent neural network can be thought of as multiple copies of the same network, each passing a message to a successor. Consider what happens if we unroll the loop:\n\n![An unrolled recurrent neural network.](Understanding-LSTM-Networks/RNN-unrolled.png)This chain-like nature reveals that recurrent neural networks are intimately related to sequences and lists. They’re the natural architecture of neural network to use for such data.\n\nAnd they certainly are used! In the last few years, there have been incredible success applying RNNs to a variety of problems: speech recognition, language modeling, translation, image captioning… The list goes on. I’ll leave discussion of the amazing feats one can achieve with RNNs to Andrej Karpathy’s excellent blog post, [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). But they really are pretty amazing.\n\nEssential to these successes is the use of “LSTMs,” a very special kind of recurrent neural network which works, for many tasks, much much better than the standard version. Almost all exciting results based on recurrent neural networks are achieved with them. It’s these LSTMs that this essay will explore.\n\n# The Problem of Long-Term Dependencies\n\nOne of the appeals of RNNs is the idea that they might be able to connect previous information to the present task, such as using previous video frames might inform the understanding of the present frame. If RNNs could do this, they’d be extremely useful. But can they? It depends.\n\nSometimes, we only need to look at recent information to perform the present task. For example, consider a language model trying to predict the next word based on the previous ones. If we are trying to predict the last word in “the clouds are in the _sky_,” we don’t need any further context – it’s pretty obvious the next word is going to be sky. In such cases, where the gap between the relevant information and the place that it’s needed is small, RNNs can learn to use the past information.\n\n![RNN-shorttermdepdencies](Understanding-LSTM-Networks/RNN-shorttermdepdencies.png)\n\nBut there are also cases where we need more context. Consider trying to predict the last word in the text “I grew up in France… I speak fluent _French_.” Recent information suggests that the next word is probably the name of a language, but if we want to narrow down which language, we need the context of France, from further back. It’s entirely possible for the gap between the relevant information and the point where it is needed to become very large.\n\nUnfortunately, as that gap grows, RNNs become unable to learn to connect the information.\n\n![Neural networks struggle with long term dependencies.](Understanding-LSTM-Networks/RNN-longtermdependencies.png)\n\nIn theory, RNNs are absolutely capable of handling such “long-term dependencies.” A human could carefully pick parameters for them to solve toy problems of this form. Sadly, in practice, RNNs don’t seem to be able to learn them. The problem was explored in depth by [Hochreiter (1991) [German]](http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf) and [Bengio, et al. (1994)](http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf), who found some pretty fundamental reasons why it might be difficult.\n\nThankfully, LSTMs don’t have this problem!\n\n# LSTM Networks\n\nLong Short Term Memory networks – usually just called “LSTMs” – are a special kind of RNN, capable of learning long-term dependencies. They were introduced by [Hochreiter & Schmidhuber (1997)](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf), and were refined and popularized by many people in following work. They work tremendously well on a large variety of problems, and are now widely used.\n\nLSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!\n\nAll recurrent neural networks have the form of a chain of repeating modules of neural network. In standard RNNs, this repeating module will have a very simple structure, such as a single tanh layer.\n\n![The repeating module in a standard RNN contains a single layer](Understanding-LSTM-Networks/LSTM3-SimpleRNN.png)\n\nLSTMs also have this chain like structure, but the repeating module has a different structure. Instead of having a single neural network layer, there are four, interacting in a very special way.\n\n![The repeating module in an LSTM contains four interacting layers](Understanding-LSTM-Networks/LSTM3-chain.png)\n\nDon’t worry about the details of what’s going on. We’ll walk through the LSTM diagram step by step later. For now, let’s just try to get comfortable with the notation we’ll be using.\n\n![notation](Understanding-LSTM-Networks/LSTM2-notation.png)\n\nIn the above diagram, each line carries an entire vector, from the output of one node to the inputs of others. The pink circles represent pointwise operations, like vector addition, while the yellow boxes are learned neural network layers. Lines merging denote concatenation, while a line forking denote its content being copied and the copies going to different locations.\n\n## The Core Idea Behind LSTMs\n\nThe key to LSTMs is the cell state, the horizontal line running through the top of the diagram.\n\nThe cell state is kind of like a conveyor belt. It runs straight down the entire chain, with only some minor linear interactions. It’s very easy for information to just flow along it unchanged.\n\n![](Understanding-LSTM-Networks/LSTM3-C-line.png)\n\nThe LSTM does have the ability to remove or add information to the cell state, carefully regulated by structures called gates.\n\nGates are a way to optionally let information through. They are composed out of a sigmoid neural net layer and a pointwise multiplication operation.\n\n![](Understanding-LSTM-Networks/LSTM3-gate.png)\n\nThe sigmoid layer outputs numbers between zero and one, describing how much of each component should be let through. A value of zero means “let nothing through,” while a value of one means “let everything through!”\n\nAn LSTM has three of these gates, to protect and control the cell state.\n\n## Step-by-Step LSTM Walk Through\n\nThe first step in our LSTM is to decide what information we’re going to throw away from the cell state. This decision is made by a sigmoid layer called the “**forget gate layer**.” It looks at $h_{t-1}$ and $x_t$, and outputs a number between $0$ and $1$ for each number in the cell state $C_{t-1}$. A $1$ represents “completely keep this” while a $0$ represents “completely get rid of this.”\n\nLet’s go back to our example of a language model trying to predict the next word based on all the previous ones. In such a problem, the cell state might include the gender of the present subject, so that the correct pronouns can be used. When we see a new subject, we want to forget the gender of the old subject.\n\n![](Understanding-LSTM-Networks/LSTM3-focus-f.png)\n\nThe next step is to decide what new information we’re going to store in the cell state. This has two parts. First, a sigmoid layer called the “**input gate layer**” decides which values we’ll update. Next, a **tanh layer** creates a vector of new candidate values, $\\tilde{C}_t$, that could be added to the state. In the next step, we’ll combine these two to create an update to the state.\n\nIn the example of our language model, we’d want to add the gender of the new subject to the cell state, to replace the old one we’re forgetting.\n\n![](Understanding-LSTM-Networks/LSTM3-focus-i.png)\n\nIt’s now time to update the old cell state, $C_{t-1}$, into the new cell state $C_t$. The previous steps already decided what to do, we just need to actually do it.\n\nWe multiply the old state by $f_t$, forgetting the things we decided to forget earlier. Then we add $i_t*\\tilde{C}_t$. This is the new candidate values, scaled by how much we decided to update each state value.\n\nIn the case of the language model, this is where we’d actually drop the information about the old subject’s gender and add the new information, as we decided in the previous steps.\n\n![](Understanding-LSTM-Networks/LSTM3-focus-C.png)\n\nFinally, we need to decide what we’re going to output. This output will be based on our cell state, but will be a filtered version. First, we run a sigmoid layer which decides what parts of the cell state we’re going to output. Then, we put the cell state through $\\tanh$ (to push the values to be between $-1$ and $1$) and multiply it by the output of the sigmoid gate, so that we only output the parts we decided to.\n\nFor the language model example, since it just saw a subject, it might want to output information relevant to a verb, in case that’s what is coming next. For example, it might output whether the subject is singular or plural, so that we know what form a verb should be conjugated into if that’s what follows next.\n\n![](Understanding-LSTM-Networks/LSTM3-focus-o.png)\n\n# Variants on Long Short Term Memory\n\nWhat I’ve described so far is a pretty normal LSTM. But not all LSTMs are the same as the above. In fact, it seems like almost every paper involving LSTMs uses a slightly different version. The differences are minor, but it’s worth mentioning some of them.\n\n**One popular LSTM variant**, introduced by [Gers & Schmidhuber (2000)](ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf), is adding “peephole connections.” This means that we let the gate layers look at the cell state.\n\n![](Understanding-LSTM-Networks/LSTM3-var-peepholes.png)\n\nThe above diagram adds peepholes to all the gates, but many papers will give some peepholes and not others.\n\n**Another variation** is to use coupled forget and input gates. Instead of separately deciding what to forget and what we should add new information to, we make those decisions together. We only forget when we’re going to input something in its place. We only input new values to the state when we forget something older.\n\n![](Understanding-LSTM-Networks/LSTM3-var-tied.png)\n\n**A slightly more dramatic variation** on the LSTM is the **Gated Recurrent Unit**, or **GRU**, introduced by [Cho, et al. (2014)](http://arxiv.org/pdf/1406.1078v3.pdf). It combines the forget and input gates into a single “update gate.” It also merges the cell state and hidden state, and makes some other changes. The resulting model is simpler than standard LSTM models, and has been growing increasingly popular.\n\n![A gated recurrent unit neural network.](Understanding-LSTM-Networks/LSTM3-var-GRU.png)\n\nThese are only a few of the most notable LSTM variants. There are lots of others, like **Depth Gated RNNs** by [Yao, et al. (2015)](http://arxiv.org/pdf/1508.03790v2.pdf). There’s also some completely different approach to tackling long-term dependencies, like **Clockwork RNNs** by [Koutnik, et al. (2014)](http://arxiv.org/pdf/1402.3511v1.pdf).\n\nWhich of these variants is best? Do the differences matter? [Greff, et al. (2015)](http://arxiv.org/pdf/1503.04069.pdf) do a nice comparison of popular variants, finding that they’re all about the same. [Jozefowicz, et al. (2015)](http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf) tested more than ten thousand RNN architectures, finding some that worked better than LSTMs on certain tasks.\n\n# Conclusion\n\nEarlier, I mentioned the remarkable results people are achieving with RNNs. Essentially all of these are achieved using LSTMs. They really work a lot better for most tasks!\n\nWritten down as a set of equations, LSTMs look pretty intimidating. Hopefully, walking through them step by step in this essay has made them a bit more approachable.\n\nLSTMs were a big step in what we can accomplish with RNNs. It’s natural to wonder: is there another big step? A common opinion among researchers is: “Yes! There is a next step and it’s attention!” The idea is to let every step of an RNN pick information to look at from some larger collection of information. For example, if you are using an RNN to create a caption describing an image, it might pick a part of the image to look at for every word it outputs. In fact, [Xu, _et al._ (2015)](http://arxiv.org/pdf/1502.03044v2.pdf) do exactly this – it might be a fun starting point if you want to explore attention! There’s been a number of really exciting results using attention, and it seems like a lot more are around the corner…\n\nAttention isn’t the only exciting thread in RNN research. For example, Grid LSTMs by [Kalchbrenner, _et al._ (2015)](http://arxiv.org/pdf/1507.01526v1.pdf) seem extremely promising. Work using RNNs in generative models – such as [Gregor, _et al._ (2015)](http://arxiv.org/pdf/1502.04623.pdf), [Chung, _et al._ (2015)](http://arxiv.org/pdf/1506.02216v3.pdf), or [Bayer & Osendorfer (2015)](http://arxiv.org/pdf/1411.7610v3.pdf) – also seems very interesting. The last few years have been an exciting time for recurrent neural networks, and the coming ones promise to only be more so!\n\n本文转自\n\n[Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)","tags":["Model"],"categories":["Neural Networks"]},{"title":"AutoEncoder","url":"%2Fblog%2FAutoEncoder.html","content":"\n\n\n有监督的神经网络需要我们的数据是有标注（Labeled）的，然而神经网络并不止限于处理有标注的数据，同时还能处理无标注的数据，形如：${x^{(1)},x^{(2)},x^{(3)},...} 其中 \\ x^{(i)}\\in{\\mathbb{R}^n}$\n\n其中的一种算法叫做AutoEncoder——自编码网络。\n\n## 自编码网络模型\n\n*   自编码网络的结构如下图所示：  \n\n    ![AutoEncoderNN](AutoEncoder/AutoEncoderNN.png)\n\n网络中最左侧蓝色的节点是输入层，最右侧黄色的一列神经元是输出层。输出层的神经元数量完全等于输入层神经元的数量。 隐藏层的神经元数量少于输出层。\n\n自编码网络的作用是，将输入样本压缩到隐藏层，再在输出端重建样本。也就是说，自编码网络输出层与输入层存在如下关系：$\\hat{x_i} \\approx x_i $\n\n*   注意：由于神经元的输出只在0和1之间，因此**输入需要进行均值归一化**\n\n> 自编码网络可以看做将数据进行压缩（由原来的“n-维”压缩成“m维”（m=隐藏层神经元数目）），然后再在需要的时候用损失尽量小的方式将数据恢复出来。\n\n这里有两层意思:\n\n> 第一，自编码网络是要将经过压缩的数据还原，即将我们将学习一组 $h_{W,b} \\approx x$ 这是算法要学习的参数。\n\n> 第二，还原数据应该使得损失尽量小，也就规定了我们的目标函数：$J(W,b) = \\frac{1}{m} \\sum_{i=1}^m{(\\hat{x} - x)^2} $\n\n## 数据压缩原理\n\n*   压缩：限制隐藏层神经元数量 \n\n    限制隐藏层的神经元数量，就可以得到压缩的效果。例如：输入x是10*10图片的像素灰度值，即x是100维向量。输入层大小n=100。我们令隐藏层大小 s_2=50 ,那么隐藏层的输出a2是一个50维向量，网络的输出层必须使用这个50维向量来重建100维的输入。即实现了数据压缩。\n\n*   压缩原理 \n    数据压缩依靠的是数据本身是有冗余信息的。当输入是完全随机，相互独立同分布的时候，网络将很难习得一个有效的压缩模型，然而现实中的数据（自然图像、语言、声音）总是存在不同程度的冗余性。自编码网络通过学习发现并去掉了这些冗余信息。实际上，自编码网络学习出的低维数据表示十分类似于PCA（主成分分析）学习出的主成分。\n\n*   压缩：限制隐藏层的稀疏性 \n    另一种方式是限制隐藏层的稀疏性。首先定义稀疏性：\n\n> **_稀疏性---_** 神经元总是使用一个激活函数，通常使用Sigmoid或者tanh函数，它们在输入很大的时候，趋于正无穷输出接近1的数，称该神经元为“激活状态”；在输入很小，趋于负无穷的时候分别输出0和-1，称该神经元为“非激活状态”。稀疏性要求隐藏层中的激活神经元是“稀疏”的——即大部分神经元处于非激活状态。\n\n 在神经网络中，常用$ a_j^{(2)} $表示第2层第j个神经元的输出,为表示输出和某个输入相关，记为$a_j^{(2)}(x^{(i)})$  \n\n令 \n$$ \\hat{\\rho}_j = \\frac{1}{m}\\sum_{i=1}^m[a_j^{(2)}(x^{(i)})] \\quad $$\n\n为隐藏层第j个单元对所有输入样本的输出的平均值，那么根据稀疏性限制可以限制：  \n\n$ \\hat{\\rho} = \\rho$ 此处 $\\rho$ 为稀疏参数,通常用一个接近于0的常数代替(例如$\\ \\rho=0.05$)\n\n为了保证$\\rho_j$不偏离$\\rho$ ，需要设置惩罚函数。  \n$J(W,b) = \\frac{1}{m} \\sum_{i=1}^m{(\\hat{x} - x)^2} + PenalTerm$\n\n$PenalTerm = \\sum_{j=1}^{s_2}\\rho·log\\frac{\\rho}{\\rho_j}+(1-\\rho)log\\frac{1-\\rho}{1-\\rho_j}$\n\n惩罚函数以相对熵(K-L Divergence)的形式给出。\n\n> 注：K-L Divergence用于表示两个函数的差别,其定义为  \n> $ KL(f(x)||g(x))= \\sum_{x\\in X}f(x)\\cdot log \\frac{f(x)}{g(x)}$\n\n*   相对熵的性质：ρ与ρj相等时为0，随着偏差增大，相对熵增大，其图像如下图：\n    ![K-L Divergence](AutoEncoder/K-L Divergence.png)  \n\n    ## 权重\n\n    1.  在传统的AutoEncoder中我们知道，输入层到隐层有一个权重W1和bias b1，隐藏到输出层也有一个权重W2和截距项b2，此时我们也知道W1和W2的转置的型是同样大小的。但是在传统的AutoEncoder中我们对于W1和W2是**单独**训练的。\n    2.  在**tied weight**中也就是W1和W2是tied的，此时让${W_2} = W_1^T$。因为如果初始化的时候让W2的转置等于W1，那么经过一次梯度下降由于W2上的grad和W1上的不一样，所以梯度下降一次之后，他们就不一样了。所以在实际算法中${W_2} = W_1^T$是做不到的(有多重解决方法)，但是不影响算法想过。\n\n## Sparse AutoEncoder\n\n[Sparse AutoEncoder](http://ufldl.stanford.edu/wiki/index.php/Sparse_Coding:_Autoencoder_Interpretation)\n\n\n\n## Denosing AutoEncoder\n\n首先来看看Bengio论文中关于dAE的示意图，如下：\n\n![denoising_autoencoders](AutoEncoder/denoising_autoencoders.png)\n\n\n\n​\t由上图可知，样本x按照qD分布加入随机噪声后变为 ,按照文章的意思，这里并不是加入高斯噪声，而是以一定概率将输入层某些节点的值清为0，这点与dropout很类似，只不过dropout作用在隐含层。此时输入到可视层的数据变为$\\tilde x$，隐含层输出为y，然后由y重构x的输出z，注意此时这里不是重构$\\tilde x$，而是x。\n\n​\tBengio对dAE的直观解释为：\n\n1.  dAE有点类似人体的感官系统，比如人眼看物体时，如果物体某一小部分被遮住了，人依然能够将其识别出来。\n2.  多模态信息输入人体时（比如声音，图像等），少了其中某些模态的信息有时影响也不大。\n3.  普通的autoencoder的本质是学习一个相等函数，即输入和重构后的输出相等，这种相等函数的表示有个缺点就是当测试样本和训练样本不符合同一分布，即相差较大时，效果不好，明显，dAE在这方面的处理有所进步。\n\n### 基于生成模型推导Denosing AutoEncoder\n\n两条生成路径\n\n$$\nY \\to X \\to \\tilde X:p\\left( {X,\\tilde X,Y} \\right) = p\\left( Y \\right)p\\left( {X|Y} \\right)p\\left( {\\tilde X|X} \\right)\n$$\n\n$$\nX \\to \\tilde X \\to Y:q\\left( {X,\\tilde X,Y} \\right) = q\\left( X \\right)q\\left( {\\tilde X|X} \\right)q\\left( {\\tilde X|Y} \\right)\n$$\n\n注意：$Y \\to Z$ ，Z本质上是还原的X，也就是X\n\n两条路径中都有${\\tilde X}$,则两条路径得到的${\\tilde X}$的分布应该是接近的（越接近，说明Z对X的还原程度越好）\n\n两条路径中${\\tilde X}$分布的接近程度使用交叉熵定义(两个分布越相似，交叉熵越小):\n\n$$\nH\\left( {q\\left( {\\tilde X} \\right)||p\\left( {\\tilde X} \\right)} \\right) = {E_{q\\left( {\\tilde X} \\right)}}\\left[ { - \\log \\left( {p\\left( {\\tilde X} \\right)} \\right)} \\right] = H\\left( {q\\left( {\\tilde X} \\right)} \\right) + {D_{KL}}\\left( {q\\left( {\\tilde X} \\right)||p\\left( {\\tilde X} \\right)} \\right)\n$$\n\n损失函数为：\n\n$$\nL = \\mathop {\\min }\\limits_{\\theta '} \\left\\{ {H\\left( {q\\left( {\\tilde X} \\right)||p\\left( {\\tilde X} \\right)} \\right)} \\right\\} = \\mathop {\\max }\\limits_{\\theta '} \\left\\{ { - H\\left( {q\\left( {\\tilde X} \\right)||p\\left( {\\tilde X} \\right)} \\right)} \\right\\}\n$$\n\n推导得最优解为(过程见：Extracting and composing robust features with denoising autoencode 4.2 )：\n$$\n\\arg\\min_{\\theta, \\theta'} E_{q(X,\\bar X)}[L_H(X, g_{\\theta'}(f_{\\theta}(\\bar X)))]\n$$\n\n## Stacked AutoEncoder(SAE)\n\n[Stacked AutoEncoder](http://ufldl.stanford.edu/wiki/index.php/Stacked_Autoencoders)\n\n## Stacked Denosing AutoEncoder(SDAE)\n\n​\tYou provide noise to the input. It passes through the hidden layer. Output is generated and loss is calculated between the output  and the original (clean) input. You continue until convergence when the loss is minimized. Then finally you pass the full data through this network and collect the data present in the deepest hidden layer. This is your new input.（相当于原始数据在新的维度上的表示）\n\n​\tYou take this (collected) input and pass noise to it and follow the same procedure thereafter. Ultimately after you are done with the last layer, the data collected in this last hidden layer is now your new data.\n\n根据文章 *Collaborative Deep Learning for Recommender Systems (3.1节)* 可以看出 SDAE 也是Sparse的AE\n\n​\t","tags":["Model"],"categories":["Neural Networks"]},{"title":"从Lagrange multiplier到KKT条件","url":"%2Fblog%2Ffrom-Lagrange-Multiplier-to-KKT-Conditions.html","content":"\n最近看书的过程中遇到了几次需要用到KKT条件的地方，每次都要重新翻书。本文单独将这一块的知识点拉出来做一下笔记，备查。\n\n*note : 本文中的所有向量默认都是列向量*\n\n# 概述\n\nLagrange multiplier和KKT都是用来解决非线性规划问题的。非线性规划的数学模型如下：\n$$\n\\left \\{\n\\begin {aligned}\n\\min & \\  f(x) \\\\\ns.t. & \\  h_i(x) = 0 (i=1,2,\\dots ,m) \\\\\n     & \\  g_i(x) \\ge 0 (i=1,2,\\dots ,l) \\\\\n\\end {aligned}\n\\right .\n$$\n可以看出在这个问题中存在两种约束：等式约束和不等式约束 。把满足所有约束条件的点称做**可行点** ( 可行解 ) , 所有可行点的集合称做**可行域**。\n\n- 拉格朗日乘数法(Lagrange multiplier)是用于解决只含等式约束的非线性规划问题的。\n- KKT条件是用于解决包含不等式约束问题的。\n\n其中等式约束可以使用不等式约束等价表示：\n\n$$\nh_i(x) = 0 \\iff \n\\left \\{\n\\begin {aligned}\nh_i(x) \\ge 0 \\\\\n-h_i(x) \\ge 0 \\\\\n\\end {aligned}\n\\right .\n$$\n\n因而 , 也可将非线性规划的数学模型写成以下形式:\n\n$$\n\\left \\{\n\\begin {aligned}\n\\min & \\ f(x) \\\\\ns.t. & \\ g_i(x) \\ge 0 (i=1,2,\\dots ,l) \\\\\n\\end {aligned}\n\\right .\n$$\n\n# Lagrange multiplier\n\n拉格朗日算子(Lagrange multiplier)在高等数学中有比较详细的讲解，本文先简要的记录一下。拉格朗日算子是用来解决具有等式约束的极值问题的，如：\n$$\n\\left \\{\n\\begin {aligned}\n\\min & \\ f(x) \\\\\ns.t. & \\ h_i(x) = 0 (i=1,2,\\dots ,m)\\\\\n\\end {aligned}\n\\right .\n$$\n即在$m$个等式约束下寻找能够使$f(x)$最小化的$x$ 。上式也可以写成向量形式：\n$$\n\\left \\{\n\\begin {aligned}\n\\min & \\ f(x) \\\\\ns.t. & \\ H(x) = 0  \\\\\n\\end {aligned}\n\\right .\n$$\n其中：\n$$\nH(x) = \n\\begin{Bmatrix}\nh_1(x) \\\\\nh_2(x) \\\\\n\\vdots \\\\\nh_m(x) \\\\\n\\end{Bmatrix}\n=\\begin{Bmatrix}\n0 \\\\\n0 \\\\\n\\vdots \\\\\n0 \\\\\n\\end{Bmatrix}\n$$\n求解这个等式约束的最优化问题的步骤如下：\n\n第一步：构建拉格朗日函数，将求$f(x)$最小值转变为求拉格朗日函数的最小值$L(x, \\lambda)$\n$$\nL(x, \\lambda) = f(x) - \\lambda^{\\mathrm T} H(x)\n$$\n第二步：假设点$\\hat x$能够使 f(x) 在满足约束的条件下取的最小值，那么在该点处满足拉格朗日函数的 **一阶必要条件**。即，对$L(x, \\lambda)$关于$x$和$\\lambda$求偏导数，并令其为0\n$$\n\\left \\{\n\\begin {aligned}\n \\nabla_x f(\\hat x) -  J_H (\\hat x)  \\lambda = 0 \\\\\n H(\\hat x) = 0 \\\\\n \\end {aligned}\n\\right .  \\tag1\n$$\n\n其中$ J_H (x)$是等式约束的雅克比矩阵，它的每一行表示一个等式约束关于$x$的梯度。\n$$\nJ_H (x) = \n\\begin {Bmatrix}\n(\\nabla_x h_1(x))^{\\mathrm{T}} \\\\\n(\\nabla_x h_2(x))^{\\mathrm{T}} \\\\\n\\vdots \\\\\n(\\nabla_x h_m(x))^{\\mathrm{T}} \\\\\n\\end {Bmatrix}\n$$\n\n\n通过求解(1)式得到能够使$f(x)$最小化的$\\hat x$ ，和$f(x)$的最小值。\n\n**通过上式可以看出在极小值点处 $\\nabla_x f(x) =  J_H (x) \\lambda$ ，即，该点处函数$f(x)$的梯度可以用所有等式约束的梯度向量线性表示。** （这句话是为了和KKT条件问题的论述相对应。）\n\n下面以两种情况对该结论做以说明：\n\n- 如果等式约束只有一个：如\n\n$$\n\\left \\{\n\\begin {aligned}\n\\min & \\ f(x) \\\\\ns.t. & \\ h_1(x) = 0 \\\\\n\\end {aligned}\n\\right .\n$$\n\n则可以得到其拉个朗日函数的一阶条件如下：\n$$\n\\left \\{\n\\begin {aligned}\n \\nabla_x f(\\hat x) - \\lambda  \\nabla_x h_1(\\hat x) = 0 \\\\\n h_1(\\hat x) = 0 \\\\\n \\end {aligned}\n\\right .\n$$\n此时极值点处函数$f(x)$的梯度和等式约束$h_1(x)$的梯度方向相同。\n\n- 如果等式约束有两个：如\n\n$$\n\\left \\{\n\\begin {aligned}\n\\min & \\ f(x) \\\\\ns.t. & \\ h_1(x) = 0 \\\\\n     & \\ h_2(x) = 0 \\\\\n\\end {aligned}\n\\right .\n$$\n\n则可以得到其拉个朗日函数的一阶条件如下：\n$$\n\\left \\{\n\\begin {aligned} \n\\nabla_x f(\\hat x) - \\lambda_1  \\nabla_x h_1(\\hat x) - \\lambda_2  \\nabla_x h_2(\\hat x) & = 0 \\\\\n                                                                           h_1(\\hat x) & = 0 \\\\\n                                                                           h_2(\\hat x) & = 0 \\\\\n\\end {aligned}\n\\right .\n$$\n此时极值点处函数$f(x)$的梯度可以用等式约束$h_1(x)$与$h_2(x)$的梯度向量线性表示。\n\n\n\n# KKT\n\n在数学中，KKT条件是：\n\n- 一个非线性规划问题有最优化解的一个**一阶必要条件**。\n- 一个广义化拉格朗日乘数法。\n- 用于解决包含不等式约束的最优化问题。\n\n存在这样一个非线性规划问题：\n\n$$\n\\left \\{\n\\begin {aligned}\n\\min & \\ f(x) \\\\\ns.t. & \\ g_i(x) \\ge 0 (i=1,2,\\dots ,l) \\\\\n\\end {aligned}\n\\right . \\tag 2\n$$\n\n假定$\\hat x$是非线性规划的极小点，该点可能位于可行域的内部，也可能处于可行域的边界上。\n\n若为前者，这事实上是个无约束优化问题, 最优点 $\\hat x$必满足条件 $\\nabla_x f(\\hat x) = 0$ ；\n\n若为后者，情况就复杂得多了，现在我们来讨论后一种情形。\n\n![KKT](from-Lagrange-Multiplier-to-KKT-Conditions/KKT.png)\n\n设最优点为$\\hat x$。我们先讨论两个比较简单的特殊情况：$\\hat x$落在一个不等式约束的边界上；$\\hat x$处在两个不等式约束的共同作用下。\n\n1. 当$\\hat x$落在一个不等式约束的边界上，即$\\hat x$只处在一个不等式约束的作用下，假设这个不等式约束就是$g_1(x) \\ge 0$ ，此时最优点$\\hat x$必定落在函数$g_1(x) = 0$ 上。此时可以将问题转化为等式约束的非线性优化问题。\n\n$$\n  \\left \\{\n  \\begin {aligned}\n  \\min & \\ f(x) \\\\\n  s.t. & \\ g_1(x) = 0 \\\\\n  \\end {aligned}\n  \\right .\n$$\n\n  则可以得到其拉个朗日函数的 **一阶必要条件** 如下：\n$$\n\\left \\{\n\\begin {aligned}\n\\nabla_x f(\\hat x) - \\lambda_1  \\nabla_x g_1(\\hat x) & = 0 \\\\\n                                            g_1(\\hat x) & = 0 \\\\\n\\end {aligned}\n\\right .\n$$\n  如右图所示，虚线为$f(x)$的等值线，实线为约束函数$g_1(x)=0$ ，可行域在约束函数右侧。由于最优点$\\hat x$在可行域的边界上，此时在点$\\hat x$处没有可行下降方向，所以$\\nabla_x g_1(\\hat x)$必与$- \\nabla_x f(\\hat x)$在一条直线上且方向相反。结合上式可知此时 $\\lambda_1 \\ge 0$ ，所以：\n$$\n\\left \\{\n  \\begin {aligned}\n   \\nabla_x f(\\hat x) - \\lambda_1  \\nabla_x g_1(\\hat x) & = 0 \\\\\n                                            g_1(\\hat x) & = 0 \\\\\n                                              \\lambda_1 & \\ge 0 \\\\\n   \\end {aligned}\n  \\right .\n$$\n\n2. 若$\\hat x$点有两个起作用约束 ，例如有 $g_1 (\\hat x) = 0$ 和 $g_2 (\\hat x) = 0$。此时可以将问题转化为等式约束的非线性优化问题。\n\n$$\n  \\left \\{\n  \\begin {aligned}\n  \\min & \\ f(x) \\\\\n  s.t. & \\ g_1(x) = 0 \\\\\n       & \\ g_2(x) = 0 \\\\\n  \\end {aligned}\n  \\right .\n$$\n\n  则可以得到其拉个朗日函数的一阶条件如下：\n$$\n  \\left \\{\n  \\begin {aligned} \n   \\nabla_x f(\\hat x) - \\lambda_1  \\nabla_x h_1(\\hat x) - \\lambda_2  \\nabla_x h_2(\\hat x) & = 0 \\\\\n                                                                              g_1(\\hat x) & = 0 \\\\\n                                                                              g_2(\\hat x) & = 0 \\\\\n  \\end {aligned}\n  \\right .\n$$\n  如左图所示，虚线为$f(x)$的等值线，实线为约束函数$g_1(x)=0$ 和$g_2(x)=0$，可行域在约束函数右侧。由于最优点$\\hat x$在由$g_1(x)=0$ 和$g_2(x)=0$共同围成的边界上，所以$- \\nabla_x f(\\hat x)$与$\\nabla_x g_1(\\hat x)$的夹角必定大约90度，也就是说$\\nabla_x f(\\hat x)$必定处在$\\nabla_x g_1(\\hat x)$与$\\nabla_x g_2(\\hat x)$组成的夹角之内。结合上式可知此时 $\\lambda_1 \\ge 0 ,  \\lambda_1 \\ge 0$ ，所以：\n$$\n  \\left \\{\n  \\begin {aligned} \n  \\nabla_x f(\\hat x) - \\lambda_1  \\nabla_x h_1(\\hat x) - \\lambda_2  \\nabla_x h_2(\\hat x) & = 0 \\\\\n                                                                             g_1(\\hat x) & = 0 \\\\\n                                                                             g_2(\\hat x) & = 0 \\\\\n                                                            \\lambda_1 \\ge 0 ,  \\lambda_2 & \\ge 0 \\\\\n  \\end {aligned}\n  \\right .\n$$\n\n3. 若$\\hat x$点有K个起作用约束($0 \\le K \\le l$) ，此时\n\n   $$\n   \\left \\{\n   \\begin {aligned}\n    \\nabla_x f(\\hat x) - \\sum_k^K \\lambda_k  \\nabla_x g_k(\\hat x) &= 0 \\\\\n    g_k(\\hat x) &= 0, (k = 1,2 \\dots K)\\\\\n    \\lambda_k & \\ge 0, (k = 1,2 \\dots K)\\\\\n    \\end {aligned}\n   \\right .\n   $$\n\n\n\n\n以上条件只是针对最优点$\\hat x$处于可行域的边界上论述的，还有一种情况就是最优点处在可行域内部。将两种情况（最优点处在可行域内部和边界上）合并起来表示如下：\n$$\n\\left \\{\\begin {aligned} \\nabla_x f(\\hat x) - \\sum_i^l \\lambda_i  \\nabla_x g_i(\\hat x) &= 0 \\\\\ng_i(\\hat x) &\\ge 0, (i = 1,2 \\dots l) \\\\\n\\lambda_i g_i(\\hat x) &= 0, (i = 1,2 \\dots l)  \\\\\n\\lambda_i & \\ge 0, (i = 1,2 \\dots l) \\\\ \n\\end {aligned}\\right .\n$$\n可以看出当 $g_i(\\hat x) = 0$ 时，它可能是对于最优点$\\hat x$起作用的约束 ， $\\lambda_i$可以不为零；当$g_i(\\hat x) \\ne 0$ 时，即$g_i(\\hat x) \\gt 0$ ，此时它一定不是对最优点$\\hat x$起作用的约束，此时必有$\\lambda_i = 0$ 。\n\n现可将库恩 - 塔克条件叙述如下 :设 $\\hat x$ 是非线性规划式(2)的极小点 , 而且在 $\\hat x$ 点的各起作用约束的梯度线性无关，则存在向量 $\\Lambda = (\\lambda_1 ,\\lambda_2, \\dots, \\lambda_l)$ ， 使下述条件成立 :\n$$\n\\left \\{\n\\begin {aligned}\n\\nabla_x f(\\hat x) - \\sum_i^l \\lambda_i  \\nabla_x g_i(\\hat x) &= 0 \\\\\ng_i(\\hat x) &\\ge 0, (i = 1,2 \\dots l) \\\\\n\\lambda_i g_i(\\hat x) &= 0, (i = 1,2 \\dots l) \\\\\n\\lambda_i & \\ge 0, (i = 1,2 \\dots l) \\\\\n\\end {aligned}\n\\right .\n$$\n\n库恩-塔克条件是非线性规划领域中最重要的理论成果之一，是确定某点为最优点的**必要条件**。但一般来说它并不是充分条件，因而满足这个条件的点不一定就是最优点。\n\n**对于凸规划问题，KKT条件既是最优点存在的必要条件，同时也是充分条件。**\n\n# KKT条件总结\n\n如本开头部分所述，含有不等式约束的非线性优化问题可以有多种表述，本节直接列出各种该表述的和其对饮高的KKT条件。\n$$\n\\left \\{\n\\begin {aligned}\n      & \\min f(x) \\\\\ns.t. & g_i(x) \\ge 0 (i=1,2,\\dots ,l) \\\\\n\\end {aligned}\n\\right . \n\\Rightarrow\n\\left \\{\n\\begin {aligned}\n\\nabla_x f(\\hat x) - \\sum_i^l \\lambda_i  \\nabla_x g_i(\\hat x) &= 0 \\\\\n                                                                                     g_i(\\hat x) &\\ge 0, (i = 1,2 \\dots l)  \\\\\n                                                                  \\lambda_i g_i(\\hat x) &= 0, (i = 1,2 \\dots l) \\\\\n                                                                                    \\lambda_i & \\ge 0, (i = 1,2 \\dots l) \\\\\n\\end {aligned}\n\\right .\n$$\n\n$$\n\\left \\{\n\\begin {aligned}\n      & \\min f(x) \\\\\ns.t. & g_i(x) \\le 0 (i=1,2,\\dots ,l) \\\\\n\\end {aligned}\n\\right . \n\\Rightarrow\n\\left \\{\n\\begin {aligned}\n \\nabla_x f(\\hat x) + \\sum_i^l \\lambda_i  \\nabla_x g_i(\\hat x) &= 0 \\\\\n                                                                                      g_i(\\hat x) &\\le 0, (i = 1,2 \\dots l) \\\\\n                                                                    \\lambda_i g_i(\\hat x) &= 0, (i = 1,2 \\dots l) \\\\\n                                                                                      \\lambda_i & \\ge 0, (i = 1,2 \\dots l) \\\\\n \\end {aligned}\n\\right .\n$$\n\n$$\n\\left \\{\n\\begin {aligned}\n      & \\min f(x) \\\\\ns.t. & h_j(x) = 0 (j=1,2,\\dots ,m) \\\\\n      & g_i(x) \\ge 0 (i=1,2,\\dots ,l) \\\\\n\\end {aligned}\n\\right .\n\\Rightarrow\n\\left \\{\n\\begin {aligned}\n \\nabla_x f(\\hat x) - \\sum_j^m \\gamma_j \\nabla_x h_j(\\hat x) - \\sum_i^l \\lambda_i  \\nabla_x g_i(\\hat x) &= 0 \\\\\n                                                                                                                                                                h_j(\\hat x) &= 0 (j=1,2,\\dots ,m) \\\\\n                                                                                                                                                                g_i(\\hat x) &\\ge 0, (i = 1,2 \\dots l) \\\\\n                                                                                                                                             \\lambda_i g_i(\\hat x) &= 0, (i = 1,2 \\dots l) \\\\\n                                                                                                                                                               \\lambda_i & \\ge 0, (i = 1,2 \\dots l) \\\\\n \\end {aligned}\n\\right .\n$$\n\n$$\n\\left \\{\n\\begin {aligned}\n      & \\min f(x) \\\\\ns.t. & h_j(x) = 0 (j=1,2,\\dots ,m) \\\\\n      & g_i(x) \\le 0 (i=1,2,\\dots ,l) \\\\\n\\end {aligned}\n\\right .\n\\Rightarrow\n\\left \\{\n\\begin {aligned}\n \\nabla_x f(\\hat x) + \\sum_j^m \\gamma_j \\nabla_x h_j(\\hat x) + \\sum_i^l \\lambda_i  \\nabla_x g_i(\\hat x) &= 0 \\\\\n                                                                                                                                                                  h_j(\\hat x) &= 0 (j=1,2,\\dots ,m) \\\\\n                                                                                                                                                                  g_i(\\hat x) &\\le 0, (i = 1,2 \\dots l) \\\\\n                                                                                                                                               \\lambda_i g_i(\\hat x) &= 0, (i = 1,2 \\dots l) \\\\\n                                                                                                                                                                 \\lambda_i & \\ge 0, (i = 1,2 \\dots l) \\\\\n \\end {aligned}\n\\right .\n$$\n\n先列出这四种表述。\n\n# 参考资料\n\n运筹学-第三版\n","tags":["Optimization"],"categories":["Mathematics"]},{"title":"范数正则化","url":"%2Fblog%2FNorm-Regularization.html","content":"\n# 0 概述\n\n机器学习的中心问题是在训练集上训练出一个能够在新的输入数据上表现良好的模型。现有的很多策略是在牺牲训练误差来减小泛化误差，这些策略被统称为正则化。\n\n和传统的机器学习算法一样，神经网络的范数正则化方法也是通过限制模型参数来减少过拟合的。但是神经网络的范数正则化也有自己的特点，为了论述方便本文将神经网络的参数分为两类：\n\n- $\\boldsymbol w$ ：仿射变换权重参数，模型向量两层神经元的相互作用的参数，不包含偏执(bias)；\n- $\\boldsymbol \\beta$ ：偏执参数；\n- $\\boldsymbol \\theta$ ：包含仿射变换权重参数$w$和偏执参数(bias)。\n\n在深度学习中，正则化只针对仿射变换权重参数$\\boldsymbol w$，而每一层的偏执参数不做正则化处理。这是因为：\n\n- 每个偏置仅控制一个单变量(权重参数控制两个变量)，这意味着，我们不对其进行正则化也不会导致太大的偏差\n- 偏置参数的正则化可能会导致明显的欠拟合。\n\n正则化之前的目标函数记为 $J(\\boldsymbol \\theta, \\boldsymbol X, y)$ ，正则化后的目标函数记为$\\tilde J(\\boldsymbol \\theta, \\boldsymbol X, y)$ ，则:\n\n$$\n\\tilde{J}(\\boldsymbol \\theta,\\boldsymbol  X, y) = J(\\boldsymbol \\theta, \\boldsymbol X, y) + \\alpha \\Omega(\\boldsymbol \\theta)\n$$\n\n\n其中$\\Omega$是正则化项，$\\alpha \\ge 0$ 是超参，$\\alpha$越大，正则化力度越大。机器学习中常用的正则化项是p-范数 ($L^p$)：$||\\boldsymbol x||_p=(\\sum_i |x_i|^p)^{\\frac1p}, p \\ge 1$\n\n- $p=2$时，$L^2$ 称为2范数，欧几里得范数， $||\\boldsymbol x||_2=(\\sum_i |x_i|^2)^{\\frac12}$ 。实际应用当中，常用的是它的平方， $||\\boldsymbol x||_2^2=\\sum_i |x_i|^2 = \\boldsymbol x^{\\mathrm{T}} \\boldsymbol x$ 。\n- $p=1$时，$L^1$ 称为1范数，$||\\boldsymbol x||_1=\\sum_i |x_i|$ 。当区分元素 恰好是零 和 非零(但值可能很小) 对于模型很重要的时候使用这种范数。\n- $p=\\infty$时，$L^\\infty$ 称为最大范数，$||\\boldsymbol x ||_ \\infty=\\max_i|x_i|$ 。\n- “$L^0$范数”表示向量中非零元素的个数，但是这个术语在数学意义上是不对的。\n\n\n# 1 $L^2$范数正则化\n\n$L^2$范数正则化将目标函数$\\tilde J$中正则化项定义为参数的2范数的平方，$\\Omega(\\boldsymbol \\theta) = \\frac 12 ||\\boldsymbol w||_2^2 = \\frac 12 \\boldsymbol w ^ {\\mathrm{T}} \\boldsymbol w$ 。\n\n下面从三个角度理解$L^2$范数正则化：\n\n1. **从梯度下降的角度**\n\n目标函数求关于$w$的梯度，最终求的$w$的梯度下降法更新公式过程如下：\n\n$$\n\\begin {aligned}\n& \\tilde{J}(\\boldsymbol w ,\\boldsymbol \\beta,\\boldsymbol  X, y) = J(\\boldsymbol w ,\\boldsymbol \\beta, \\boldsymbol X, y) +   \\frac \\alpha2 \\boldsymbol w ^ {\\mathrm{T}} \\boldsymbol w \\\\\n\\\\\n& \\nabla_w \\tilde{J}(\\boldsymbol w ,\\boldsymbol \\beta,\\boldsymbol  X, y) = \\nabla_w {J}(\\boldsymbol w ,\\boldsymbol \\beta,\\boldsymbol  X, y)  + \\alpha \\boldsymbol  w \\\\\n\\\\\n& w  \\gets w - \\epsilon(\\nabla_w {J}(\\boldsymbol w ,\\boldsymbol \\beta,\\boldsymbol  X, y) + \\alpha  w) \\\\\n\\\\\n&  w  \\gets (1-\\epsilon\\alpha) w - \\epsilon \\nabla_w {J}(\\boldsymbol w ,\\boldsymbol \\beta,\\boldsymbol  X, y)\n\\end {aligned}\n$$\n\n其中$\\epsilon$为学习率。目标函数 ${J}(\\boldsymbol w ,\\boldsymbol \\beta,\\boldsymbol  X, y)$ 不加正则化时的梯度下降更新公式为：\n\n$$\nw  \\gets   w - \\epsilon \\nabla_w {J}(\\boldsymbol w ,\\boldsymbol \\beta,\\boldsymbol  X, y)\n$$\n\n通过以上两个公式的对比可以看出，在梯度下降的每一步中，$L^2$范数正则化先将$w$乘以一个常数因子$(1-\\epsilon\\alpha) $ ($w$的缩放)，然后执行非正则化的梯度下降。\n\n2. **从模型训练的整体角度(解析解的推导)**\n\n假设非正则化的目标函数 ${J}(\\boldsymbol w ,\\boldsymbol \\beta,\\boldsymbol  X, y)$ 在 $\\boldsymbol {\\hat w}$ 处取得最小值，即：\n\n$$\n\\boldsymbol {\\hat w} = \\arg\\min_w {J}(\\boldsymbol w ,\\boldsymbol \\beta,\\boldsymbol  X, y)\n$$\n\n**为了简化分析，我们将目标函数近似为其在$\\hat w$处的二阶泰勒展开。** （当目标函数正好为$w$的二次函数时 $\\hat J = J$）\n\n对${J}(\\boldsymbol w ,\\boldsymbol \\beta,\\boldsymbol  X, y)$ 在 $\\boldsymbol {\\hat w}$ 处做二阶泰勒近似并使用$L^2$范数正则化，记为$\\hat J(\\boldsymbol \\theta)$ :\n$$\n\\begin {aligned}\n& \\hat J(\\boldsymbol \\theta) = J(\\boldsymbol {\\hat w}) +\\frac12(\\boldsymbol {w} - \\boldsymbol {\\hat w})^{\\mathrm{T}}\\boldsymbol H(\\boldsymbol {w} - \\boldsymbol {\\hat w}) +   \\frac \\alpha2 \\boldsymbol w ^ {\\mathrm{T}} \\boldsymbol w \\\\\n& \\nabla_w \\hat J(\\boldsymbol \\theta) = \\boldsymbol H(\\boldsymbol {w} - \\boldsymbol {\\hat w})  + \\alpha \\boldsymbol w\n\\end {aligned}\n$$\n\n其中$\\boldsymbol H$ 是目标函数 ${J}(\\boldsymbol w ,\\boldsymbol \\beta,\\boldsymbol  X, y)$ 在$\\boldsymbol {\\hat w}$ 处的Hessian matrix。$ \\frac \\alpha2 \\boldsymbol w ^ {\\mathrm{T}} \\boldsymbol w$ 为正则化项。\n\n注意：因为$\\boldsymbol {\\hat w} = \\arg\\min_w {J}(\\boldsymbol w ,\\boldsymbol \\beta,\\boldsymbol  X, y)$ \n\n- 该式中没有一阶项。$\\nabla J(\\boldsymbol {\\hat w}) = 0$ 。\n- $\\boldsymbol H$ 是半正定矩阵。\n\n令$\\tilde {\\boldsymbol w} = \\arg\\min_w \\hat J(\\boldsymbol \\theta)$ ，即在$\\tilde {\\boldsymbol w}$处$\\hat J(\\boldsymbol \\theta)$取最小值。此时：\n\n$$\n\\begin {aligned}\n& \\boldsymbol H(\\tilde {\\boldsymbol {w}} - \\boldsymbol {\\hat w}) + \\alpha \\tilde {\\boldsymbol {w}}  =  0 \\\\\n& \\tilde {\\boldsymbol {w}}  = (\\boldsymbol H + \\alpha \\boldsymbol I)^{-1} \\boldsymbol H  \\boldsymbol {\\hat w}\n\\end {aligned}\n$$\n\n当$\\alpha \\to 0$ 时，$\\tilde{\\boldsymbol {w}} \\to \\boldsymbol {\\hat w}$ 。因为$\\boldsymbol H$ 是实对称矩阵，所以它可以分解为三个矩阵：\n\n$$\n\\boldsymbol {H} = \\boldsymbol {Q} \\boldsymbol {\\Lambda} \\boldsymbol {Q }^{\\mathrm T}\n$$\n\n$\\boldsymbol {\\Lambda}$ 为$\\boldsymbol H$的特征值组成的对角阵， $\\boldsymbol {Q}$为$\\boldsymbol H$的特征向量组成的标准正交阵(此时$\\boldsymbol {Q}^{-1} = \\boldsymbol {Q} ^ {\\mathrm {T}}$)。所以可以表示为：\n\n$$\n\\begin {aligned}\n\\tilde {\\boldsymbol {w}}  &= (\\boldsymbol H + \\alpha \\boldsymbol I)^{-1} \\boldsymbol H  \\boldsymbol {\\hat w} \\\\\n                                             &= (\\boldsymbol {Q} \\boldsymbol {\\Lambda} \\boldsymbol {Q }^{\\mathrm T} + \\alpha \\boldsymbol I)^{-1} \\boldsymbol {Q} \\boldsymbol {\\Lambda} \\boldsymbol {Q }^{\\mathrm T}  \\boldsymbol {\\hat w} \\\\\n                                             &=\\boldsymbol {Q} (\\boldsymbol {\\Lambda} + \\alpha \\boldsymbol I)^{-1}\\boldsymbol {\\Lambda} \\boldsymbol {Q }^{\\mathrm T}\\boldsymbol {\\hat w}\\\\\n\\end {aligned}\n$$\n\n$L^2$范数正则化的效果是沿着由$\\boldsymbol H$的特征向量所定义的轴缩放$\\boldsymbol {\\hat w}$ ，即将与$\\boldsymbol H$的第$i$个特征向量 对齐的$\\boldsymbol {\\hat w}$的分量 乘以$\\frac {\\lambda_i}{\\lambda_i + \\alpha}$得到正则化后的$\\tilde {\\boldsymbol {w}}$的第$i$个分量。当$\\lambda_i \\gg \\alpha$ 时，$\\frac {\\lambda_i}{\\lambda_i + \\alpha} \\to 1, \\tilde{w}_i \\to {\\hat w_i}$ ；当$\\lambda_i \\ll \\alpha$ 时$\\frac {\\lambda_i}{\\lambda_i + \\alpha} \\to 0, \\tilde{w}_i \\to 0$ 。\n\n> $\\boldsymbol {H}$ 的特征值 $\\Lambda$的物理含义：Hessian矩阵的特征值其对应的特征向量方向上的函数变化率。特征值越大，其对应方向上的变化率越大，特征值越小，其对应方向上的函数变化率越小。(当前理解还不透彻，需要加强)\n\n3. **几何角度**\n\n![L2_regularization](Norm-Regularization/L2_regularization.png)\n\n蓝线椭圆表示没有正则化目标函数的等值线。红线圆圈表示$L^2$正则化项的等值线。在$\\tilde w$点，原始目标函数和正则化项的和达到最小值。目标函数$J$的Hessian的第一维(横向)特征值很小。当横向平移动时，目标函数不会增加得太多。因为目标函数对这个方向没有强烈的偏好，所以正则化项对该轴具有更强烈的影响。正则化项将$w^1$拉向零。而目标函数对沿着第二维的移动非常敏感。对应的特征值较大，表示高曲率。因此，权重衰减对$w^2$的位置影响相对较小。\n\n可以理解为**原始目标函数$J$** 和**正则化项**竞争的过程。原始目标函数$J$希望最优点落在$\\hat w$处，正则化项希望最优点落在原点处。在$w$的各个维度上他们通过比较各自的曲率（二阶导数）来决定谁起主要作用，谁的曲率大，谁就起主导作用。\n\nnote: $L^2$正则化项在原点处各方向上的曲率是相同的。\n\n\n\n# 2 $L^1$范数\n\n下面从两个角度理解$L^1$范数正则化：\n\n1. **从模型训练的整体角度(解析解的推导)**\n\n$L^1$范数正则化将目标函数$\\tilde J$中正则化项定义为参数$\\boldsymbol w$的各维度的绝对值之和，$\\Omega(\\boldsymbol \\theta) =||\\boldsymbol w||_1 = \\sum_i |w_i|$ 。正则化后的目标函数和其导数为：\n\n$$\n\\DeclareMathOperator{\\sign}{sign}\n\\begin {aligned}\n& \\tilde{J}(\\boldsymbol w ,\\boldsymbol \\beta,\\boldsymbol  X, y) = J(\\boldsymbol w ,\\boldsymbol \\beta, \\boldsymbol X, y) +  \\alpha ||\\boldsymbol w||_1 \\\\\n& \\nabla_w  \\tilde{J}(\\boldsymbol w ,\\boldsymbol \\beta,\\boldsymbol  X, y) = \\nabla_w J(\\boldsymbol w ,\\boldsymbol \\beta, \\boldsymbol X, y) +  \\alpha \\sign(\\boldsymbol w)\n\\end {aligned}\n$$\n\n其中若$w \\gt 0$，则$sign(w)= +1$；若$w \\lt 0$，则$sign(w) = -1$；若$w=0$，则$sign(w)=0$。\n\n假设$\\boldsymbol {\\hat w} = \\arg\\min_w {J}(\\boldsymbol w ,\\boldsymbol \\beta,\\boldsymbol  X, y) $，为了说明问题需要对原始目标函数做近似处理，未正则化的目标函数 $J(\\boldsymbol w ,\\boldsymbol \\beta,\\boldsymbol  X, y) $ 在$\\boldsymbol {\\hat w}$处的二阶泰勒近似为：\n\n$$\nJ(\\boldsymbol {w}) \\approx  J(\\boldsymbol {\\hat w}) +\\frac12(\\boldsymbol {w} - \\boldsymbol {\\hat w})^{\\mathrm{T}}\\boldsymbol H(\\boldsymbol {w} - \\boldsymbol {\\hat w})\n$$\n\n此时\n\n$$\n\\begin {aligned}\n& \\tilde{J}(\\boldsymbol w) \\approx     J(\\boldsymbol {\\hat w}) +\\frac12(\\boldsymbol {w} - \\boldsymbol {\\hat w})^{\\mathrm{T}}\\boldsymbol H(\\boldsymbol {w} - \\boldsymbol {\\hat w})  +  \\alpha ||\\boldsymbol w||_1 \\\\\n\\end {aligned}\n$$\n\n其中$H$是关于$w$的Hessian矩阵。\n\n)由于$\\sign$的存在，我们直接令是正则化的二阶近似的梯度为0还是很难直观的说明问题的。(假设$\\tilde w$ 是正则化目标函数的最小值，我们希望最终看到的是$\\tilde {w}_i$和$\\hat w_i$的代数关系)。为了得到更直观的代数关系，我们对Hessian矩阵进一步简化：假设$H$的所有非对角元素都为0，即，$H$是一个对角矩阵(当训练数据集的各维度的特征是不相关时会出现这种情况，比如使用了PCA算法对训练数据做了预处理)，此时：\n$$\n\\DeclareMathOperator{\\diag}{diag}\nH = \\diag (H_{1,1},H_{2,2},\\dots,H_{n,n})\n$$\n\n此时正则化的目标函数可以进一步近似为：\n\n$$\n\\begin {aligned}\n\\tilde{J}(\\boldsymbol w) &\\approx  \\hat{J}(\\boldsymbol w) \\\\\n                                           &=  J(\\boldsymbol {\\hat w}) +\\frac12(\\boldsymbol {w} - \\boldsymbol {\\hat w})^{\\mathrm{T}}\\boldsymbol H(\\boldsymbol {w} - \\boldsymbol {\\hat w})  +  \\alpha ||\\boldsymbol w||_1 \\\\\n                                           &= J(\\boldsymbol {\\hat w}) + \\sum_i[\\frac 12 H_{i,i}(w_i-\\hat w_i)^2] +  \\alpha \\sum_i|w_i| \\\\\n                                           &= J(\\boldsymbol {\\hat w}) + \\sum_i[\\frac 12 H_{i,i}(w_i-\\hat w_i)^2 +  \\alpha |w_i|] \n\\end {aligned} \\tag 1\n$$\n\n此时我们讨论这一个特殊的目标函数 $\\hat{J}(\\boldsymbol w) $ ，寻找一个$\\tilde w$使 $\\hat{J}(\\boldsymbol w) $取最小值即：\n\n$$\n\\tilde w = \\arg\\min_w \\hat{J}(\\boldsymbol w)\n$$\n\n对$\\hat{J}(\\boldsymbol w) $关于$w$的每个方向分别独立求导，并使之为0，得：\n\n$$\nH_{i,i}(w_i-\\hat w_i)+\\alpha \\cdot sign(w_i)=0 \\tag 2\n$$\n\n针对上面的公式(1)可以得到如下结论(注意：当前的目标是寻找一个$\\tilde w$使 $\\hat{J}(\\boldsymbol w) $取最小值)：\n\n1. 可以看到式(1)中的二次函数是关于$\\hat w$对称的，所以若要使式(1)最小，那么必有：$|w_i|\\lt|\\hat w|$，因为在二次项$\\frac 12 H_{i,i}(w_i-\\hat w_i)^2$不变的前提下，这样可以使得$\\alpha|w_i|$更小。\n2. $sign(w_i)=sign(\\hat w_i)$或$w_i=0$，因为在$\\alpha|w_i|$不变的情况下，$sign(w_i)=sign(\\hat w_i)$或$w_i=0$可以使式(1)更小。\n\n\n当$sign(w_i)=sign(\\hat w_i)$时结合公式(2)，得：\n\n$$\n\\begin {aligned}\n& H_{i,i}(w_i-\\hat w_i)+\\alpha \\cdot sign(\\hat w_i) = 0 \\\\\nw_i &= \\hat w_i - \\frac {\\alpha}{H_{i,i}} \\sign(\\hat w_i) \\\\\n       & = \\sign(\\hat w_i) |\\hat w_i|  - \\frac {\\alpha}{H_{i,i}} \\sign(\\hat w_i) \\\\\n       & = \\sign(\\hat w_i)(|\\hat w_i| -  \\frac {\\alpha}{H_{i,i}})\n\\end {aligned}\n$$\n\n但是这个公式不能满足$sign(w_i)=sign(\\hat w_i)$这个条件，因为$|\\hat w_i| \\lt \\frac{\\alpha}{H_{i,i}}$时，$sign(w_i)= - sign(\\hat w_i)$，这就是$w_i=0$时的条件。使 $\\hat{J}(\\boldsymbol w) $取最小值的$\\tilde w$ 的第$i$维是：\n\n$$\n\\tilde w_i = w_i = \\left \\{ \n      \\begin {aligned}\n             &\\sign(\\hat w_i)(|\\hat w_i| -  \\frac {\\alpha}{H_{i,i}})& , & |\\hat w_i| >  \\frac {\\alpha}{H_{i,i}} \\\\\n             &0                                                                            & , & |\\hat w_i| \\le  \\frac {\\alpha}{H_{i,i}} \\\\\n      \\end {aligned}\n\\right .\n$$\n\n将上式中的分段函数合并一下得到如下公式：\n\n$$\n\\tilde w_i = sign(\\hat w_i) \\max\\left\\{ |\\hat w_i| - \\frac{\\alpha}{H_{i,i}},0 \\right\\}\n$$\n\n根据以上公式总结如下：\n- 1.若$|\\hat w_i| \\leq \\frac{\\alpha}{H_{i,i}}$，$\\tilde w_i=0$ 。此时$\\hat{J}(\\boldsymbol w) $中的正则化项起到的主导作用。\n- 2.若$|\\hat w_i| \\gt \\frac{\\alpha}{H_{i,i}}$，$\\tilde w_i = \\sign(\\hat w_i)(|\\hat w_i| -  \\frac {\\alpha}{H_{i,i}})$ ，正则化结果$\\tilde w_i$是将$\\hat w_i$沿着第$i$个坐标轴向该轴的原点方向移动$\\frac{\\alpha}{H_{i,i}}$得到的。\n\n\n2. **几何角度**\n\n\n\n![L1_regularization](Norm-Regularization/L1_regularization.png)\n\n\n\n蓝线椭圆表示没有正则化目标函数的等值线。红线圆圈表示$L^2$正则化项的等值线。在$\\tilde w$点，原始目标函数和正则化项的和达到最小值。\n\n\n# 3 关于近似\n\n在这一节介绍$L^1$范数和$L^2$范数正则化项对目标函数的影响时都采用了近似。我个人对于这一点是很疑惑的，我思考的结论是这样的：\n\n- 我们的目标是：假设$\\tilde w$ 是正则化目标函数的最小值，我们希望最终看到的是$\\tilde {w}_i$和$\\hat w_i$的代数关系。\n- 近似的作用是使用**特殊情形下的目标函数** 来代替 **一般化的目标函数**进行问题论述的，因为一般化的目标函数很难直观的说明问题(即，$\\tilde {w}_i$和$\\hat w_i$的代数关系)。\n- 在$L^2$范数正则化问题中，特殊情形下的目标函数指的是原始目标函数正好是二次函数(quadratic)。\n- 在$L^1$范数正则化问题中，特殊情形下的目标函数指的是原始目标函数正好是二次函数(quadratic)，并且训练数据集的各维度的特征是不相关的（比如使用了PCA算法对训练数据做了预处理）。\n- 我们得出的结论都是在这些特殊情形下得出的。\n\n这种想法可能不对，先放在这里，如果以后有更好的理解在回来修改。\n\n\n\n# 4 tensorflow实现代码\n\n下面使用我从 [https://tensorflow.google.cn/tutorials/keras/overfit_and_underfit](https://tensorflow.google.cn/tutorials/keras/overfit_and_underfit)中抽取出来的部分代码展示 正则化在深度学习中的泛化作用，顺带也展示一下dropout 在模型泛化中的作用\n\n\n\n```python\nfrom __future__ import absolute_import, division, print_function, unicode_literals\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# download data\nNUM_WORDS = 10000\n(train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data(num_words=NUM_WORDS)\ndef multi_hot_sequences(sequences, dimension):\n    # Create an all-zero matrix of shape (len(sequences), dimension)\n    results = np.zeros((len(sequences), dimension))\n    for i, word_indices in enumerate(sequences):\n        results[i, word_indices] = 1.0  # set specific indices of results[i] to 1s\n    return results\ntrain_data = multi_hot_sequences(train_data, dimension=NUM_WORDS)\ntest_data = multi_hot_sequences(test_data, dimension=NUM_WORDS)\n```\n\n\n```python\nbaseline_model = keras.Sequential([\n    # `input_shape` is only required here so that `.summary` works.\n    keras.layers.Dense(16, activation=tf.nn.relu, input_shape=(NUM_WORDS,)),\n    keras.layers.Dense(16, activation=tf.nn.relu),\n    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n])\n\nbaseline_model.compile(optimizer='adam',\n                       loss='binary_crossentropy',\n                       metrics=['accuracy', 'binary_crossentropy'])\n\nbaseline_history = baseline_model.fit(train_data,\n                                      train_labels,\n                                      epochs=15,\n                                      batch_size=512,\n                                      validation_data=(test_data, test_labels),\n                                      verbose=0)\n```\n\n```python\nl2_model = keras.models.Sequential([\n    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n                       activation=tf.nn.relu, input_shape=(NUM_WORDS,)),\n    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n                       activation=tf.nn.relu),\n    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n])\n\nl2_model.compile(optimizer='adam',\n                 loss='binary_crossentropy',\n                 metrics=['accuracy', 'binary_crossentropy'])\n\nl2_model_history = l2_model.fit(train_data, train_labels,\n                                epochs=15,\n                                batch_size=512,\n                                validation_data=(test_data, test_labels),\n                                verbose=0)\n```\n\n\n```python\ndpt_model = keras.models.Sequential([\n    keras.layers.Dense(16, activation=tf.nn.relu, input_shape=(NUM_WORDS,)),\n    keras.layers.Dropout(rate=0.5),\n    keras.layers.Dense(16, activation=tf.nn.relu),\n    keras.layers.Dropout(rate=0.5),\n    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n])\n\ndpt_model.compile(optimizer='adam',\n                  loss='binary_crossentropy',\n                  metrics=['accuracy','binary_crossentropy'])\n\ndpt_model_history = dpt_model.fit(train_data, train_labels,\n                                  epochs=20,\n                                  batch_size=512,\n                                  validation_data=(test_data, test_labels),\n                                  verbose=0)\n```\n\n```python\ndef plot_history(histories, key='binary_crossentropy'):\n    plt.figure(figsize=(16, 10))\n    for name, history in histories:\n        val = plt.plot(history.epoch, history.history['val_' + key],\n                       '--', label=name.title() + ' Val')\n        plt.plot(history.epoch, history.history[key], color=val[0].get_color(),\n                 label=name.title() + ' Train')\n    plt.xlabel('Epochs')\n    plt.ylabel(key.replace('_', ' ').title())\n    plt.legend()\n    plt.xlim([0, max(history.epoch)])\n```\n\n\n```python\nplot_history([('baseline', baseline_history),\n              ('l2', l2_model_history)])\n```\n\n\n![png](Norm-Regularization/L2.png)\n\n```python\nplot_history([('baseline', baseline_history),\n              ('dropout', dpt_model_history)])\n```\n\n\n![png](Norm-Regularization/dropout.png)\n\n可以发现加入正则化项的模型相对于baseline的泛化能力更强。\n\n\n\n\n\n# 参考资料\n\nDeep Learning\n\n线性代数-第五版-同济\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Regularization"],"categories":["Mathematics"]},{"title":"最大似然损失函数","url":"%2Fblog%2FMaximum-Likehook-Estimator-Cost-Functions.html","content":"\n损失函数是神经网络设计中的重要一环。在神经网络的设计中，输出层的使用的激活函数和模型损失函数是根据实际问题设计的。本文以最大似然估计为理论基础，阐述回归问题、二分类问题和多分类问题中输出层的激活函数和模型损失函数的选择。\n\n符号定义：\n\n- 训练集特征$\\matrix {X}=\\{x^{(1)},x^{(2)} \\dots x^{(N)} \\}$ ，第$n$个样本的属性特征向量为$x^{(n)}$ ；\n\n- 训练集目标值 $T=\\{t^{(1)}, t^{(2)} \\dots t^{(N)} \\}$ ，第$n$个样本的label值为$t^{(n)}$ ；\n  如果是回归问题：$t^{(n)}$为一个实数；\n  如果是分类问题：$t^{(n)}$为一个one-hot编码向量，如二分类中第$i$个样本属于第0个类别时$t^{(n)}=(1, 0)$ 或者$t_0^{(n)}=1, t_1^{(n)}=0$ 。\n\n- $X$和$T$共同组成了训练集。\n\n- 通过一个模型$y=y(x, w)$ 进行预测：根据样本的属性特征$x^{(n)}$预测样本的label值，预测值为$y$ ，预测值的集合为$Y=\\{y^{(1)},y^{(2)} \\dots y^{(N)} \\}$\n  如果是回归问题：预测值$y$为一个实数；\n  如果是分类问题，预测值$y$为一个向量，各维度通常为概率值。如逻辑回归(二分类)(0.3, 0.7)、softmax(多分类)(0.1, 0.2, 0.7)。\n\n- 损失函数$E(\\theta) = g(T, Y)$ 是用来衡量模型预测值和样本真实值相近程度的，模型预测值和样本真实值越相近，则模型越好。其中$Y$ 是通过参数为$\\theta$的模型预测得到的。（当然还有正则化问题，本文先不考虑正则化）\n\n  \n\n  note: *下文中的上标表示样本在样本在样本集中的序号，下标表示向量的序号。在必要的时候为了使公式简洁会省略上标*\n\n\n\n# 1. Maximum Likehook Estimator\n\n最大似然函数应该是机器学习中最为常见的损失函数了。\n\n**最大似然理论认为，样本从服从分布$p(\\theta)$ 的总体随机抽取的($\\theta$是分布的参数，未知的)：**\n**那么样本集中的每个样本也服从于分布$p(\\theta)$ 。** 即：\n$$\np(t) = p(t|\\theta)\n$$\n**这个分布$p(\\theta)$是能够使样本的联合分布最大的分布。** 即：\n$$\np(T| \\theta) =\\prod_{n=1}^N {p(t^{(n)}|\\theta)}\n$$\n\n该公式称为**似然函数(Likehook Function)**。由于分布$p(\\theta)$是以$\\theta$为参数的，也就是说未知数$\\theta$是能够使似然函数最大的$\\theta_{ML}$:\n$$\n\\theta_{ML}={\\arg\\max}_\\theta \\prod_{n=1}^N {p(t^{(n)}|\\theta)}\n$$\n\n\n对两边取对数得 **对数似然函数 (Log Likehook Function)**:\n$$\n\\begin {aligned}\n\\ln p(T| \\theta) &=\\sum_{n=1}^N \\ln{p(t^{(n)}|\\theta)} \\\\\n\\theta_{ML} &={\\arg\\max}_\\theta \\sum_{n=1}^N \\ln{p(t^{(n)}|\\theta)}\n\\end {aligned}\n$$\n\n我们常见的多种损失函数都可以通过这个最大似然理论推导获得。其区别在于对$p(\\theta)$的不同解释方式。\n\n# 2. 回归问题\n\n在回归问题中，可以认为$\\theta$是由变量$x^{(i)}$和回归模型参数$w$组成的。并且目标值$t$服从**高斯分布**。\n$$\np(t|x,w)=N(t|y(x,w),\\beta^{-1})\n$$\n$\\beta$为高斯噪声。\n\n那么其似然函数和对数似然函数为：\n$$\n\\begin {aligned}\np(T|X,w)      &=\\prod_{n=1}^N  N(t^{(n)}|y(x^{(n)},w),\\beta^{-1}) \\\\\n\\\\\n\\ln p(T|X,w)&=\\sum_{n=1}^N \\ln N(t^{(n)}|y(x^{(n)},w),\\beta^{-1}) \\\\\n                     &=\\frac N2 \\ln \\beta -\\frac N2  \\ln(2\\pi) - \\beta E_D(w) \\\\\n                     &=\\frac N2 \\ln \\beta -\\frac N2  \\ln(2\\pi) - N \\beta E_{MSE}(w) \\\\\n\\\\\nE_D(w)         &=\\frac 12 \\sum_{n=1}^N (t^{(n)} - y(x^{(n)} ,w))^2 \\\\\n\\\\\nE_{MSE}(w)         &=\\frac 1N \\sum_{n=1}^N (t^{(n)} - y(x^{(n)} ,w))^2\n\\end {aligned}\n$$\n$E_D$就是被称为**sum-of-squares error function**的一种损失函数，$E_{MSE}$就是被称为**mean squared error function(MSE)**的一种损失函数 。使对数似然函数最大值$w$就是使$E_D$或$E_{MSE}$最小的$w$ 。(在模型训练过程中，我们更关心的是模型参数$w$，$\\beta$也可以求解，此处就不提了，有需要的话可以参考PRML 3.1.1或5.2)\n\n使似然函数或者$E_D$对$w$的导数为0，求得：\n$$\nw_{ML} = (X^TX)^{-1}X^TT\n$$\n这个公式就是**最小二乘法**的公式。\n\n\n# 3. 二分类问题\n\n在二分类问题中，可以认为$\\theta$是由变量$x^{(i)}$和模型参数$w$组成的。并且目标值$t^{(i)}$服从**Bernoulli distribution（伯努力分布，0-1分布）**。$t^{(i)}$的取值为0或1。\n\n使用神经网络处理二分类问题时，输出层通常使用sigmoid函数作为激活函数。而在传统的逻辑回归模型中也是使用的sigmoid函数。即：\n$$\ny = \\sigma(a) \\equiv \\frac 1{1+exp(-a)}\n$$\nsigmoid函数的一个重要特性就是其输出值表示的是概率，即：$y(x,w)$表示取$t=1$的概率，而$(1-y(x,w))$表示取$t=0$的概率。所以对于任何一个样本$\\{ x,t \\}$ 满足参数为$y(x,w)$的伯努力分布:\n$$\np(t|x,w)=y(x,w)^t \\{1-y(x,w)\\}^{(1-t)}\n$$\n那么其似然函数和对数似然函数为：\n$$\n\\begin {aligned}\np(T|X,w)     &= \\prod_{n=1}^N  y(x^{(n)},w)^{t^{(n)}} \\{1-y(x^{(n)},w)\\}^{(1-t^{(n)})}  \\\\\n\\\\\n\\ln p(T|X,w)&= \\sum_{n=1}^N \\{ t^{(n)} \\ln y(x^{(n)},w) + (1-t^{(n)}) \\ln [1-y(x^{(n)},w)]\\} \\\\\n\\\\\nE(w)             &= - \\ln p(T|X,w) \\\\\n                    &= - \\sum_{n=1}^N \\{ t^{(n)} \\ln y(x^{(n)},w) + (1-t^{(n)}) \\ln [1-y(x^{(n)},w)]\\}\n\\end {aligned}\n$$\n此处的$E(w)$就是我们常用到的**交叉熵损失函数(cross-entropy error function)** ，是对数似然函数的负数。\n\n# 4. 多分类问题\n\n首先介绍一下**Multinoulli分布**。在多分类问题中，样本的目标值有$K$种可能的互斥取值，所以每个目标值$t^{(n)}$可以使用$K$维向量的one-hot编码。如$K=6$，一个样本属于第3个类别，则$t_3=1, t_k=0,(1 \\le k \\le K ,k  \\ne 3)$，即：\n$$\n\\begin {aligned}\n& t =(0,0,1,0,0,0) \\\\\n& \\sum_{k=1}^K t_k = 1\n\\end {aligned}\n$$\n那么从总体抽样时，一个样本属于每个类别的概率也可以使用一个$K$维向量$\\mu$表示，$\\mu_k$表示$t_k = 1$的概率，且$\\sum_{k=1}^K\\mu_k =1$ 。\n\n那么一个样本$t$服从的分布就是：\n$$\n\\begin {aligned}\np(t) &= p(t | \\mu)  \\\\\n       &= \\prod_{k=1}^K p(t_k= 1 | \\mu_k) \\\\\n       &=\\prod_{k=1}^K \\mu_k^{ t_k}\n\\end {aligned}\n$$\n其中：\n$$\n\\begin {aligned}\nt  &= (t_1,t_2 \\dots t_K)^T \\\\\n\\mu &= (\\mu_1,\\mu_2 \\dots \\mu_K)^T\n\\end {aligned}\n$$\n使用神经网络处理多分类问题时，输出层通常使用softmax函数作为激活函数。即：\n$$\ny_k(x,w) = \\frac {\\exp(a_k(x,w))}{\\sum_j^K \\exp(a_j(x,w))} , (1 \\le k \\le K)\n$$\nsoftmax函数的一个重要特性就是其输出值表示的是概率，即:$y_k(x,w)$ 和上文的离散型分布中的$\\mu_k$ 的意义是一样，都表示$t_k=1$的概率。所以对于任何一个样本$\\{ x,t \\}$ :\n$$\n\\begin {aligned}\np(t|x,w)   &=\\prod_{k=1}^K y_k^{ t_k} \\\\\n                 &=\\prod_{k=1}^K y_k(x,w)^{ t_k}\n\\end {aligned}\n$$\n\n那么其似然函数和对数似然函数为：\n$$\n\\begin {aligned}\np(T|X,w)         & = \\prod_{n=1}^N \\prod_{k=1}^K y_k(x^{(n)},w)^{ t_k^{(n)}} \\\\\n\\\\\n\\ln p(T|X,w)   & = \\sum_{n=1}^N \\sum_{k=1}^K t_k^{(n)} \\ln y_k(x^{(n)},w)\\\\\n\\\\\nE(w)                & = - \\ln p(T|X,w) \\\\\n                       & = - \\sum_{n=1}^N \\sum_{k=1}^K t_k^{(n)} \\ln y_k(x^{(n)},w)\n\\end {aligned}\n$$\n此处的$E(w)$就是我们常用到的**交叉熵损失函数(cross-entropy error function)** ，是对数似然函数的负数。\n\n二分类问题可以看做是一种特殊的多分类问题，所以在神经网络中也可以使用softmax函数作为二分类问题的输出层激活函数。\n\n# 5. 总结\n\n以上损失函数都是基于最大似然估计推导的，最大似然估计最吸引人的地方在于，它被证明当样本数目$N \\to \\infty$ 时，就收敛率而言是最好的渐近估计。在合适的条件下，当训练样本数目趋向于无穷大时，参数的最大似然估计会收敛到参数的真实值，这个条件就是：\n\n- 真实分布必须在模型分布族中，否则无法估计正式分布。如在处理回归问题是，我们假设真实分布是一个高斯分布，求解过程就是估计高斯分布的参数的，但是如果真实分布不是高斯分布，那么我们按照高斯分布来求解，得到的结果肯定就是错误的。\n- 真实分布必须刚好对应一个模型分布的$\\theta$值，\n\n神经网络中针对于不同问题使用的输出层激活函数是不同的，进而使用不同的损失函数：\n\n|      |    输出层分布    | 输出层激活函数  | 输出层神经元数量 |                损失函数                 |\n| :--: | :---------: | :------: | :------: | :---------------------------------: |\n|  回归  |  Gaussian   | identity |    1     | sum-of-squares error function / MSE |\n| 二分类  |  Bernoulli  | sigmoid  |    1     |    cross-entropy error function     |\n| 多分类  | Multinoulli | softmax  |    K     |    cross-entropy error function     |\n\n二分类问题可以看做是一种特殊的多分类问题，所以输出层激活函数也可以使用softmax，损失函数使用多分类的 cross-entropy error function。\n\n其他：\n\n​\t还有针对于其他问题的设计，如：multiple target variables。当遇到的时候再补充\n\n# 参看资料\n\nDeep Leaning\n\nPattern Recognition and Machine Learning","tags":["Cost Functions"],"categories":["Concepts"]},{"title":"信息论中的一些知识点","url":"%2Fblog%2FPoints-in-Information-Theory.html","content":"\n# 信息量(自信息)\n\n信息奠基人香农(Shannon)认为“信息是用来消除随机不确定性的东西”. 一个事件蕴含的信息量与这条信息能够消除的不确定性是正相关的.  信息量应该满足如下条件:\n\n1. 事件发生的概率越低, 信息量越大; \n2. 事件发生的概率越高, 信息量越低; \n3. 多个对立事件同时发生, 总信息量是多个事件信息量相加. \n\n\n由此确定的信息量表示为:\n$$\nI(x)=-\\log_{2}p(x)\n$$\n\n其中, $p(x)$表示随机事件发生的概率. 可以看出, 自信息的计算和随机变量本身数值没有关系, 只和其概率有关. \n\n# 熵(entropy)\n\n对于一个变量$X \\sim p$($X$服从$p$分布), 该变量的熵是描述其不确定性的量, 表示该变量蕴含的信息量的期望(平均信息量).\n\neg:对于一个有k个状态的离散随机变量$X$, 有\n$$\nH(X)=-\\sum_{k=1}^Kp(X=k) \\log p(X=k)\n$$\na.当 $\\log$ 以2为底的时候称之为bits,结果可以视为多少个二进制位可以表示该变量\n\nb.当 $\\log$ 以e为底的时侯称之为 nats\n\n熵只依赖于随机变量的分布, 与随机变量取值无关, 所以也可以将 $X$ 的熵记作$ H(p)$. \n\n$0log0=0$.  \n\n熵的基本性质:\n\n- 非负性: $𝐻(𝑋) ≥ 0$, 等号表明确定场(无随机性)的熵最小;\n- 极值性: $𝐻(𝑋) ≤ \\log |X|$, 其中等号成立当且仅当$p(x)=\\frac 1{\\mid x \\mid}$, 这里$\\mid X \\mid$表示集合$X$中的元素个数. 该性质表明等概场具有的最大熵;\n- 熵描述了随机变量的不确定性, 熵越大，随机变量的不确定性就越大，分布越混乱;\n- 熵描述了随机变量的平均信息量;\n\n# 联合熵和条件熵\n\n设$X$、$Y$是两个离散型随机变量, 它们的联合分布为$𝑝(𝑥, 𝑦)$, 则$X$ 、$Y$的联合熵定义为\n$$\nH(X,Y)=-\\sum_{x \\in X} \\sum_{y \\in Y} p(x, y) \\log p(x, y)\n$$\n设$X$、$Y$是两个离散型随机变量, 它们的联合分布为$𝑝(𝑥, 𝑦)$, 则给定𝑋时𝑌的条件熵定义为\n$$\n\\begin {align}\nH(Y|X) & =\\sum_{x \\in X} p(x)H(y|X=x)                        \\\\\n       & =-\\sum_{x \\in X} \\sum_{y \\in Y} p(x, y) \\log p(y|x) \\\\\n       & =E[-\\log (y \\mid x)]                                \\\\\n\\end {align}\n$$\n联合熵和条件熵的直观含义见下图:\n\n![](Points-in-Information-Theory/cond-joint-entropy.png)\n\n链式规则: \n$$\nH(X, Y) = H(Y|X) + H(X)\n$$\n\n$$\n\\begin {align}\nH(X_1, X_2, X_3) &= H(X_1) + 𝐻(X_2, X_3 \\mid X_1) \\\\\n                 &= H(X_1) + 𝐻(X_2 \\mid X_1) + 𝐻(X_3 \\mid X_1, X_2) \\\\\n\\end {align}\n$$\n\n定理: \n$$\n\\begin {align}\n& H(X \\mid Y) \\le H(X) \\\\\n& H(X, Y) \\le H(X) + H(Y) \n\\end {align}\n$$\n\n# 交叉熵 (cross entropy)\n\n设随机变量$X$的分布密度为$𝑝(𝑥)$, $𝑞(𝑥)$是通过统计手段得到的$X$的近似分布, 则随机变量$X$的交叉熵定义为\n$$\nH(X,q)=-\\sum_{x \\in X}p(x) \\log q(x)\n$$\n\n note: 有的文章中交叉熵表示为 $H(p, q)$ . 该表示方法与联合熵相似, 需按照上下文确定.\n\n交叉熵可以看作是当我们用模型 $q$编码来自模型$p$的变量时所需的平均bits(如果$\\log$以2为底的话)\n\n所以, 有$H(p)=H(p,p)$,所以KL距离就可以看做是：用模型q来编码来自模型p的变量所需的额外bits！\n\n若存在$X$的真实分布为$p(x)$, 它的两个近似分布为$𝑞_1(𝑥)$ , $𝑞_2(𝑥)$ ,  并且$𝐻(p, q_1)< 𝐻(p, q_2)$ , 则$𝑞_1$是更好的近似分布. \n\n## 应用\n\n- 损失函数\n- 语言模型评价方法(实际上是熵率)\n\n# 熵率\n\n熵率可以直观的理解为一个长度为$n$的随机变量序列，该序列的熵随$n$增长的增长率.\n\n定义: 当如下极限存在时, 随机过程$\\{X_i\\}$ 的熵率定义为:\n$$\nH(\\chi) = \\lim_{n \\to \\infty} \\frac 1nH(x_1, x_2, \\dots, x_n)\n$$\n同时定义一个与熵率相关的量\n$$\nH'(\\chi)= \\lim_{n \\to \\infty}H(X_n|X_1,X_2,....X_{n-1})\n$$\n\n性质: **对于平稳随机过程，以上两者极限均存在，且有 $H(\\chi)= H'(\\chi)$**\n该性质非常常用, 为了证明这个性质, 引入如下两个定理:\n\n定理一: 对于平稳随机过程, $H(X_n|X_1,X_2,....X_{n-1})$ 随 $n$ 递减, 且存在极限 $H'(\\chi)$.\n\n证明 如下:\n$$\n\\begin {align}\nH(X_{n+1} \\mid X_1,X_2,....X_n) & \\le H(X_{n+1} \\mid X_2,....X_n) \\\\\n                                & = H(X_n|X_1,X_2,....X_{n-1})\n \\end {align}\n$$\n不等式由条件作用使熵减小这个性质得到, 等式由平稳随机过程的性质得到.\n所以, $H'(\\chi)$ 是非负且递减的, 即:  $H'(\\chi)$ 存在.\n\n定理二: (Cesaro 均值): 若 $a_n \\to a$, 且 $b_n = \\frac 1n \\sum_{i=1}^n a_i$, 则 $b_n \\to a$\n证明略\n\n下面证明熵率的性质: 对于平稳随机过程，以上两者极限均存在，且有 $H(\\chi)= H'(\\chi)$ .\n\n有联合熵的链式法则知:\n$$\n\\frac 1n H(x_1, x_2, \\dots, x_n) =  \\frac 1n \\sum_{i=1}^n H(X_n|X_1,X_2,....X_{n-1})\n$$\n即: 熵率为条件熵的时间平均.  由定理一知 条件上趋于极限 $H'(\\chi)$.\n又 由Cesaro 均值可知:\n$$\n\\begin {align}\nH(\\chi) & = \\lim_{n \\to \\infty} \\frac 1nH(x_1, x_2, \\dots, x_n) \\\\\n        & = \\lim_{n \\to \\infty}H(X_n|X_1,X_2, \\dots, X_{n-1})   \\\\\n        & = H'(\\chi)                                            \\\\\n\\end {align}\n$$\n\n**平稳马尔可夫链的熵率**\n\n设 $ \\{X_i\\}$为平稳马尔可夫链，且其平稳分布为 $\\mu$ , 转移矩阵为 $P$  , 则熵率为:\n\n$$\n\\begin {align}\nH(\\chi) &= H'(\\chi) \\\\\n        &= \\lim_{n \\to \\infty}H(X_n|X_1,X_2,\\dots, X_{n-1}) \\\\\n        &= \\lim_{n \\to \\infty} H(X_n \\mid X_{n-1}) \\\\\n        &= H(X_2 \\mid X_1) \\\\\n        &= -\\sum_{ij} p(X_1 = \\mu_i, X_2 = \\mu_j) \\log p(X_2 = \\mu_j \\mid X_1 = \\mu_i) \\\\ \n        &= -\\sum_{ij} p(X_1 = \\mu_i) p(X_2 = \\mu_j \\mid X_1 = \\mu_i) \\log p(X_2 = \\mu_j \\mid X_1 = \\mu_i) \\\\ \n        &= -\\sum_{ij} \\mu_i P_{ij}\\log{P_{ij}} \\\\\n\\end {align}\n$$\n\nnote: **熵率** 可以理解为 **随机过程的 \"熵\" **. \n\n应用:\n\n- 语言模型评价方法\n\n# 相对熵\n\n这个值是用来衡量两个分布之间相异度的, \n\n设$p(x)$ 是随机变量X的真实分布密度, $q(x)$是通过统计手段得到的X的近似分布, 则二者间相对熵定义为:\n$$\nD_{KL}(p||q)=-\\sum_{k=1}^Kp_k \\log \\frac{p_k}{q_k}\n$$\n如果是连续的随机变量, 把$\\sum$用积分 符号替换就好了\n\n对上式进行转化：\n$$\nD_{KL}(p||q)=\\sum_{k}{p_k} \\log{p_k} -\\sum_kp_k \\log q_k=-H(p)+H(p,q)\n$$\n其中$H(p,q)$为交叉熵, $p$ 为真是分布, $q$为近似分布.\n\n相对熵也称作\n– Kullback-Leibler 发散度、KL发散度\n– Kullback-Leibler 距离、KL距离\n\nKL距离就可以看做是：\n\n- 相对熵描述同一个随机变量的不同分布的差异\n- 相对熵描述了因为错用分布密度而增加的信息量\n- 用模型$q$来编码来自模型$p$的变量所需的额外bits！\n- 因为是“额外的”, 所以 KL的距离的值一定大于$0$, $D_{KL}=0$当且仅当$p=q$. \n\n\n应用于推荐系统的一个例子\n\n在使用LDA(Latent Dirichlet Allocation)计算物品的内容相似度时, 我们可以先计算出物品在话题上的分布, 然后利用两个物品的话题分布计算物品的相似度. 比如, 如果两个物品的话题分布相似, 则认为两个物品具有较高的相似度, 反之则认为两个物品的相似度较低. \n\n*note:* 交叉熵和相对熵其实是等价的, 那么在实际问题中该怎么选择呢? \n交叉熵大量应用在sigmoid函数和softmax函数中，最典型的算法应该就是神经网络和逻辑回归吧，而相对熵大量应用在生成模型中，例如GAN、EM、贝叶斯学习和变分推导中。从这里我们可以看出:\n\n- 如果想通过算法对样本数据进行概率分布建模，那么通常都是使用相对熵，因为我们需要明确的知道生成的分布和真实分布的差距，最好的KL散度值应该是0；\n- 而在判别模型中，仅仅只需要评估损失函数的下降值即可，交叉熵可以满足要求，其计算量比KL散度小。\n\n\n\n# 互信息(Mutual Information)\n\n互信息可以评价两个分布之间的距离，这主要归因于其对称性，假设互信息不具备对称性，那么就不能作为距离度量，例如相对熵，由于不满足对称性，故通常说相对熵是评价分布的相似程度，而不会说距离。\n\n互信息的定义为：**一个随机变量由于已知另一个随机变量而减少的不确定性.**\n$$\n\\begin {align}\nI(X; Y) & = H(X) - H(X \\mid Y)=H(Y) - H(Y \\mid X) \\\\\n        & = H(X) + H(Y) - H(X, Y) \\\\\n        & = H(X, Y) - H(X \\mid Y) - H(Y \\mid X) \\\\\n\\end {align}\n$$\n再来看一下这张图理解一下:\n\n![](Points-in-Information-Theory/cond-joint-entropy.png)\n\n对于三个变量的 联合熵, 条件熵, 互信息 的直观含义见下图:\n\n![](Points-in-Information-Theory/cond-joint-entropy-info.png)\n\n互信息用于衡量两个随机变量分布之间的**距离, 相关性, 独立性**。\n\n我们知道如果$p(x,y)=p(x)p(y)$, 则X和Y互相独立(不相关), 基于这个前提我们也可以使用$p(x,y)$ 与 $p(x)p(y)$ 的关系 来定义 两个随机变量$x$和$y$ 的相关性(相互独立的程度). \n\n互信息使用相对熵度量$ p(x,y)$与$p(x)p(y)$之间的关系：\n$$\nI(X; Y) = D_{KL}(p(X,Y)||p(X)p(Y))= - \\sum_{x \\in X}\\sum_{y \\in Y}p(x,y)\\log \\frac{p(x,y)}{p(x)p(y)}\n$$\n如: X和Y互相独立, $p(x,y)=p(x)p(y)$, 对数项为0  则 $I(X, Y) = 0$. 反之 两个变量相关性越强, 则$I(X, Y)$ 越大.\n\n互信息是大于等于0的，当且仅当X与Y相互独立时候等号成立。\n\n## PMI\n\n另一个与MI有关的的定义是**pointwise mutual information(PMI),**\n$$\nPMI(x,y)=\\log \\frac{p(x,y)}{p(x)p(y)}=\\log \\frac{p(x|y)}{p(x)}=\\log \\frac{p(y|x)}{p(y)}\n$$\n可以得知 MI值其实就是PMI值的**期望**, 该数值衡量了${p(x,y)}$ 和 ${p(x)p(y)}$ 的差异性, 即:  the discrepancy between these events occuring together compared to what would be expected by chance.\n\n \n\n## 最大互信息系数(maximal information coefficient)\n\n上面介绍的互信息都是针对离散随机变量计算的, 对于连续随机变量互信息定义为:\n$$\nI(X, Y) = D_{KL}(p(X,Y)||p(X)p(Y))= - \\int_x \\int_y p(x,y)\\log \\frac{p(x,y)}{p(x)p(y)} dx dy\n$$\n$p（x，y）$是联合概率密度分布函数. \n\n在生产环境下, 我们经常会遇到这样的情况, 数据特征是连续型特征, 但是我们是基于有限个样本进行分析的. 为了获得这些连续型特征(随机变量)的概率密度函数通常比较麻烦(如 核密度估计), 对于两个变量的联合概率密度分布的计算就更加的复杂了. 即: 连续随机变量 的联合概率计算相对来说比较麻烦. 所以我们就要找一个办法来解决这个问题.\n\nMIC 就是解决这个问题的. MIC 的思想是将两个变量离散化. 方法是 将当前二维空间在 x,y 方向分别划分为一定的区间数，然后查看当前的数据点(样本)在各个方格中落入的情况，并且使用散点图来表示，这样就解决了在互信息中的联合概率难求的问题。具体流程如下:\n\n1. 给定网格化的列数 $c$ 和行数 $r$, 对XY构成的二维坐标空间进行$c$列$r$行网格化(即对连续空间离散化), 此时可能有若干种网格化方案. 求出每种网格化方案对应的互信息值, 并找出其中的最大值 $ \\max_{G \\in \\mathcal G (c, r)} I(x_G ; y_G)$\n   假设$c=2$, $r=2$. 则可能有以下红、蓝两种网格化方案（实际上会更多），分别计算每个网格化方案对应的互信息值，找出使互信息值最大的网格化方案。\n\n   ![](Points-in-Information-Theory/mic01.png)\n\n2. 对互信息值进行归一化: $\\frac {\\max_{G \\in \\mathcal G(c, r)} I(x_G ; y_G)} {\\log \\min(c, r)}$ .\n\n3. 选取所有离散化方案中互信息的最大值作为MIC值: $c$, $r$ 有多种选取方案, 在所有的备选方案中选取一个使归一化的互信息最大的值 即:\n   $$\n   MIC = \\max_{c \\times r \\lt B} \\frac {\\max_{G \\in \\mathcal G (c, r)} I(x_G ; y_G)} {\\log \\min(c, r)}\n   $$\n   \n\n其中: \n\n- $c$, $r$ 是在 x,y 方向上的划分格子的个数，本质上就是网格分布;\n- $B$ 是变量，在原作者的论文当中提到 B 的大小设置是数据量的 0.6 次方. 具体为甚么用这个值, 猜测应该是经验吧;\n- $\\mathcal G (c, r)$ 是在给定$c$, $r$ 后, 所有的网格化方案的集合, $G \\in \\mathcal G(c, r)$;\n- $x_G$, $ y_G$ 分别表示在网格化方案 $G$ 中 变量 $x$ 和 $y$ 对应的离散序列.\n\nMIC总结\n\n**目的**: 用于衡量两个变量X和Y的线性或非线性的强度。\n\n特点: \n\n- **普适性**。不仅可以发现变量间的线性函数关系，还能发现**非线性**关系(如指数的，周期的)；\n- **均衡性**。MIC度量不仅可以用来纵向比较同一相关关系的强度，还可以用来横向比较不同关系的强度。比如: 对于相同噪声水平的两个函数关系(如一个指数的，另一个是周期的)，MIC度量具有近似的值。\n\n**缺点:** MIC的统计能力遭到了一些质疑，当零假设不成立时，MIC的统计就会受到影响。在有的数据集上不存在这个问题，但有的数据集上就存在这个问题. \n\n针对MIC的两个特点, 在《Machine Learning - A Probabilistic Perspective》一书中使用了如下图解释\n\n![IMG_265](Points-in-Information-Theory/Machine-Learning-A-Probabilistic-Perspective.jpg)\n\n该图使用的数据源是具有357个变量(特征)的数据集, 左图中的每个点是这些特征的一个两个组合(共63566个), 横坐标表示两个特征 的MIC, 纵轴是相关系数. 右边选取了六对特征组合, 并刻画出了其关系图. \n\n- 从右图可以看出C表示的两个特征的分布是没有规律的, 不具有相关性, 其相关系数接近0, MIC接近0. \n- H或者D 表示的随机变量具有近似的线性关系, 其相关系数和MIC都很高.\n- EFG表示的随机变量基本没有线性关系, 所以相关系数接近于0, 但是从右图可以看出其都具有非线性关系. 所有MIC值比较大. \n\n开源工具: [minepy - Maximal Information-based Nonparametric Exploration](https://minepy.readthedocs.io/en/latest/) \n其python api 地址:http://minepy.sourceforge.net/docs/1.0.0/python.html\n\n\n\n# 信息增益\n\n信息增益是决策树ID3算法在进行特征切割时使用的划分准则，其物理意义和互信息完全相同，并且公式也是完全相同。其公式如下：\n\n$$\ng(D, A) = H(D) - H(D \\mid A)\n$$\n\n其中D表示数据集，A表示特征，信息增益表示得到A的信息而使得类X的不确定度下降的程度，在ID3中，需要选择一个A使得信息增益最大，这样可以使得分类系统进行快速决策。 \n\n需要注意的是：在数值上，信息增益和互信息完全相同，但意义不一样，需要区分，当我们说互信息时候，两个随机变量的地位是相同的，可以认为是纯数学工具，不考虑物理意义，当我们说信息增益时候，是把一个变量看成是减少另一个变量不确定度的手段。\n\n# 信息增益率\n\n信息增益率是决策树C4.5算法引入的划分特征准则，其主要是克服信息增益存在的在某种特征取无意义值的时候导致的决策树划分特征失误的问题。例如假设有一列特征是身份证ID，每个人的都不一样，其信息增益肯定是最大的，但是对于一个情感分类系统来说，这个特征是没有意义的，此时如果采用ID3算法就会出现失误，而C4.5正好克服了该问题。其公式如下：\n$$\ng_r(D, A) = \\frac {g(D, A)} {H(A)}\n$$\n\n# 基尼系数\n\n基尼系数是决策树CART算法引入的划分特征准则，其提出的目的不是为了克服上面算法存在的问题，而主要考虑的是计算快速性、高效性，这种性质使得CART二叉树的生成非常高效。其公式如下：\n$$\n\\begin {align}\nGini(p) & = \\sum_{i=1}^m p_i (1-p_i) \\\\\n        & = 1 -   \\sum_{i=1}^m p_i^2 \\\\\n        & = 1 -  \\sum_{i=1}^m (\\frac {| C_k |}{|D|})^2\n\\end {align}\n$$\n可以看出，基尼系数越小，表示选择该特征后熵下降最快，对分类模型效果更好，其和信息增益和信息增益率的选择指标是相反的。基尼系数主要是度量数据划分对训练数据集D的不纯度大小，基尼系数越小，表明样本的纯度越高。 \n\n这里还存在一个问题，这个公式显得非常突兀，感觉突然就出来了，没有那种从前人算法中改进而来的感觉？其实为啥说基尼系数计算速度快呢，因为基尼系数实际上是信息熵的一阶进似，作用等价于信息熵，只不过是简化版本。根据泰勒级数公式，将$f(x) = - \\ln (x)$ 在 $x=1$ 处展开，忽略高阶无穷小，其可以等价为 $f(x) = 1 - x$ , 所以可以很容易得到上述定义。\n\n参考资料：\n\n[不知为不知–信息论和最大熵原则](https://blog.csdn.net/dog250/article/details/78944526)\n\n[机器学习各种熵：从入门到全面掌握](https://mp.weixin.qq.com/s/LGyNq3fRlsRSatu1lpFnnw##)\n\n[信息论(Information theory)的一些point](http://blog.csdn.net/dark_scope/article/details/8459576) \n\nMachine Learning - A Probabilistic Perspective\n","tags":["Information Theory"],"categories":["Mathematics"]},{"title":"Hidden Markov Models","url":"%2Fblog%2FHMM.html","content":"\n在之前学习过多次隐马模型，但是长时间不用再加上也没回头复习，回头看的时候感觉什么都忘了，所以本次重新拾起来。记得之前看过一篇[英文文章](http://www.comp.leeds.ac.uk/roger/HiddenMarkovModels/html_dev/main.html)讲的不错（现在无法访问了），随做了一个备份。现在以这篇文章为基础重新学习一下。目前网络上该[文章](http://www.comp.leeds.ac.uk/roger/HiddenMarkovModels/html_dev/main.html)的翻译版本有很多，我也会参考一些。\n\n# 1 概述\n\n个人觉得学习一个新模型，首先了解这个模型能干什么，然后在深入了解模型细节才能事半功倍。隐马模型是用来干什么的？举一个预测天气的例子：\n\n在几百年前，英国人为了预测今天的天气(sun, cloud, rain)，可以通过观察海藻的潮湿程度（dry, dryish, damp, soggy）：如果海藻是干燥的(dry)，则今天将是一晴天(sun)；如果海藻是潮湿的(soggy)，则今天将是一雨天(rain)。也就是说海藻的潮湿程度与天气是相关的。\n\n假设小明刚从中国来到英国，想知道上周从周一到周日的天气，由于一些原因他只能拿到上周海藻的潮湿程度的记录。那么他可以通过上面的规律推测出上周的天气。(例子不恰当，将就着用吧)。\n\n在这个例子中，小明观察到的是海草的状态，但是要预测的天气是隐藏的。而隐马模型就是使用显性的可观察到的状态序列（一周海藻潮湿程度的记录），对隐藏的未知的状态序列（一周的天气）进行预测的模型。\n\n# 2 马尔科过程(Markov Process)\n\n交通信号灯的变化是有规律可寻的：红灯-> 绿灯->黄灯 循环转换。如果当前是红灯，那么下一个一定就是绿灯。当前状态只依赖于前一个状态，状态之间的转化是确定的。这种确定性的状态转化规律是非常容易建模模拟的。\n\n天气的状态在三种天气(sun, cloud, rain)之间转换，但是晴天(sun)之后可能是多云(cloud)也可能是雨天(rain)。状态转化是不确定的。假设我们有一个过去100天的天气观察序列记录了过去100天的天气，那么明天的天气是什么呀。为了解决这个问题，首先需要使用100天的观察序列建立模型，然后根据模型对明天的天气进行预测。\n\n对非确定性的状态转化序列建模就涉及到了随机过程的建模了。对一个长度为$N$的随机过程建模如下： 即这个序列中每一个时间点的状态的联合概率\n$$\nP(X_N,X_{N-1} \\dots X_1)\n$$\n使用product rule进行改写：\n$$\nP(X_N,X_{N-1} \\dots X_1)=\\prod_{n=1}^NP(X_n|X_{n-1} \\dots X_1)\n$$\n可以看到公式右边是相当复杂的，$P(X_n|X_{n-1} \\dots X_1)$说明系列中时间点$n$时刻的状态是由该时刻之前的所有状态决定的。如果$N=1000$ ，那么为了求出序列中最后一个时刻所处状态的概率就需要考虑其之前的999个时刻。\n\n所以为了对非确定性的状态转化序列建模模拟，需要进行一些假设使问题简化。此处需要引入马尔科夫性和马尔科夫过程。\n\n> 马尔科夫性: 在一个随机过程$\\{X_t, t\\in T\\}$中，如果随机过程在$t_0$时刻所处的状态已知时，它在$t=0$时刻以后的状态与其在$t=0$时刻之前的状态无关。这种性质称为马尔科夫性。\t即：过程中“将来”的情况与“过去”的情况是无关的。\n>\n> 马尔科夫过程：具有马尔可夫性的随机过程称为马尔可夫过程。在一个随机过程中，一个状态仅取决于其之前的k个状态，这个过程称为k阶马尔科夫过程。$k=1$时为一阶马尔科夫过程。\n>\n> 一阶马尔科夫过程：设随机过程$\\{X_t, t\\in T\\}$的状态空间为S，如果\n> $$\n> P (X_n=x_{n}\\mid X_{n-1}=x_{n-1},\\dots ,X_0=x_{0})=P(X_{t_n}=x_{n}\\mid X_{t_{n-1}}=x_{n-1})\n> $$\n> 其中$n>2$，$x_i \\in S$，则成该随机规称为一阶马尔科夫过程。即当前状态只取决于前面的一个状态。\n\n![](HMM/first_order_markov_process.png)\n\n在上面的天气变化问题中，将三种天气(sun, cloud, rain)状态组成状态空间$S$，将一周的天气变化的过程抽象为一阶马尔科夫过程（今天的天气只与昨天有关，与前天无关），从而简化问题处理。对这样一个一阶马尔科夫过程建模如下：\n$$\n\\begin {aligned}\nP(X_N,X_{N-1} \\dots X_1)&=\\prod_{n=1}^NP(X_n|X_{n-1} \\dots X_1) \\\\\n                                           &=P(x_1)\\prod_{n=2}^NP(X_n|X_{n-1})\n\\end {aligned}\n$$\n一阶马尔科夫过程中，当前状态只取决于前面的一个状态，也就是说该过程只考虑状态之间的两两关系。如果状态空间中有M个状态，那么需要考虑的关系就有$M \\times M$ 种。使用状态转移矩阵(state transition matrix) A表示状态之间的两两关系，矩阵中的元素$a_{ij}=P(S_j \\mid S_i)$，其中$S_i$表示状态空间$S$中的第$i$个状态，$S_j$表示状态空间$S$中的第$j$个状态，$0 \\le i \\le |S|, 0 \\le j \\le |S|$。在天气变化这么一个马尔科夫过程中，状态转移概率是这样一个矩阵：\n\n$$\n\\begin{bmatrix}\n            & sun   &cloud  & rain    \\\\\n sun     &0.50   & 0.375 & 0.125 \\\\\n cloud  & 0.25  & 0.125 & 0.625 \\\\\n rain     & 0.25  & 0.375 & 0.375\n  \\end{bmatrix}\n$$\n\n第二行的三个数表示，昨天是多云(cloud)的情况下，今天是晴天(sun)、多云(cloud)、下雨(rain)的概率分别为 0.25 、 0.125 、 0.625。\n\n在一个序列中的第一个状态是没有前一个状态的，并且状态空间中的所有状态都有可能是第一个状态，所以需要一个向量来描述状态空间$S$中的值是第一个的概率，即初始状态向量($\\pi$)。在天气变化这么一个马尔科夫过程中，第一天是晴天(sun)、多云(cloud)、下雨(rain)的概率分别为 0.35 、 0.05 、 0.6。即:\n$$\n\\pi = (0.35 、 0.05 、 0.6)^T\n$$\n按照生成模型的观点理解一阶马尔科夫过程：\n\n- 按照初始状态向量($\\pi$)从状态空间$S$中选择一个状态$S_i$，生成过程中的第一个状态$x_1$;\n- 按照转移状态矩阵$A$从状态空间$S$中选择一个状态$S_j$，生成过程中的第二个状态$x_2$, 生成的概率为$a_{ij}$ ;\n- 按照该过程一次生成 $x_3 ,x_4 \\dots x_n$ 。\n\n一阶马尔科夫过程中有三个基本概念：\n\n1 **状态空间**：在随机过程中可选的状态的集合。如三种天气(sun, cloud, rain)状态。\n2 **初始状态向量($\\pi$)**： 描述状态空间$S$中的值是第一个状态的概率。\n3 **状态转移矩阵(A)**：描述每个状态之间相互转换的概率。\n\n\n# 3 隐马尔可夫模型(Hidden Markov Models)\n\n马尔科夫过程是对一个观察到的序列进行建模，在文章开始的例子中，“小明刚从中国来到英国，想知道上周从周一到周日的天气，由于一些原因他只能拿到上周海藻的潮湿程度的记录。”小明知道的是海藻湿度一周的状态变化序列，他不知道上周从周一到周日的天气状态，海藻的状态和天气的状态是存在紧密关系的。这里例子中存在两个状态序列：观察到的状态序列(海藻的潮湿状态)，隐藏的状态序列(一周的天气状态)。\n\n这种存在一个隐藏状态序列一个观察状态序列且隐藏状态序列和观察状态序列存在关系的问题，可以使用隐马尔可夫模型进行建模。在隐马模型中，假定隐藏状态序列是一个一阶马尔科夫过程，观察状态序列中的每一个节点都和隐藏状态序列中的节点一一对应，这个对应关系就反应了观察状态和隐藏状态的对应关系。如下雨天(隐藏状态)会使海藻潮湿(观察状态)。隐马模型使用状态发射矩阵（emission probability matrix）$\\phi$来表示隐藏状态和观察状态的对应关系\n\n![](HMM/hidden_markov_model.png)\n\n可观察状态的集合为$O$，和隐藏状态的的集合为$S$。$O_i$表示可观察状态集合中的第$i$个状态，$S_j$表示隐藏状态集合中的第$j$个状态。状态发射矩阵$\\phi$中的元素:\n\n$$\n\\phi_{ji}=P(O_i|S_j)\n$$\n\n文章开头的天气问题的状态发着矩阵可以表示如下：\n$$\n\\begin{bmatrix}\n           & dry   &dryish& damp & soggy \\\\\n sun    &0.60  & 0.20  & 0.15    &0.05     \\\\\n cloud & 0.25 & 0.25  & 0.25    &0.25     \\\\\n rain    & 0.05 & 0.10  & 0.35    &0.50\n  \\end{bmatrix}\n$$\n第一行表示，如果今天是晴天(sun)，那么今天的海藻处于四中状态(dry、dryish、damp、soggy)的概率分别为0.60、 0.20、 0.15、0.05。\n\nnote: 状态发着矩阵中每一行的和必须是1。\n\n相对于马尔科夫过程，隐马模型多了一个观察状态序列，和一个发射状态矩阵。隐马模型包含如下五个概念：\n\n1. **隐藏状态空间**：如三种天气(sun, cloud, rain)状态。\n2. **观察状态空间**：如海藻的四中状态(dry、dryish、damp、soggy)\n3. **初始状态向量($\\pi$)**： 描述状态空间$S$中的值是第一个状态的概率。\n4. **状态转移矩阵(A)**：描述每个隐藏状态之间相互转换的概率。\n5. **发射状态矩阵($\\phi$)**：给定一个隐藏状态时，一个观察状态出现的概率。\n\n一个隐马模型是一个标准的马尔科夫过程加上一个观察状态集合和从隐藏状态到观察状态的关系矩阵。\n\n隐马模型可以表示为初始状态向量($\\pi$)、状态转移矩阵(A)、发射状态矩阵($\\phi$)的三元组$\\{\\pi, A, \\phi \\}$ 。\n\n# 4 隐马模型的应用\n\n隐马模型可以用于解决三类问题，针对不同的问题使用不同的求解算法：\n\n1. leaning：当知道一个观察序列时，使用适当的算法训练一个HMM，求得参数$\\{\\pi, A, \\phi \\}$ 。使用 forward-backward algorithm求解。\n2. evaluation: 已知一个的HMM($\\{\\pi, A, B\\}$ 已知)，和一个观察序列时，求观察序列出现的概率。使用forward algorithm 求解。\n3. decoding: 已知一个观察序列和其对应的HMM时，求一个与之对应的隐藏状态序列。使用Viterbi algorithm求解。\n\n \n\n# 参考资料\n\n[机器学习 Hidden Markov Models](http://blog.csdn.net/matrix_space/article/details/45582017)\n\nPattern Recognition and Machine Learning","tags":["Series analysis"],"categories":["Model"]},{"title":"神经网络基础","url":"%2Fblog%2FBasic_of_Neural_Networks.html","content":"\n\n\n虽然学习神经网络很长时间了，但是也经常遇到问题的时候产生混乱，本次计算做一个神经网络的专题，将我看到的关于神经网络的东西按照我自己的学习和理解习惯整理下来。\n\n本文是这个专题的第一章，介绍基本的神经网络中知识。并在最后整理了一下神经网络的设计中的几个问题，以后会逐一学习。\n\n# 1 对一个神经元(neuron)建模\n\n人工神经网络一开始是用来对生物神经系统进行建模的，后来发现它在机器学习任务中能够获得比较好的效果，再然后的事情大家就都知道了。\n\n人工神经网络的一个节点是对生物神经元的数学建模，也就是说两者之间是可以类比的。其类比关系如下：\n\n| 生物神经元     | 突触(synapse) | 树突(dendrity)          | 细胞体(cell body)                     | 轴突(axon)                                |\n| --------- | ----------- | --------------------- | ---------------------------------- | --------------------------------------- |\n| **人工神经元** | 权重 $w_i$    | 乘法操作 $w_i \\times x_i$ | 激活因子  $a=\\sum_i {w_i \\times x_i }$ | 激活函数 $f(a)=f(\\sum_i {w_i \\times x_i })$ |\n\n在生物神经系统中，一个神经元通过树突(dendrity)末梢的突触(synapse)接受另一个神经元传到过来的神经冲动(impulse)，突触上的一些化学物质对接受到的神经冲动产生兴奋或者抑制，树突将通过突触处理的信号传递到细胞体。而一个神经元细胞通过树突和若干个其它细胞相连接，在细胞体上将所有的树突接收到的神经冲动进行汇总，根据汇总的神经冲动决定该神经元是否被激活，并把激活状态信息通过轴突给其它神经元。\n\n![生物神经元模型](Basic_of_Neural_Networks/A_cartoon_drawing_of_a_biological_neuron.png)\n\n在人工神经网络中，一个节点上最先和上一层节点作用的是权重因子 $w_i$(类比于突触), 其作用是控制前一个节点传递过来的信息对于当前节点的影响(兴奋或抑制) 。然后通过类似于树突的结构将信息$w_i \\times x_i$传导到细胞体，在细胞体重将所有影响相加得到激活因子$a$。然后根据激活因子的大小按照激活函数$f(a)$来决定这个节点是否被激活并传递给下一个节点。\n\n![数学神经元模型](Basic_of_Neural_Networks/a_mathematical_neuron_model.png)\n\n通过以上分析可以看出，一个神经元实际上就是一个以$w_0 \\dots w_n$为参数，$x_0\\dots x_n$为输入的函数：\n$$\nh(x0\\dots x_n;w0 \\dots w_n)=f(\\sum_{i=0}^n {w_i x_i})\n$$\n其中$f$是用户的定义的激活函数。\n\n# 2 人工神经网络的结构\n\n人工神经网络是将若干这这样的神经元进行连接来对生物神经系统进行建模的，其中包括 输入层、隐藏层、输入层。每一层由若干节点(神经元)组成。\n\n输入层 (input layer)：训练数据的各维度属性特征，每一个输入层节点对应一个属性。输入层的神经元数量由数据决定。输入层必须有。\n\n隐藏层(hidden layer)：由若干上文所述的完整神经元组成的。隐藏层的层数可以由用户定义，每一层的神经元数量也可以定义，隐藏层可以有，也可以没有。\n\n输出层(output layer)：对于分类问题，输出等的节点数量为类别数量。输出层必须有。\n\n![multi_layer_forward_networks](Basic_of_Neural_Networks/muliti_layer_forward_networks.png)\n\n# 3 前向传播算法(forward propagation)\n\n在Deep Learning中6.5节是这样表述前向传播算法的：\n\n> When we use a feedforward neural network to accept an input $x$ and produce an output $\\hat y$, information flows forward through the network. The inputs $x$ provide the initial information that then propagates up to the hidden units at each layer and finally produces $\\hat y$. This is called forward propagation. \n\n输入信息$x$逐层通过神经网络中的各层，在每一层中经过计算，最终在输出层得到值$\\hat y$的过程。 即前向传播算法是将**输入信息**逐层进行**计算**，向前进行传播的过程，在这个过程中输入x是确定的，在设计好的神经网络中每一层的计算方式也是确定的(前向传播过程中每个神经元的权重$w_i$ 是确定值)。\n\n# 4 后向传播算法(back propagation)\n\n先从线性回归模型的训练说起：对于样本集 $(x^{(i)},t^{(i)}),i\\in [1,N]$, 括号中上标是样本序号\n\n线性回归模型为： $\\hat y_w^{(i)} = w^Tx^{(i)} = \\sum_j{w_j x_j}^{(i)}$ （$x$ 和 $\\hat y$ 括号中上标是样本序号，$x$的下表为属性序号）\n\n损失函数为： $ E_w = \\frac12\\sum_{i=1}^N (\\hat y_w^{(i)} - t^{(i)}))^2 $ \n\n目标函数就是(实际还需要加正则化)： $\\min_w E_w$\n\n也就是说通过多次调整参数$w$的值使得损失函数最小化。而这个调整参数的过程就是梯度下降法，迭代公式为：\n$$\nw_j = w_j - \\alpha \\frac{\\partial}{\\partial w_j}E_w\n$$\n其中: $\\alpha$ 是学习率,\n$$\n\\begin {aligned} \\\\\n\\frac{\\partial}{\\partial w_j}E_w &= \\frac{\\partial}{\\partial w_j} \\frac12\\sum_{i=1}^N (\\hat y_w^{(i)} - t^{(i)})^2 \\\\\n& =\\sum_{i=1}^N (\\hat y_w^{(i)} - t^{(i)})\\frac{\\partial}{\\partial w_j}(\\hat y_w^{(i)} - t^{(i)}) \\\\\n&=\\sum_{i=1}^N (\\hat y_w^{(i)} - t^{(i)})\\frac{\\partial}{\\partial w_j}(\\sum_j{w_j x_j}^{(i)} - t^{(i)}) \\\\\n&=\\sum_{i=1}^N (\\hat y_w^{(i)} - t^{(i)})x_j^{(i)}\n\\end {aligned}\n$$\n*note: 以上公式是按照梯度下降法推导的, 如果是随机梯度下降法 $N=1$, 如果是mini batch梯度下降法$N=batch size$*\n\n---\n\n回到正题！\n\n前向传播算法实际上就是一个非线性函数$\\hat y(x^{(i)},W)$ 。对于每一个样本$(x^{(i)},t^{(i)})$，前向传播算法以$x^{(i)}$为输入产生一个预测值$\\hat y_W^{(i)} =\\hat y(x^{(i)},W)$。\n\n所以其损失函数为：\n$$\nE_W^{(i)} = \\frac12 (\\hat y_W^{(i)} - t^{(i)}))^2\n$$\n使用随机梯度下降法的$w \\in W$的迭代公式为\n$$\nw_j = w_j - \\alpha \\frac{\\partial}{\\partial w_j}E_w\n$$\n到现在为止一切进行的都很顺利，但是问题来了, $ \\frac{\\partial}{\\partial w_j}E_w$ 怎么求？\n\n![three_layers_networks](Basic_of_Neural_Networks/three_layers_networks.png)\n\n上图是PRML中的Figure5.1，其中$y_K$的计算公式为：\n$$\ny_K(x, w) = \\sigma (\\sum_{j=1}^M w_{kj}^{(2)} h(\\sum_{i=1}^D {w_{ji}^{(1)} x_i} + w_{j0}^{(1)}) + w_{k0}^{(2)})\n$$\n该公式中 括号中的上标为神经网络的层号，输入层x是第0层，隐藏层z是第1层，输出层y是第2层。\n\n如果要求$w_{ji}^{(1)}$ 中的$w_{11}^{(1)}$ ，根据求导法则需要4次求导。如果神经网络有100层呢？\n\n**神经网络由于使用了多层的嵌套结构，导致训练过程中深层的参数$w$的求导过程复杂。**\n\n后向传播算法就是用于解决这个问题的，在Deep Learning中6.5节是这样表述后向传播算法的：\n\n> During training, forward propagation can continue onward until it produces a scalar cost $J(\\theta)$. The back-propagation algorithm, often simply called backprop, allows the information from the cost to then flow backwards through the network, in order to compute the gradient.\n\n也就是说后向传播是将损失函数的信息由输出层向输入层方向逐层传递，用于计算损失函数对参数w的偏导数。\n\n下面按照backpropagation来计算下图中的$ \\frac{\\partial E}{\\partial w_{ji}}$ ，以下所有推到都是按照随机梯度下降法，所以只需要求与第n个样本相关的梯度，故省略n：\n\n![backpropagation](Basic_of_Neural_Networks/backpropagation.png)\n\n> 上图中由左到右依次为输入层(以$i$为下标, 共$I$个节点)、隐藏层(以$j$为下标, 共$J$个节点)、输出层(以$k$为下标, 共$K$个节点)。\n>\n> 对于每个节点：字母$a$表示激活因子，如：$a_j = \\sum_{i=0}^I w_{ji}z_i$ ,$a_k = \\sum_{j=0}^J w_{kj}z_j$\n>\n> 隐藏层的激活函数为$h$ ,  输出层的激活函数为identity, \n>\n> 字母$z$ 表示节点输出值，如: $z_j = h(a_j)$ ,$z_k = a_k$ \n\n首先使用链式法则：\n\n$$\n\\frac{\\partial E}{\\partial w_{ji}} = \\frac{\\partial E}{\\partial a_j} \\frac{\\partial a_j}{\\partial w_{ji}} = \\delta_j z_i\n$$\n\n其中\n\n$$\n\\frac{\\partial a_j}{\\partial w_{ji}} =z_i\n$$\n\n$$\n\\delta_j \\equiv \\frac{\\partial E}{\\partial a_j}\n$$\n\n**$\\delta_j$表示$j$这个节点对最终的误差需要负多少责任。**输出层节点$k$ 的误差是(输出层的激活函数为identity, $\\hat y_k = z_k = a_k$ ):\n$$\n\\delta_k =\\frac {\\partial}{\\partial a_k}\\frac12(z_k - t_k)^2 = z_k - t_k\n$$\n后向传播算法可以理解为，误差$\\delta$从输出层向输入层方向传播的过程，所以也叫做 **Error Backpropagation** 。\n\n下面只需要推导$\\delta_j$ , 利用链式法则，\n$$\n\\begin{aligned}\n\\delta_j & \\equiv \\frac{\\partial E}{\\partial a_j} \\\\\n&= \\sum_{k=1}^K \\frac {\\partial E}{\\partial a_k} \\frac{\\partial a_k}{\\partial a_j} \\\\\n& = h'(a_j) \\sum_{k=1}^K w_{kj} \\delta_k\n\\end{aligned}\n$$\n\n其中\n$$\n\\frac {\\partial E}{\\partial a_k} = \\delta_k\n$$\n\n$$\n\\begin{aligned}\n\\frac{\\partial a_k}{\\partial a_j} & = \\frac{\\partial }{\\partial a_j}(\\sum_{j=0}^Jz_j w_{kj}) \\\\\n&=\\frac{\\partial }{\\partial a_j}(\\sum_{j=0}^J h(a_j) w_{kj}) \\\\\n&= h'(a_j) w_{kj}\n\\end{aligned}\n$$\n**后向传播的目标是为了计算偏导数$\\frac{\\partial E}{\\partial w_{ji}}$ ，方法是误差$\\delta$ 沿着神经网络向后传播。**\n\nPRLM 中5.3.1 节将后向传播的流程总结如下\n\n> 1. Apply an input vector $x_n$ to the network and forward propagate through\n>    the network using $a_j=\\sum_iw_{ji}z_i$ and $z_j = h(a_j)$ to find the activations of all the hidden and output units.\n> 2. Evaluate the $\\delta_k$ for all the output units using $\\delta_k =\\frac {\\partial}{\\partial a_k}\\frac12(z_k - t_k)^2 = z_k - t_k$\n> 3. Backpropagate the $\\delta$ using $\\delta_j =  h'(a_j) \\sum_{k=1}^K w_{kj} \\delta_k $to obtain $\\delta_j$ for each hidden unit in the network.\n> 4. Use $\\frac{\\partial E}{\\partial w_{ji}} = \\delta_j z_i$ to evaluate the required derivatives\n\n\n\n# 5 神经网络问题大纲\n\n最后给自己立一个flag，以下是我整理的几个神经网络的设计中的几个问题，以后会逐一学习。\n\n1. 网络结构设计：隐藏层数量、隐藏层神经元数量\n2. 激活函数选择：ReLu，tanh，sigmoid ……\n3. Error function 设计：sum-of-squares、Cross Entropy ……\n4. 正则化问题：L2，dropout ……\n5. 优化算法的选择：SGD、GD ……\n\n\n\n# 参考资料\n\n[CS231n Convolutional Neural Networks for Visual Recognition lecture notes](http://cs231n.github.io/neural-networks-1/)\n\nDeep Leaning\n\nPattern Recognition and Machine Learning","tags":["Neural Networks"],"categories":["Neural Networks"]},{"title":"Python函数的参数","url":"%2Fblog%2FParameters_of_Function_in_Python.html","content":"\n函数定义中从形式上看存在四种形式的参数：\n\n位置参数：```def tupleSqeArgs(arg1[,arg2])```\n\n默认参数：```def tupleSqeArgs([arg1,[arg2,]] arg3='defaultB')```\n\n元组参数：```def tupleVarArgs([arg1, [arg2='defaultB',]] *nkw)```\n\n字典参数：```def dictVarArgs([arg1, [arg2='defaultB', [*nkw,]]] **kw)```\n\n[]内的内容是可选的。\n\n按照*python核心编程*中的定义，参数的分类是这样的\n\n > - 形式参数\n >    - 位置参数\n >    - 默认参数\n > - 可变长度的参数\n >    - 非关键字可变长参数（元组）\n >    - 关键字变量参数（字典）\n\n感觉读起来是不是很绕口且不容易记忆（反正我记不着后面两个），本文结合自己的一些实验，按照自己的记忆和学习习惯，将python函数的参数重新分为如下三类：\n\n1. 位置参数\n2. 元组参数\n3. 关键词参数\n\nNote：Python的函数参数需要从**函数定义**和**函数调用**两个方向理解。\n\n## 1 位置参数\n\n调用时需要按照函数定义中参数的出现顺序进行调用。\n\n**默认参数**：一种特殊的位置参数：默认参数必须出现在位置参数之后，函数调用时可以不对默认参数传值。\n\n```python\ndef tupleSqeArgs(arg1,arg2, arg3='defaultB'): \n    print 'formal arg 1:', arg1 \n    print 'formal arg 2:', arg2\n    print 'formal arg 3:', arg3\n```\n\n调用方式如下：\n\n```python\ntupleSqeArgs(1,2)\ntupleSqeArgs(1,2,3)\ntupleSqeArgs(arg1=1,arg2=2) #可以理解为关键词参数\ntupleSqeArgs(arg1=1,arg2=2,arg3=3) #可以理解为关键词参数\n```\n\n## 2 元组参数（Tuple）\n\n元组保存了所有传递给函数的\"额外\"的参数(匹配了所有位置和具名参数后剩余的)。函数定义中，所有的元祖参数必须在位置参数之后，且只能有一个。\n\n```python\ndef tupleVarArgs(arg1, arg2='defaultB', *nkw): \n    print 'formal arg 1:', arg1 \n    print 'formal arg 2:', arg2\n    for eachXtrArg in nkw: \n        print 'another arg:', eachXtrArg,type(eachXtrArg)\n```\n\n调用方法如下：\n\n```python\ntupleVarArgs('abc')  #len(nkw) == 0\ntupleVarArgs(23, 4.56)  #len(nkw) == 0\ntupleVarArgs('abc', 123, 'xyz', 456.789)   #len(nkw) == 2,nkw==('xyz', 456.789)\nt = ('xyz', 456.789)\ntupleVarArgs('abc', 123, *t)   #len(nkw) == 2,nkw==('xyz', 456.789)\n```\n\n## 3 关键词参数（Dictionary）\n\n在我们有不定数目的或者额外集合的关键字的情况中， 参数被放入一个字典中，字典中键为参数名，值为相应的参数值。\n\n```python\ndef dictVarArgs(arg1, arg2='defaultB', **kw):\n    print 'formal arg1:', arg1 \n    print 'formal arg2:', arg2 \n    for eachXtrArg in kw.keys():\n        print 'Xtra arg %s: %s' %  (eachXtrArg, str(kw[eachXtrArg])) \n```\n\n调用方式为：\n\n```python\ndictVarArgs(1220, 740.0, c='grail') \ndictVarArgs(arg2='tales', c=123, d='poe', arg1='mystery')\n\nd = {'arg1': 'mystery',\n'arg2': 'tales',\n'c': 123,\n'd': 'poe'}\ndictVarArgs(**d)\n\nd = {'c': 123,'d': 'poe'}\ndictVarArgs('mystery','tales', **d)\n```\n\n\n\n# 4 位置参数&元组参数&关键词参数共同出现时\n\n```python\ndef dictVarArgs(arg1, arg2='defaultB',*nkw, **kw):\n    print 'formal arg1:', arg1\n    print 'formal arg2:', arg2\n    for eachXtrArg in nkw: \n        print 'another arg:', eachXtrArg,type(eachXtrArg)    \n    for eachXtrArg in kw.keys():\n        print 'Xtra arg %s: %s' %  (eachXtrArg, str(kw[eachXtrArg]))\n\n```\n\n合法的调用方法如下:\n\n```python\n dictVarArgs(123, 567,'tales', 'mys',c=123, d='poe') \n # 元组参数（'tales', 'mys'）必须出现在具名参数（关键词参数）之前，在位置参数之后\n```\n\n非法调用如下：\n\n```python\ndictVarArgs(123, arg2=567,'tales', 'mys',c=123, d='poe') \n# 这种调用方法arg2=567，认为arg2时关键词参数。元组参数出现在了关键词参数之后，调用失败。\n```\n\n","tags":["Python"],"categories":["Python"]},{"title":"Python编码问题","url":"%2Fblog%2FPython_Encode.html","content":"\n从一开始接触Python就被它的编码问题困扰，遇到问题就从网上找一个解决方案，能解决问题就用，但是也不明白其中的原理，用完就忘了，下次遇到问题的时候再去找。最近我话时间阅读了一些博客和代码，将相关的问题整理下来。\n\n# 1 编码(Encode)与解码(Decode)\n\n- 世界上只有两种编码：Unicode和other(ASCII,GBK,BIG5,UTF-8)\n- other中的所有编码都可以与unicode编码相互转化。Unicode是各种编码之间转换的媒介，other中的编码不能直接相互转化\n- ASCII码是单字节编码，GBK,BIG5,UTF-8等是多字节编码。这一点很重要\n- 操作系统和大多数编程语言都直接支持Unicode。在计算机内存中处理字符时(如使用Notepad++编辑一个txt文件)，统一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为other中编码(如UTF-8)对应的字节流。\n- Encode: 将 Unicode字符流 转换为 other中编码(如UTF-8)对应的字节流 的过程\n- Decode: 将 other中编码(如UTF-8)对应的字节流 转换为 Unicode字符流 的过程\n\n\n![](Python_Encode/char_codes.png)\n\n# 2 常见编码问题\n\n我常遇到的与Python相关的编码问题有两个。为了能够详细的说明问题，我Python源文件的编辑到执行分为了三个阶段：1. 源文件的编辑；2. 解释器读取源文件; 3. 解释器执行源文件。\n\n![](Python_Encode/3_encoding_settings.png)\n\n\n\n## 2.1 源文件编辑\n\n我们使用的编辑器都是有文件编码设置的，如Windows系统自带的记事本在国内默认是GBK，Vim通过配置文件设置为utf-8。磁盘上的文件都是以二进制格式存放的，其中文本文件都是以某种特定编码(如GBK)的字节形式存放的。当使用编辑器打开文本文件Src.py时，编辑器首先在磁盘上读取文件的二进制字节流，然后编辑器会按照其设置的编码方式将字节流解码(Decode)成为我们能够认识的Unicode字符串。注意，当打开某个特定文件时，编辑器设置的编码方式要和文件实际使用的编码一样，即，如果文件使用的是GBK编码，文本编辑器设置的编码方式为GBK才能正确打开这个文件（当我们使用记事本、Notepad++时，这些软件可以自动检查文件的编码方式，然后以这个编码打开文件）。\n\n当文本编辑完成以后，需要保存文件，编辑器首先将其操作的Unicode字符串转换为二进制的字节流(Encode)，然后写入磁盘。\n\n## 2.2 Python解释器读取源文件\n\n当调用python Src.py执行原文件的时候，Python解释器首先需要读取这个文本文件，但是它不知道这个Src.py是以什么编码方式存储的。如果不告诉它，他就会以ASCII码的来解码(Decode)这个文本文件，所以如果Src.py文件中只有ASCII码字符，一般是能够正确解码的。但是如果这个文件中包含汉字，这个解码过程就会失败，我们需要告诉python解释器，这个文件使用的是何种编码。这就是我们需要在源文件中写入 如下字符串的原因。\n\n```python\n# coding:utf-8\n```\n\n这行代码告诉解释器，该文件是以utf-8编码的。note: 此处设置的编码要与源文件实际使用的编码方式一致。\n\n关于源文件中声明字符串的两种方式如下：\n\n```python\n# coding:utf-8\nu = u'太阳'\nprint 'type(u):', type(u)  # type(u): <type 'unicode'>\nprint 'repr(u):', repr(u)  # repr(u): u'\\u592a\\u9633'\nstr_byte = '太阳'\nprint 'type(str_byte):', type(str_byte)  # type(str_byte): <type 'str'>\nstr_u = str_byte.decode('utf-8')\nprint 'type(str_u):', type(str_u)  # type(str_u): <type 'unicode'>\nprint 'repr(str_u):', repr(str_u)  # repr(str_u): u'\\u592a\\u9633'\nstr_u = str_byte.decode('gbk')  # 解码失败 UnicodeDecodeError\n```\n\n在源文件读取阶段，解释器都会以utf-8解码 u'太阳' 和 '太阳'\n\n在程序执行阶段， \n\n- u'太阳'  会转化为unicode对象， u开头的字符串会 声明这个字符串是 unicode对象；\n- '太阳'  会转化为 utf-8编码的字节串（str对象），此种定义方法实际上声明命了一个str对象。为什么是utf-8，是  “# coding:utf-8”  声明的，所以可以用utf-8解码该字节串，而用gbk解码则失败了。\n\n## 2.3 Python程序的执行\n\n我常使用的是python2，但是由于ptyhon2产生的时间比较早，所以设计上出现了存在一些问题。以下内容只针对Python 2.x ，Python 3.x 没有以下问题。\n\n### 2.3.1 字符串与字节串\n\n上面已经讲过，在计算机内存中，字符串中的字符都是Unicode编码的。但是在python刚出现时，还没有Unicode编码，它处理的都是ASCII码这样的单字节字符，所以它将单字的序列定义为字符串，即 类str。以现在的眼光来看，类str的对象实际上是字节串，而不是真正意义上的字符串。还好，后来Python又添加了unicode类，这才是真正意义上的字符串。\n\n类str对象是除unicode以外的所有编码(如GBK,UTF-8)的字符串对应的字节串\n\nnote：在python中类str和类unicode都是basestring的子类。\n\n同时，由于以上所述原因，python2的默认编码是ASCII码，对于一个给定的str对象，它就默认这个对象每个字节都代表一个ASCII码字符。\n\n所以对于非ASCII码字符串，如果想得到字符串的长度，需要在unicode对象上使用len函数，在str对象上使用len函数会得到其编码的字节长度，而不是字符长度。\n\n```python\n# coding:utf-8\n\nu = u'太阳'\nprint 'type(u):', type(u)  # len(str_byte): 6\nprint 'repr(u):', repr(u)  # repr(u): u'\\u592a\\u9633'\nprint 'len(u):', len(u)  # len(u): 2\nstr_byte = '太阳'\nprint 'type(str_byte):', type(str_byte)  # type(str_byte): <type 'str'>\nprint 'repr(str_byte):', repr(str_byte)  # repr(str_byte): '\\xe5\\xa4\\xaa\\xe9\\x98\\xb3'\nprint 'len(str_byte):', len(str_byte)  # len(str_byte): 6\n```\n\n### 2.3.2 字节串之间的转换\n\n在python程序执行过程中有一个str对象(字节串) str_utf8 ，它是以UTF-8编码的字节串，如果我想把它转换为以GBK编码的字节串str_gbk应该怎么办呢。根据上面描述首先需要将str_utf8解码(decode)为unicode编码的字符串u，然后将其编码(encode)为GBK编码的字节串。\n\n> UTF-8=>Unicode=>GBK\n\n```python\n# coding:utf-8\n\nu = u'太阳'\nstr_utf8 = u.encode('utf-8')  \nprint repr(str_utf8)    # '\\xe5\\xa4\\xaa\\xe9\\x98\\xb3'\nstr_unicode = str_utf8.decode('utf-8')\nstr_gbk1 = str_unicode.encode('gbk')\nprint repr(str_gbk1)   # '\\xcc\\xab\\xd1\\xf4'\n\nstr_gbk2 =  str_utf8.decode('utf-8').encode('gbk')  #也可以这样\nprint repr(str_gbk2)  # '\\xcc\\xab\\xd1\\xf4'\n```\n\n但是有时候可以直接做到从UTF-8到GBK的转化：\n\n```python\n# coding:utf-8\n\nimport sys\nprint sys.getdefaultencoding() # ascii\nreload(sys)\nsys.setdefaultencoding('utf-8') # 将python解释器的默认解码设置为utf-8\n\nu = u'太阳'\nstr_utf8 = u.encode('utf-8')  \nprint repr(str_utf8)    # '\\xe5\\xa4\\xaa\\xe9\\x98\\xb3'\nstr_gbk3 =  str_utf8.encode('gbk')  #也可以这样\nprint repr(str_gbk3)  # '\\xcc\\xab\\xd1\\xf4'\n\n```\n\n从代码上看，utf-8的字节串直接转化为了gbk编码的字节串。实际上的转化过程还是\n\n> UTF-8=>Unicode=>GBK \n\n对于这种代码，python解释器的做法实际上是 \n\n```\nstr_gbk3 =  str_utf8.decode(defaultencoding).encode('gbk') \n```\n\n这就是为什么我们需要定义defaultencoding的的原因。\n\n此处需要注意：python中默认的defaultencoding 是ascii。\n\n### 2.3.4 python读写文件\n\n读写的文件内容可以当做一个python程序变量来处理。\n\n内置的open()方法打开文件时，read()读取的是字节流(str)，读取后需要使用正确的编码格式(由实际读取的文件决定)进行解码(decode)。write()写入时，如果参数是unicode，则需要使用你希望写入的编码进行编码(encode)，如果是其他编码格式的字节串(str)，则需要先用该str的编码进行decode，转成unicode后再使用写入的编码进行encode。如果直接将unicode作为参数传入write()方法，Python将先使用源代码文件声明的字符编码进行编码然后写入。\n\n```python\n# coding: UTF-8 \nf = open('test.txt')  # 已知是GBK编码\ns = f.read()\nf.close()\nprint type(s)         # <type 'str'>\nu = s.decode('GBK')   # 解码成unicode \nf = open('test2.txt', 'w')   # 已知是UTF-8编码\ns = u.encode('UTF-8')   # 编码为UTF-8\nf.write(s)\nf.close()\n```\n\n\n\n# 3 字符编码简介\n\n在第一节已经对字符编码进行了一个简单的概括，本节进行稍微详细的说明。本节内容主要参考自[Python字符编码详解](http://www.cnblogs.com/huxi/archive/2010/12/05/1897271.html)\n\n字符编码的作用就是将字符与计算机的数值相对应。如字符\"A\"对应65(\\x41)，字符\"1\"对应49(\\x31)。字符的数量和编码的长度是相关的，如中国人使用的汉字有几万个，而美国人使用的英文加上特殊符号也就那么几十个。正式由于不同环境中字符和字符数量的不同才产生了各种令人头疼的编码。\n\n## 3.1 ASCII\n\nASCII(American Standard Code for Information Interchange)，是一种单字节的编码。计算机世界里一开始只有英文，而单字节可以表示256个不同的字符，可以表示所有的英文字符和许多的控制 符号。不过ASCII只用到了其中的一半（\\x80以下），共128个字符，这也是MBCS得以实现的基础。\n\n## 3.2 MBCS\n\n然而计算机世界里很快就有了其他语言，单字节的ASCII已无法满足需求。后来每个语言就制定了一套自己的编码，由于单字节能表示的字符太少，而且同时也需要与ASCII编码保持兼容，所以这些编码纷纷使用了多字节来表示字符，如GBK、、GB2312、BIG5等，他们的规则是，如果第一个字节是\\x80以下，则仍然表示ASCII字符；而如果是\\x80以上，则跟下一个字节一起（共两个字节）表示一个字符。\n\nMBCS(Multi-Byte Character Set)是这些编码的统称。目前为止大家都是用双字节，所以有时候也叫做DBCS(Double-Byte Character Set)。必须明确的是，MBCS并不是某一种特定的编码，Windows里根据你设定的区域不同，MBCS指代不同的编码，而Linux里无法使用 MBCS作为编码。在Windows中你看不到MBCS这几个字符，因为微软为了更加洋气，使用了ANSI来吓唬人，记事本的另存为对话框里编码ANSI就是MBCS。同时，在简体中文Windows默认的区域设定里，指代GBK。\n\n## 3.3 Unicode\n\n后来，有人开始觉得太多编码导致世界变得过于复杂了，于是大家坐在一起拍脑袋想出来一个方法：所有语言的字符都用同一种字符集来表示，这就是Unicode。\n\n最初的Unicode标准UCS-2使用两个字节表示一个字符，所以你常常可以听到Unicode使用两个字节表示一个字符的说法。但过了不久有人觉得256$\\times$256太少了，还是不够用，于是出现了UCS-4标准，它使用4个字节表示一个字符，不过我们用的最多的仍然是UCS-2。\n\n**此处需要注意，ASII和MBCS即保存了字符和码位的对应关系，传输和存储的时候也是使用了字符对应的码位。与ASII和MBCS不同，UCS(Unicode Character Set)还仅仅是字符对应码位的一张表而已，比如\"汉\"这个字的码位是6C49。字符具体如何传输和储存则是由UTF(UCS Transformation Format)来负责。**\n\n**现代操作系统和大多数编程语言都直接支持Unicode。在计算机内存中，统一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码。**\n\n一开始这事很简单，直接使用UCS的码位来保存，这就是UTF-16，比如，\"汉\"直接使用\\x6C\\x49保存(UTF-16-BE)，或是倒过来使用\\x49\\x6C保存(UTF-16-LE)。但用着用着美国人觉得自己吃了大亏，以前英文字母只需要一个字节就能保存了，现在大锅饭一吃变成了两个字节，空间消耗大了一倍……于是UTF-8横空出世。\n\nUTF-8编码把一个Unicode字符根据不同的数字大小编码成1-6个字节，ASCII字符使用1字节表示，汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节。\n\n另外值得一提的是BOM(Byte Order Mark)。我们在储存文件时，文件使用的编码并没有保存，打开时则需要我们记住原先保存时使用的编码并使用这个编码打开，这样一来就产生了许多麻烦。而UTF则引入了BOM来表示自身编码，如果一开始读入的几个字节是其中之一，则代表接下来要读取的文字使用的编码是相应的编码：\n\n> BOM_UTF8 '\\xef\\xbb\\xbf' \n> BOM_UTF16_LE '\\xff\\xfe' \n> BOM_UTF16_BE '\\xfe\\xff'\n\n并不是所有的编辑器都会写入BOM，但即使没有BOM，Unicode还是可以读取的，只是像MBCS的编码一样，需要另行指定具体的编码，否则解码将会失败。\n\n你可能听说过UTF-8不需要BOM，这种说法是不对的，只是绝大多数编辑器在没有BOM时都是以UTF-8作为默认编码读取。即使是保存时默认使 用ANSI(MBCS)的记事本，在读取文件时也是先使用UTF-8测试编码，如果可以成功解码，则使用UTF-8解码。记事本这个别扭的做法造成了一个 BUG：如果你新建文本文件并输入\"姹塧\"然后使用ANSI(MBCS)保存，再打开就会变成\"汉a\"，你不妨试试 ：）\n\n\n\n\n# 参考资料\n\n[Python字符编码详解](http://www.cnblogs.com/huxi/archive/2010/12/05/1897271.html)\n\n[Python中的字符串与字符编码](http://www.cnblogs.com/yyds/p/6171340.html)\n\n[python字符串编码及乱码解决方案](http://blog.csdn.net/pipisorry/article/details/44136297)\n","tags":["Python"],"categories":["Python"]},{"title":"GloVe","url":"%2Fblog%2FGloVe.html","content":"# 1. 概述\n\n做自然语言处理的时候很多时候会用的Word Embedding，目前常用的方法是word2vec算法训练词向量。不过训练词向量的方法有很多，今天介绍GloVe算法。\n\nGloVe：Global Vectors。\n\n模型输入：语料库 corpus\n\n模型输出：每个词的表示向量\n\n# 2. 基本思想\n\n## 2.1. 背景知识\n\n要讲GloVe模型的思想方法，我们先介绍两个其他方法：\n\n一个是基于奇异值分解（SVD）的[LSA](https://en.wikipedia.org/wiki/Latent_semantic_analysis)算法，该方法是topic model的一种，对word-document矩阵（矩阵的每个元素为tf-idf）进行奇异值分解，从而得到term的向量表示和document的向量表示。\n\n当使用LSA训练词向量的时候，需要将word-document矩阵换成word-context矩阵$M_{nm}$，该矩阵的行是word，列是word的上下文，每一行是一个word与其上下文的共现次数，即在整个语料库中的全局统计特征。矩阵中各元素的值还有其他更优的取值方法，请参见[Improving Distributional Similarity with Lessons Learned from Word Embeddings](https://www.transacl.org/ojs/index.php/tacl/article/view/570)的第一二部分。\n\n对$M_{nm}$奇异值分解$M_{nm}=U_{nk}\\Sigma_{kk}V_{km}^T$,取其$\\Sigma$前$d$个主要元素，则\n$$\nM_{nm} \\approx U_{nd}\\Sigma_{dd}V_{dm}^T\n$$\n公式的右边可以分解为两部分\n$$\nW_{nd}=U_{nd}\\Sigma_{dd}\\\\\nC_{md}=V_{md}\n$$\n其中$W_{nd}$的每一行为一个word的词向量，$C_{md}$的每一行为一个context的向量。\n\n关于LSA，在斯坦福大学的自然语言的课程的第三次课程中有涉及 [CS224n: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/cs224n/syllabus.html)\n\n另一个方法是[word2vec]((http://blog.csdn.net/itplus/article/details/37969519))算法，该算法可以分为skip-gram 和 continuous bag-of-words（CBOW）两类,但都是基于局部滑动窗口计算的。即，该方法利用了局部的上下文特征（local context）\n\n> 关于word2vec，在斯坦福大学的自然语言的课程的第三次课程中有涉及 [CS224n: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/cs224n/syllabus.html)\n>\n> - word2vec 使用固定的window遍历整个语料库\n> - 使用每个词(center word)的上下文(surrounding words)预测该这个词(center word)(CBOW模型)\n> - word2vec预测每一个词(center word)的时候都利用了上下文中单词之间的共现关系(note：没有使用两个词在整个语料库中的共现次数)\n\n\n\nLSA总结：\n\n- 训练速度快\n- 有效利用了全局统计特征\n- Primarily used to capture word similarity\n\nword2vec总结：\n\n- Scales with corpus size\n- 没有使用全局统计特征\n- Can capture complex patterns beyond word similarity \n\n## 2.2. GloVe模型的思想\n\nLSA和word2vec作为两大类方法的代表，一个是利用了全局特征的矩阵分解方法，一个是利用局部上下文的方法。GloVe将这两类方法的优点结合到了一起，特点如下：\n\n> Fast training\n>\n> Scalable to huge corpora\n>\n> Good performance even with small corpus,\tand\tsmall vectors\n\nGloVe模型就是将这两中特征合并到一起的，即使用了语料库的全局统计（overall statistics）特征，也使用了局部的上下文特征（即滑动窗口）。为了做到这一点GloVe模型引入了Co-occurrence Probabilities Matrix。\n\n首先引入word-word的共现矩阵$X$，\n$X$的元素$X_{ij}$是语料库中出现在word $i$上下文中的word $j$ 的次数；\n$X_i=\\sum_{k}{X_{ik}}$,是出现在word $i$ 上下文中的所有word的总次数；\n$P_{ij}=P\\left(j\\vert{i}\\right)=\\frac{X_{ij}}{X_i}$,是word $j$出现在word $i$ 上下文的概率。\n\n由以上概念引申出共现概率矩阵（Co-occurrence Probabilities Matrix），以下为论文中的例子：\n\n-![](GloVe/Co-occurrence-probilities.png)\n该矩阵的第一个元素为ice出现时solid出现的概率，第二个元素为ice出现时gas出现的概率，以此类推。\n\n由Co-occurrence Probabilities Matrix可以看出$Ratio=\\frac{P_{ik}}{P_{jk}}$的取值是有一定的规律的。[文章](http://blog.csdn.net/coderTC/article/details/73864097)对该规律进行了总结：\n\n| **ratioi,j,k的值** | **单词j,k相关** | **单词j,k不相关** |\n| ---------------- | ----------- | ------------ |\n| **单词i,k相关**      | 趋近1         | 很大           |\n| **单词i,k不相关**     | 很小          | 趋近1          |\n\n也就是说Ratio值能够反映word之间的相关性，**而GloVe模型就是利用了这个Ratio值**。\n\n 再明确一下，**GloVe模型的目标就是获取每一个word的向量表示v**。不妨假设现在已经得到了word $i, j, k$ 的词向量$w_i, w_j, w_k$。**GloVe认为，这三个向量通过某种函数的作用后所呈现出来的规律和$Ratio=\\frac{P_{ik}}{P_{jk}}$具有一致性，即相等，也就可以认为词向量中包含了共现概率矩阵中的信息。**\n\n假设这个未知的函数是$F$,则:\n\n$$F(w_i, w_j, w_k)=\\frac{P_{ik}}{P_{jk}}$$\n\n*此处可以类比word2vec的基本思想（以基于哈弗曼树的CBOW为例），假设word $i$，和其context words的词向量已知，通过一层神经网络作用于context words的向量得到的结果与word $i$在哈夫曼树中的位置具有一致性。*\n\n# 3. 模型推导\n\n公式\n\n$$\nF(w_i, w_j, w_k)=\\frac{P_{ik}}{P_{jk}} \n$$\n\n右侧的$\\frac{P_{ik}}{P_{jk}}$可以通过统计求的；\n\n左侧的$w_i, w_j, w_k$是我们模型要求的量；\n\n同时函数$F$是未知的。\n\n如果能够将函数F的形式确定下来，就可以通过优化算法求解词向量了。那么GloVe模型的作者是怎么将F确定下来的呢？*个人觉着这个过程真是脑洞大开，反正我是想不到。*\n\n1. $\\frac{P_{ik}}{P_{jk}}$考察了$i, j, k$三个word两两之间的相似关系，不妨单独考察$i, j$ 两个词和他们词向量$w_i, w_j$，线性空间中的相似关系自然想到的是两个向量的差$(v_i-v_j)$。 所以F函数的形式可以是\n   $$\n   F(w_i - w_j, w_k)=\\frac{P_{ik}}{P_{jk}}\n   $$\n\n2. $\\frac{P_{ik}}{P_{jk}}$是一个标量，而F是作用在两个向量上的，向量和标量之间的关系自然想到了使用内积。所以F函数的形式可以进一步确定为\n   $$\n   F((w_i - w_j)^T w_k)=F(w_i^T w_k- w_j^T w_k)=\\frac{P_{ik}}{P_{jk}}\n   $$\n\n3. 到此为止模型公式的形式是 $F(w_i^T w_k- w_j^T w_k)=\\frac{P_{ik}}{P_{jk}}$。 左边是差，右边是商，模型通过将F取作exp来将差和商关联起来\n   $$\n   exp(w_i^T w_k- w_j^T w_k)=\\frac{exp(w_i^T w_k)}{exp(w_j^T w_k)}=\\frac{P_{ik}}{P_{jk}}\n   $$\n\n4. 现在只需要让分子分母分别相等上式就能够成立，所以\n   $$\n   exp(w_i^T w_k)=P_{ik} \\\\\n   exp(w_j^T w_k)=P_{jk}\n   $$\n\n5. 所以只需要在整个文本库中考察$exp(w_i^T w_k)=P_{ik}=\\frac{X_{ik}}{X_i}$ ，即\n   $$\n   w_i^T w_k=log(\\frac{X_{ik}}{X_i}) = logX_{ik} - logX_i \n   $$\n\n6. 作为向量，交换$i$ 和$k$ 的顺序 $w_i^T w_k$ 和$w_k^T w_i$ 是相等的，即公式左边对于$i$ 和$k$ 的顺序是不敏感的，但是公式右边交换$i$ 和$k$ 的顺序$ logX_{ik} - logX_i  \\ne logX_{ki} - logX_k $ 。为了解决这个对称性问题，模型引入了两个偏执项 $b_i, b_k$,从而将模型变成了\n   $$\n   logX_{ik}  = w_i^T w_k + b_i + b_k\n   $$\n   其中$b_i $中包含了$logX_k$,所以公式中没有显示的写明这一项，为了保持模型的对称性，又加入了 $b_k$.\n7. 上面的公式只是理想情况下，在实际实验中左右两边只能要求接近。从而就有了代价函数（cost function）\n   $$\n   J= \\sum_{ik}(w_i^T w_k + b_i + b_k -logX_{ik})^2\n   $$\n\n8. 根据经验，如果两个词共同出现的次数越多，那么这两个词在代价函数中的影响就应该约大，所以可以根据两个词共同出现的次数设计一个权重项来对代价函数中的每一项进行加权：\n   $$\n   J= \\sum_{ik}f(X_{ik})(w_i^T w_k + b_i + b_k -logX_{ik})^2\n   $$\n   模型认为权重函数$f$应该符合以下三个特点，1. $f(0)=0$ （如果两个词没有共同出现过，权重就是0）；2. $f(x)$必须是非减函数（两个词共同出现的次数多，反而权重变小了，违反了设置权重项的初衷）；3. $f(x)$对于较大的$x$不能取太大的值（就像是汉语中“的”这个字，在很多文章中都会出现很多次，但是其在文中的重要程度非常小）。综合这三条特点的$f(x)$定义为：\n   $$\n   f(x)=\\left\\{\\begin{aligned} (\\frac{x}{x_{max}})^\\alpha &,   if \\;  x<x_{max} \\\\1&,\\;otherwise   \\end{aligned}\\right.\n   $$\n\n   \n   ![](GloVe/Weighting-function.png)\n   根据经验，GloVe作者认为$x_{max}=100$, $\\alpha=\\frac34$是一个比较好的选择。\n\n\n\nnote：本文是主要是基于原始paper论述，但也局限于个人知识面和理解水品，里面掺杂了一些个人的观点，如有错误，请谅解\n\n# 参考文献\n\n1. [LSA](https://en.wikipedia.org/wiki/Latent_semantic_analysis)\n2. [Improving Distributional Similarity with Lessons Learned from Word Embeddings](https://www.transacl.org/ojs/index.php/tacl/article/view/570)\n3. [CS224n: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/cs224n/syllabus.html)\n4. [word2vec 中的数学原理详解](http://blog.csdn.net/itplus/article/details/37969519)\n5. [GloVe: Global Vectors for Word Representation paper](https://nlp.stanford.edu/pubs/glove.pdf)\n6. [GloVe: Global Vectors for Word Representation tutorial](https://nlp.stanford.edu/projects/glove/)\n7. [理解GloVe模型（Global vectors for word representation）](http://blog.csdn.net/coderTC/article/details/73864097)\n","tags":["Embedding"],"categories":["Neural Networks"]},{"title":"xgboost","url":"%2Fblog%2Fxgboost.html","content":"\n\n\n在文章[GBDT](https://weirping.github.io/blog/GBDT.html)中介绍了 Gradient、Booster、Gradient Booster 等一些基本理论推导，和一种Tree boosting算法-GBDT算法。 sklearn 也提供了 GBDT 的实现，我们可以方便的使用。 但是在生产环境中我们通常使用的是 [Xgboost](https://xgboost.readthedocs.io/en/latest/) 这个工具提供的Tree boosting算法。在本文记录一下Xgboost中实现的Tree boosting的原理和其主要的应用， 如分类，回归，ranking。\n\n# Regression Tree Ensemble\n\n\n\nTree Ensemble 实际上可以理解为将 Gradient Booster(参考文章 [GBDT](https://weirping.github.io/blog/GBDT.html)) 中将每一步的模型(如弱分类器)换成回归树的一类模型。\n\nXgboost 中实现的 Tree Ensemble 算法和 GBDT 非常相似， 但也有所不同。我觉得在原理上是有所升级的。我们先从 Tree Ensemble 的目标函数出发，沿着其推导过程来看其改进之处。\n\nTree Ensemble 模型定义为 由 $K$ 个回归树相加组成的模型 ：\n$$\n\\hat y_i= \\sum_{i=1}^K f_k(x_i), f_k \\in \\mathcal F \\tag 1\n$$\n其中: $\\mathcal F$ 表示回归树的集合, 定义为:\n$$\n\\mathcal F = \\{ f(x) = w_{q(x)}\\} (q: R^m \\to T, w \\in R^T) \\tag 2\n$$\n简单解释一下上面的公式：\n\n- $q$ 表示一个树的结构，其作用就是将一个具有 $m$ 维特征的 sample 映射到$T$个叶子节点上。即，$q: R^m \\to T$ 。 $q(x)$ 表示叶子节点的序号。\n- $w$ 是一个 $T$ 维向量，其每个维度对应树的一个叶子节点，表示回归树中每个叶子节点的取值。 $w_{q(x)}$ 表示样本 $x$ 在回归树上的预测值。\n\n\n\nTree Ensemble 的目标函数如下：\n$$\n\\begin {align}\n& obj = \\sum_{i=1}^N l(y_i, \\hat y_i)  + \\sum_{k=1}^K \\Omega (f_k) \\\\\n& where\\ \\ \\Omega (f) = \\gamma T + \\frac 12 \\lambda||w||^2\n\\end {align} \\tag 3\n$$\n其中： \n\n- 第一项 为 训练集上的损失函数(需要是可微的凸函数)。根据任务目标的不同，损失函数的定义也不同。如：\n  回归任务可以使用平方和损失函数 (Square loss) $ l(y_i, \\hat y_i) = (y- \\hat y_i)^2 $ ；\n  分类任务可以使用交叉熵损失函数；\n  rank任务使用 ......  这一个说来话长，后面再说吧。\n- 第二项 为 模型正则项，它从树的结构和树的预测值两个方面对目标函数进行正则化\n  1. $\\gamma T$ 倾向于选择叶子节点少的回归树（结构简单）；\n  2. $\\frac 12 \\lambda||w||^2$倾向于预测值稳定的树（预测值）。\n\n  即论文中所说的 *Intuitively, the regularized objective will tend to select a model employing simple and predictive functions.* \n\n# Gradient Boosting\n\n如文章[GBDT](https://weirping.github.io/blog/GBDT.html)中所述 在 Gradient Boosting 中进行若干轮迭代计算，每一轮产生一个新的决策树和其对应的预测值。且，每一个新的决策树都是上一轮预测值的残差。那么怎么确定这颗新的决策树呢？本节推导第 $t$ 颗决策树的确定方法。\n\n如下所示：\n$$\n\\begin {align}\n\\hat y_i^{(0)} &= 0 \\\\\n\\hat y_i^{(1)} &= f_1(x_i) = \\hat y_i^{(0)} +  f_1(x_i)   \\\\\n\\hat y_i^{(2)} &= f_1(x_i) + f_2(x_i) = \\hat y_i^{(1)} +  f_2(x_i)   \\\\\n\\dots \\\\\n\\hat y_i^{(t)} &= \\sum_{k=1}^t f_k(x_i)  = \\hat y_i^{(t-1)} +  f_t(x_i)   \\\\\n\\end {align}\n$$\n\n可以看出第 $t$ 轮的预测值是第 $t-1$ 轮的预测值 加上 一个新的决策树的预测值。那么这颗新的决策树怎么确定呢？虽然此处借鉴了梯度下降法的原理，可是我们却不能直接使用梯度下降法(如SGD)求解这颗新的决策树( since they are \ntrees, instead of just numerical vectors)。\n\n我们的解决方法称为 **Additive Training** 即(Boosting)。回到我们的目标函数和第 $t$ 轮迭代时的预测值表达式 $\\hat y_i^{(t)} = \\sum_{k=1}^t f_k(x_i)  = \\hat y_i^{(t-1)} +  f_t(x_i) $, 我们可以将目标函数表达如下: \n$$\nobj^{(t)} = \\sum_{i=1}^N l(y_i, \\hat y_i^{(t-1)} +  f_t(x_i))  + \\Omega (f_t) + constant \\tag 4\n$$\n其中: $\\sum_{i=1}^t \\Omega (f_i) = \\Omega (f_t) +  \\sum_{i=1}^{t-1} \\Omega (f_i)= \\Omega (f_t) + constant$, 对于第 $t$ 轮来说 前 $t-1$ 个决策树都是确定的，所以 $ \\sum_{i=1}^{t-1} \\Omega (f_i)$ 是一个常数。\n\n所以第 $t$ 轮迭代时我们的目标函数中只有一个未知参数 $f_t(x_i)$ 即我们需要的决策树。 所以第 $t$ 个决策树只要能够使得上面的目标函数最小化就好了。\n\n但是上面的目标函数还是有点复杂，能不能简化一点呢？ 当然，借助损失函数的二级泰勒展开式来近似损失函数。\n\n回忆一下 二阶泰勒展开式：\n$$\nf(x + \\Delta x) \\approx f(x) + f'(x) \\Delta x + \\frac 12 f''(x) \\Delta x^2 \\tag 5\n$$\n为了简化表示 定义如下两个符号: \n$$\ng_i = \\frac {\\partial l(y_i, \\hat y_i )} {\\partial \\hat y_i }|_{\\hat y_i^{(t-1)}} \\\\\nh_i= \\frac {\\partial ^2 l(y_i, \\hat y_i )} {\\partial \\hat y_i^2 }|_{\\hat y_i^{(t-1)}}  \\tag 6\n$$\nnote: 对于确定的损失函数(由任务目标决定) , 第 $t$ 轮迭代时以上两个值是确定值(常数)。\n\n使用损失函数的二阶泰勒展开式近似的目标函数可以表示为：\n$$\nobj^{(t)} \\approx \\sum_{i=1}^N [l(y_i, \\hat y_i^{(t-1)}) +  g_i f_t(x_i) + \\frac 12 h_i f^2_t(x_i)]  + \\Omega (f_t) + constant \\tag 7\n$$\n\n对于第 $t$ 轮迭代, 上式中 $l(y_i, \\hat y_i^{(t-1)})$ 也是常数项目，去掉常数项， 所以对于第 $t$ 轮迭代的目标函数可以进一步简化成下式：\n$$\n\\tilde{\\mathcal L}^{(t)} = \\sum_{i=1}^N [ g_i f_t(x_i) + \\frac 12 h_i f^2_t(x_i)]  + \\Omega (f_t) \\tag 8\n$$\n\n通过上式对第 $t$ 步可能的候选决策树$f_t$进行打分，能够使 $\\tilde{\\mathcal L}^{(t)}$ 最小的一个 $f_t$ 就是这一步需要的决策树。\n\n---\n\n# 确定回归树预测值\n\n本节先假设回归树的结构 $q$ 是确定的，推导回归树中每个叶子节点预测值 $\\hat w$。\n\n对于一个决策树 $q: R^m \\to T, w \\in R^T$ 来说，令 $I_j = \\{ i | q(x_i) = j \\}$ 表示所有映射到第 $j$ 个叶子节点的样本的集合。联合公式3 对正则化项的定义，公式 7 可以表示如下：\n$$\n\\begin {aligned}\n\\tilde{\\mathcal L}^{(t)} &= \\sum_{i=1}^N [ g_i f_t(x_i) + \\frac 12 h_i f^2_t(x_i)]  + \\Omega (f_t) \\\\\n&= \\sum_{i=1}^N [ g_i f_t(x_i) + \\frac 12 h_i f^2_t(x_i)]  + \\gamma T + \\frac 12 \\lambda||w||^2 \\\\\n&= \\sum_{i=1}^N [ g_i f_t(x_i) + \\frac 12 h_i f^2_t(x_i)]  + \\gamma T + \\frac 12 \\lambda \\sum_{j=1}^Tw_j^2 \\\\\n&=  \\sum_{j=1}^T [(\\sum_{i \\in I_j} g_i) w_j + \\frac 12 (\\sum_{i \\in I_j} h_i) w_j^2 ]  + \\gamma T + \\frac 12 \\lambda \\sum_{j=1}^Tw_j^2 \\\\\n&=  \\sum_{j=1}^T [(\\sum_{i \\in I_j} g_i) w_j + \\frac 12 (\\sum_{i \\in I_j} h_i + \\lambda) w_j^2 ]  + \\gamma T \\\\\n\\end {aligned}\n$$\n\n\n令$G_j = \\sum_{i \\in I_j} g_i; H_j = \\sum_{i \\in I_j} h_i $ 上式可以表示为:\n$$\n\\tilde{\\mathcal L}^{(t)} =  \\sum_{j=1}^T [G_j w_j + \\frac 12 (H_j + \\lambda) w_j^2 ]  + \\gamma T \\tag 9\n$$\n结合公式6 可以发现 $G_j, H_j$ 只与树结构 $q$ 有关。\n\n回想上面我们对回归树的定义： $q$ 表示树的结构， $w$ 表示每个叶子节点上的预测值。打分公式 $\\tilde{\\mathcal L}^{(t)}$ 只与 $q$ 和 $w$ 有关。那么对于一个确定的树结构 $q$ ， 最优的叶子节点预测值 $w$ 可以表示为 ：\n$$\n\\hat w_j = - \\frac {G_j}{H_j + \\lambda}\n$$\n\n$$\n\\begin {aligned}\n\\tilde{\\mathcal L}^{(t)} &= - \\frac 12 \\sum_{j=1}^T \\frac {G_j^2}{H_j + \\lambda}  + \\gamma T \\\\\n&= - \\frac 12 \\sum_{j=1}^T \\frac {(\\sum_{i \\in I_j} g_i)^2}{(\\sum_{i \\in I_j} h_i) + \\lambda}  + \\gamma T\n\\end {aligned} \\tag {10}\n$$\n\nnote: $ \\hat w_j = - \\frac {G_j}{H_j + \\lambda}$ 是使公式8 取最小值的 $w$。\n\n![](xgboost/structure-score.png)\n\n由公式 10 可以发现 对于一个结构确定的回归树 $q$，$\\tilde{\\mathcal L}^{(t)}$ 的取值与$w$ 是无关的。即，$\\tilde{\\mathcal L}^{(t)}$ 值与回归树的结构 q 有关, 所以论文中称公式10 为 **structure score**。即 *a scoring function to measure the quality of a tree structure q.*\n\n所以只需要穷举所有可能的树结构 q ，求能够使的$\\tilde{\\mathcal L}^{(t)}$最小的一个 $q$ 即可。\n\n但是，$q$ 有无穷个可能的取值。\n\n---\n\n# 确定的回归树结构\n\n无论是决策树，回归森林还是GBDT，xgboost中的Tree boosting算法 都需要以超参的形式决策树的最大深度。在最大深度的限制下如果能确定每个节点的分裂条件，就能够确定一颗唯一的回归树结构 $q$。选取方法为：\n\n> 1. Start from tree with depth 0\n> 2. For each leaf node of the tree, try to add a split. \n> 3. 重复第二步，知道达到最大深度\n\n完成以上三步，其实就枚举了所有可能的树结构，并选择一个能够使公式10取最小值的结构。其中关键问题在于第二步中怎么确定分割点。\n\n公式10 其实就是类似与决策树中不纯度的定义。在xgboost确定回归树的结构的过程中，就是使用公式10来对树的叶子节点进行打分的。\n\n令 $I_L$ 和$I_R$ 分别表示一个叶子节点分类后左边和右边节点的样本集合， $I = I_L \\cup I_R$, 那么这一个分割点的打分公式表示如下：\n$$\n\\begin {aligned}\ngain &=  \\mathcal L -  (\\mathcal L_L + \\mathcal L_R) \\\\\n&= \\frac 12 [\\frac {(\\sum_{i \\in I_L} g_i)^2}{(\\sum_{i \\in I_L} h_i)} + \\frac {(\\sum_{i \\in I_R} g_i)^2}{(\\sum_{i \\in I_R} h_i)} - [\\frac {(\\sum_{i \\in I} g_i)^2}{(\\sum_{i \\in I} h_i)} ] - \\gamma\n\\end {aligned} \\tag {11}\n$$\n结合公式10 可以发现，$gain$越大，损失函数越小，跟个点选取的越好。所有我们只需要选取一个能使$gain$最大的一个分割点即可。xgboost中是穷举所有可能的分割点，即样本数据中每一维度的每一个样本值都作为候选分割点，选取gain最大的一个。\n\n![](xgboost/greedy-algorithm.png)\n\nxgboost 提供了多种方法来求解分割点，上述方法称为 exact 方法，针对内存能够一次载入的数据集。其次还有approx方法(一种近似方法)， 和 hist方法(基于直方图的方法)。还有GPU版本。\n\n其他方法参见原始论文。\n\n# Shrinkage and Column Subsampling\n\nShrinkage 和 Column Subsampling 是又一种处理过拟合问题的技术。\n\n## Shrinkage\n\nshrinkage reduces the inuence of each individual tree and leaves space for future trees to improve the model.\n\n即经过标准的tree boosting流程确定完一颗回归树以后，第 $t$ 步的预测值使用下式计算:\n$$\n\\hat y_i^{(t)} = \\hat y_i^{(t-1)} +  \\eta f_t(x_i)\n$$\n\n原理和梯度下降法中的学习率类似。\n\n##　Column Subsampling\n\n如上文所述在确定决策树分割点时使用了所以特征的所有样本值计算 gain, 从中选取一个最好的。从计算量和过拟合问题的角度看，其实我们可以从所有特征中随机的抽取固定比例的特征(如 30%)作为候选特征。\n\n包括如下三个参数： `colsample_bytree`, `colsample_bylevel`, `colsample_bynode`\n\n# 与 GBDT 的不同点\n\n\n我并没有看 原始 GBDT的实现细节，以下是我直接根 xgboost 的据论文和 文章 GBDT 的参考资料整理的 xgboost 和 原始 GBDT 的不同点，如果以后又机会了解更细节的内容再回来修改：\n\n1. 增加了模型正则项，GBDT算法中并没有使用正则化项；\n2. 除了正则化以外还使用了多种技术解决过拟合问题，如subsample，Shrinkage，Column Subsampling；\n3. 使用了二阶泰勒展开式近似目标函数，GBDT中使用的是直接使用的一阶梯度。即, 求解方式分别使用了牛顿法和梯度下降法\n\n\n# 参考资料\n\n[Introduction to Boosted Trees](https://xgboost.readthedocs.io/en/latest/tutorials/model.html)\n\n[XGBoost: A Scalable Tree Boosting System](https://arxiv.org/pdf/1603.02754.pdf)\n\n","tags":["Toolkit"],"categories":["Toolkit"]},{"title":"GBDT","url":"%2Fblog%2FGBDT.html","content":"\nGBDT(Gradient Boosting Decision Tree) 又叫 MART（Multiple Additive Regression Tree)，是一种迭代的决策树算法，该算法由多棵决策树组成，所有树的结论累加起来做最终答案。它在被提出之初就和SVM一起被认为是泛化能力（generalization)较强的算法。该模型被广泛的应用与ctr预估和搜索排序中。\n\n本文按照Gradient（梯度下降法） -> Boosting（加性模型） -> Decision Tree （决策树）的顺序描述GBDT这个模型。\n\n# Gradient（梯度下降法）\n\n对于一个优化目标函数 \n$$\n\\min_{\\Theta} J(\\Theta)\n$$\n其中 $\\Theta$ 为参数。求解$\\Theta$ 的迭代公式为: \n$$\n\\Theta^{i+1} = \\Theta^i - \\alpha \\nabla J(\\Theta)|_{\\Theta^i}\n$$\n其中 $\\alpha$ 为步长。\n\n# Boosting\n\nBoosting，迭代，即通过迭代多个模型来共同决策。它\n\n- 是一种集成学习方法\n- 是一种算法框架\n- 是一种加性模型\n\n其中比较经典的算法有  AdaBoost，RealAdaBoost。\n\nBoosting 使用多个模型的预测结果的累加来作为最终的预测结果(即，加性模型)。比如在预测人的年龄任务中，A的真实年龄是18岁，但第一个模型的预测年龄是12岁，差了6岁，即残差为6岁。那么在第二个模型里我们把A的年龄设为6岁去学习，如果第二个模型真的能把A分到6岁的叶子节点，那累加两棵树的结论就是A的真实年龄；如果第二棵树的结论是5岁，则A仍然存在1岁的残差，第三棵树里A的年龄就变成1岁，继续学。这就是 Boosting  的意义。\n\n关于这个方面的理论这里简单介绍如下：\n\n对于一个预测任务，使用了M个模型， 那么对于一条数据$x_i$ 的预测值可以表示为：\n$$\n\\hat y_i = \\sum_{m=1}^M \\beta_m b(x_i, \\gamma_m)\n$$\n其中：\n\n- $b$ : 基础模型， 对于分类任务来说，也称为 **基分类器**。\n- $\\beta$: 每个基础模型在总的预测结果中占有的权重。\n- $\\gamma$: 每个基础模型的参数。\n\n那么一个预测任务来说，总的优化目标就是\n$$\n\\min_{\\{\\beta_m, \\gamma_m\\}_1^M}  \\sum_{i=1}^N L[y_i,  \\sum_{m=1}^M \\beta_m b(x_i, \\gamma_m)]\n$$\n其中： $N$ 为训练样本量。\n\n# Gradient + Boosting\n\n下面推导 Gradient 和 Boosting 是怎么结合起来的。\n\n同样还是对于一个预测任务，给定样本量为 $N$ 样本集, 求预测模型为 $f(x)$。 即我们的学习目标是: \n$$\n\\vec f = {\\arg\\min}_{\\vec f} \\mathcal L(\\vec y, \\vec f)  ={\\arg\\min}_{\\vec f}   \\sum_{i=1}^N L[y_i,  f(x_i)]\n$$\n其中: \n\n- $\\vec f = \\{f(x_1), f(x_2), \\dots , f(x_N) \\}$ , 且函数对于所有的样本 $x_i$ 是同一个函数, 向量的长度和样本量相同。\n- $\\vec y = y_1, y_2, \\dots, y_N $ , 向量的长度和样本量相同。\n- $\\mathcal L(\\vec y, \\vec f)$ 是整个样本集的损失函数。\n\n即，优化目标为：在整个样本集上的损失最小。 下面借鉴梯度下降法的原理， **认为 $\\vec f$ 为参数, 迭代求$\\vec f$**。 类比如下：\n\n| $ \\min_{\\vec f}\\mathcal L(\\vec y, \\vec f) $ | $\\min_{\\Theta} J(\\Theta)$ |\n| ---------------------------------------- | ------------------------- |\n| $\\vec f$                                 | $\\Theta$                  |\n| $\\mathcal L$                             | $J$                       |\n\n$\\min_{\\vec f}\\mathcal L(\\vec y, \\vec f)$ 在$ \\vec f_{m-1}$ 处的梯度：\n$$\n\\vec g_m = [\\frac{\\partial \\mathcal L(\\vec y, \\vec f)}{\\partial {\\vec f}}] | _{\\vec f = \\vec f_{m-1}}\n$$\n那么求解$\\vec f_m$ 的迭代公式为: \n$$\n\\vec f_m = \\vec f_{m-1} + \\alpha_m (- \\vec g_m)\n$$\n其中： $\\alpha$ 为每一步的步长， 在GBDT里面使用的是统一的步长，即，对于所有的 基础模型 使用同一个预设的步长(超参)。\n\n那么: \n$$\n\\vec f_m =  \\alpha_0 (- \\vec g_0) + \\alpha_1 (- \\vec g_1) + \\alpha_2 (- \\vec g_2) + \\dots + \\alpha_m (- \\vec g_m) \\tag 1\n$$\n对于上式我们可以这样理解：\n\n- 每一步的 $(- \\vec g)$ 都表示一个基础模型的预测结果, 在GBDT中这个基础模型就是 决策树。那么最终的模型预测结果，是所有单个模型预测结果的累加；\n- 增加新的模型，使结果在前一步的基础上更加逼近最优点；\n- 新模型训练的是上一个模型的**残差**。\n\n这就是 Gradient + Boosting 的数学推导。\n\n# GBDT\n\nDT在这里指的是决策树(Decesion Tree)， 而决策树有分为  分类树(Classification Tree) 和 回归树 (Regression Tree)。 实际上在GBDT模型中使用的是回归树，这也是为什么GBDT又名 MART(Multiple Additive Regression Tree) 的原因。\n\n>Decesion Trees partition the space of all joint predictor variable values into disjoint regions $R_j,  j = 1, 2,  \\dots, J$ , as represented by the terminal nodes of the tree. A constant $\\gamma_j$ is assigned to each such region and the predictive  rule is \n>$$\n>x \\in R_j  \\Rightarrow f(x) = \\gamma_j\n>$$\n>决策树可以被定义为：\n>$$\n>T(x; \\Theta) = \\sum_{j=i}^J \\gamma_j I(x \\in R_j)\n>$$\n>其中： $\\Theta = \\{R_j, \\gamma_j\\}_1^J $ 表示模型参数, $J$ 表示决策树叶子节点的数量(通常是通过限制树的深度限制叶子节点的数量)。\n\n决策树就是将样本的属性映射到一个具体的类别(分类树)或者score(回归树)。\n\n使用 若干颗回归树对 式 1 中的所有梯度 $-g$ 进行替换即得到一个GBDT模型的表示方法。如下：\n$$\n\\begin {align}\n\\vec f_m &=  \\alpha_0 (- \\vec g_0)& +& \\alpha_1 (- \\vec g_1)& +& \\alpha_2 ( - \\vec g_2)& + \\dots +& \\alpha_m (- \\vec g_m) \\\\\n\\downarrow \\\\\n\\vec f_m &=  \\alpha_0 (T_0)& +& \\alpha_1 (T_1)& +& \\alpha_2 (T_2)& + \\dots +& \\alpha_m (T_m) \\\\\n\\end {align}\n$$\n\n通常来说，一个机器学习模型的训练实际上就是寻找模型参数的过程。那么GBDT模型的参数是什么呢？\n\n1. parameters Including structure of each tree, and the score in the leaf； 或者说GBDT模型的参数就是模型中的所有决策树 $\\{T_0, T_1, T_2, \\dots, T_m\\}$\n2. 与一般的模型(如LR)不同，Instead learning weights ,  we are learning functions(trees) 。\n\n\n\nGBDT的算法流程如下:\n\n![](GBDT/GBDT-algorithm.png)\n\n# GBDT 在预处理中的的应用\n\nGBDT作除了可以解决其分内应该解决的问题（分类任务，回归任务）外，还可以用来进行数据预处理，如：\n\n1.  特征筛选： GBDT可以发现有区分性的特征。由于GBDT基础是决策树，所以它也觉有决策树的特点，决策树或者随机森林可以用于特征选择，选择的依据就是特征重要性。其中常用道的特征重要性衡量指标有两个：\n\n   - Gini:(Mean Decrease in Impurity (MDI))\n   - •Permutation:(Mean Decrease in Accuracy (MDA)\n\n   详细内容这里不论述了。\n\n   使用方法可以参考这片blog [使用GBDT选取特征](https://www.letiantian.me/2015-03-31-use-gbdt-to-select-features/), 多年前我曾经使用其中的数据集合，做过相同的实验，奈何代码找不到了，只有实验结论，且于blog中的相近。当时的结论如下：\n\n   ![](GBDT/GBDT-LR.png)\n\n2. 特征组合\n   GBDT可以对现有的特征进行特征组合，直接生成新的更有效的特征，省去了人工特征组合的麻烦。通过GBDT生成的特征，可直接作为LR的特征使用，省去人工处理分析特征的环节，LR的输入特征完全依赖于通过GBDT得到的特征。这个方法被facebook用来做ctr预估。同时也有使用GBDT+FM的方案，在 2014 Kaggle CTR竞赛冠军就是使用GBDT+FM。\n\n   GBDT进行特征组合的原理比较简单，其本质还要追溯到决策树原理。 对于一个决策树来说，其本质是将特征空间分割成若干个不相交的离散区域，对于每一个区域赋予一个预测值。\n   ![](GBDT/dt-feature-compose.png)\n\n   \n   如上图所示，假设我们使用的训练样本只有两个特征，即我么的样本空间就是右图那样的一个平面。使用一颗决策树训练后得到左图所示的决策树，其四格叶子节点实际上就是将右图那样的特征空间分割称为四个区域。其一一对于关系如图中的数字所示。一个样本必然会落在四个叶子节点中的一个内。\n\n   当我们使用GBDT时，将会有多颗决策树，如下图所示，基于训练样本得到由三颗决策树组成的GBDT模型。\n\n   ![](GBDT/gbdt-feature-compose.png)\n\n   \n\n   对于任何一个样本(record A)，该样本将会在每颗决策树中落到一个节点上，假设 record A 落在了 3, 5, 13 这三个叶子节点上。那么 record  A 的新特征为 :(0,0,1,0**,** 1,0,0,0**,** 0,0,0,1)。note： 新特征中每一位对应一个叶子节点，每四位对应一颗决策树， 1 表示样本落在了相应节点上，0 表示样本没有落在了相应节点上。\n\n# 参考资料\n\nThe Elements of Statistical Learning\n\n[Practical Lessons from Predicting Clicks on Ads at Facebook](http://quinonero.net/Publications/predicting-clicks-facebook.pdf)","tags":["Decision Tree"],"categories":["Model"]},{"title":"【转】泊松分布和指数分布","url":"%2Fblog%2Fexponential-distribution-and-poisson-distribution.html","content":"\n泊松分布和指数分布 的实际物理意义经常忘掉, 正好看到 [阮一峰](http://www.ruanyifeng.com/home.html) 的篇好文, 转载备查.\n\n泊松分布和指数分布就是描述某一时间在一定的时间内时间发生的概率。\n\n泊松分布的参数为  时间t、频率$\\lambda$、次数n：描述单位时间平均发生$\\lambda$次的现象在时间t内发生n次的概率。\n\n指数分布的参数为  时间t、频率$\\lambda$ ：描述单位时间平均发生$\\lambda$次的现象在时间t内发生的概率(此处没有次数限制)。\n\n# 泊松分布\n\n日常生活中，大量事件是有固定**频率**的。\n\n> - 某医院平均每小时出生3个婴儿\n> - 某公司平均每10分钟接到1个电话\n> - 某超市平均每天销售4包xx牌奶粉\n> - 某网站平均每分钟有2次访问\n\n它们的特点就是，我们可以预估这些事件的总数，但是没法知道具体的发生时间。已知平均每小时出生3个婴儿，请问下一个小时，会出生几个？有可能一下子出生6个，也有可能一个都不出生。这是我们没法知道的。\n\n**泊松分布就是描述单位时间内，事件具体的发生概率。**\n\n$$P(N(t)=n)=\\frac{(\\lambda t)^{n}e^{-\\lambda t}}{n!}$$\n\n上面就是泊松分布的公式。等号的左边，$P$ 表示概率，$N$表示某种函数关系，$t$表示时间，$n$ 表示数量，1小时内出生3个婴儿的概率，就表示为 $P(N(1) = 3)$ 。等号的右边，$\\lambda$表示事件的频率。\n\n泊松分布的参数$\\lambda$是单位时间$t$(或单位面积)内随机事件的**平均发生次数**，描述的是该事件在单位时间内发生$n$次的概率。泊松分布的期望和方差均为$\\lambda$.\n\n接下来两个小时，一个婴儿都不出生的概率是0.25%，基本不可能发生。\n\n$$P(N(2)=0)=\\frac{(3\\times 2)^{0}e^{-3\\times 2}}{0!}\\approx 0.0025$$\n\n接下来一个小时，至少出生两个婴儿的概率是80%。\n\n$$\n\\begin {align}\nP(N(1) \\ge 2) &= 1 - P(N(1) = 1) - P(N(1) = 0)  \\\\\n&  = 1 - \\frac {(3 \\times 1)^1 e^{-3 \\times 1}} {1!} - \\frac {(3 \\times 1)^0 e^{-3 \\times 1}} {0!}  \\\\  \n&  = 1 - 3e^{ - 3} - e^{ - 3}  \\\\\n&  = 1 - 4e^{ - 3} \\\\\n& \\approx 0.8009 \\\\\n\\end{align}\n$$\n\n泊松分布的图形大概是下面的样子。\n\n![poisson_distribution](exponential-distribution-and-poisson-distribution/poisson-distribution.gif)\n\n# 指数分布\n\n**指数分布是事件的时间间隔的概率。**下面这些都属于指数分布。\n\n> - 婴儿出生的时间间隔\n> - 来电的时间间隔\n> - 奶粉销售的时间间隔\n> - 网站访问的时间间隔\n\n指数分布的公式可以从泊松分布推断出来。如果下一个婴儿要间隔时间$t$ ，就等同于$t$之内没有任何婴儿出生。\n\n $P(X>t)=P^{(}N(t)=0)=\\frac{(\\lambda t)^{0}\\mathrm{e}^{-\\lambda t}}{0!}$  $=\\ \\mathbf{e}^{-\\lambda t}$ \n\n反过来，事件在时间$t$之内发生的概率，就是1减去上面的值。即得指数分布的分布函数：\n\n$$F(t)=P(X\\leq t)=1-P(X>t)=1-\\ \\mathbf{e}^{-\\lambda t}$$\n\n其概率密度函数为：\n\n$$P(X=t)=\\lambda e^{\\lambda t},t>0$$\n\n接下来15分钟，会有婴儿出生的概率是52.76%。\n\n $P(X\\leq 0.25)=1-\\ \\mathbf{e}^{-3\\times 0.25}$  $\\approx 0.5276$ \n\n接下来的15分钟到30分钟，会有婴儿出生的概率是24.92%。\n\n$$\n\\begin {align}\n& P(0.25 \\le X \\le 0.5) = P(X \\le 0.5) - P(X \\le 0.25)  \\\\\n&  = (1 - e^{ - 3 \\times 0.5}) - (1 - e^{ - 3 \\times 0.25})\\\\ \n& = e^{ - 0.75} - e^{ - 1.5}  \\\\\n& \\approx 0.2492\n\\end {align}\n$$\n\n![exponential_distribution](exponential-distribution-and-poisson-distribution/exponential-distribution.gif)\n\n可以看到，随着间隔时间变长，事件的发生概率急剧下降，呈指数式衰减。想一想，如果每小时平均出生3个婴儿，上面已经算过了，下一个婴儿间隔2小时才出生的概率是0.25%，那么间隔3小时、间隔4小时的概率，是不是更接近于0？\n\n**一句话总结：泊松分布是单位时间内独立事件发生次数的概率分布，指数分布是独立事件的时间间隔的概率分布。**\n\n本文转自 [泊松分布和指数分布](http://www.ruanyifeng.com/blog/2015/06/poisson-distribution.html)\n\n\n","tags":["Probability"],"categories":["Mathematics"]}]